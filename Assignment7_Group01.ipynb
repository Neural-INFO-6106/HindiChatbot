{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cb421e",
   "metadata": {},
   "source": [
    "# Assignment 06 : Team 01\n",
    "\n",
    "Bhawana Agarwal, Cheril Yogi, Tripti Gupta \n",
    "\n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "To design a chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918874fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary Libraries \n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944c2fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/cherilyogi/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK model data (you need to do this once)\n",
    "nltk.download(\"book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8841d",
   "metadata": {},
   "source": [
    "Setting up some variables for text processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ba440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 3000 # can be improved by using a larger vocabulary size\n",
    "\n",
    "unknown_token = \"UNKNOWN_TOKEN\" # for words not in vocabulary\n",
    "sentence_start_token = \"START\" # representing start of a sentence\n",
    "sentence_end_token = 'END' # representing end of a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f9ed57",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Using indicnlp library, for natural language processing in Indian languages (Hindi in our case). We are using indicnlp as it provides better tools and resources for working with various Indian languages, including tokenization, trasliteration, and other NLP tasks. We are using few excerpts from the \"Story of Mirabai\" as our dataset for training and testing our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943d07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import indicnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce318af",
   "metadata": {},
   "source": [
    "Tokenizing a text file written in the Hindi language using the `indicnlp library`. The code reads the content of the file named \"mirabai.txt\" and then tokenizes it into sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77992fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
    "\n",
    "with open(r\"/Users/cherilyogi/Desktop/Class_Folder/INFO_6106/Homework_7/mirabai.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "# Tokenize the conversation into sentences\n",
    "text = content.strip()\n",
    "text = text.replace(\"\\n\",\" \")\n",
    "text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "sentences = sentence_tokenize.sentence_split(text, lang='hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fbf9c",
   "metadata": {},
   "source": [
    "The text we took as our dataset look someting like this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33350b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मीराबाई के बालमन में कृष्ण की ऐसी छवि बसी थी कि किशोरावस्था से लेकर मृत्यु तक उन्होंने कृष्ण को ही अपना सब कुछ माना। जोधपुर के राठौड़ रतनसिंह जी की इकलौती पुत्री मीराबाई का जन्म सोलहवीं शताब्दी में हुआ था। बचपन से ही वह कृष्णभक्ति में रम गई थीं।  मीराबाई के बचपन में हुई एक घटना की वजह से उनका कृष्णप्रेम अपनी चरम अवस्था तक पहुंचा। एक दिन उनके पड़ोस में किसी बड़े आदमी के यहां बारात आई। सभी औरतें छत पर खड़ी होकर बारात देख रही थीं। मीरा भी बारात देखने लगीं। बारात को देख मीरा ने अपनी माता से पूछा कि मेरा दूल्हा कौन है इस पर उनकी माता ने कृष्ण की मूर्ति की ओर इशारा कर के कह दिया कि यही तुम्हारे दूल्हा हैं। बस यह बात मीरा के बालमन में एक गांठ की तरह बंध गई।  बाद में मीराबाई की शादी महाराणा सांगा के पुत्र भोजराज जो आगे चलकर महाराणा कुंभा कहलाए से कर दी गई। इस शादी के लिए पहले तो मीराबाई ने मना कर दिया लेकिन जोर देने पर वह फूटफूट कर रोने लगीं। शादी के बाद विदाई के समय वे कृष्ण की वही मूर्ति अपने साथ ले गईं जिसे उनकी माता ने उनका दूल्हा बताया था। ससुराल में अपने घरेलू कामकाज निबटाने के बाद मीरा रोज कृष्ण के मंदिर चली जातीं और कृष्ण की पूजा करतीं उनकी मूर्ति के सामने गातीं और नृत्य करतीं। उनके ससुराल वाले तुलजा भवानी यानी दुर्गा को कुलदेवी मानते थे। जब मीरा ने कुलदेवी की पूजा करने से इनकार कर दिया तो परिवार वालों ने उनकी श्रद्धाभक्ति को मंजूरी नहीं दी। मीराबाई की ननद उदाबाई ने उन्हें बदनाम करने के लिए उनके खिलाफ एक साजिश रची। उसने राणा से कहा कि मीरा का किसी के साथ गुप्त प्रेम है और उसने मीरा को मंदिर में अपने प्रेमी से बात करते देखा है।  राणा कुंभा अपनी बहन के साथ आधी रात को मंदिर गया। वह मंदिर का दरवाजा तोड़ कर अंदर पहुंचा और देखा कि मीरा अकेले ही कृष्ण की मूर्ति के सामने परम आनंद की अवस्था में बैठी मूर्ति से बातें कर रही थीं और मस्ती में गा रही थीं। राणा मीरा पर चिल्लाया  ’मीरा तुम जिस प्रेमी से अभी बातें कर रही हो उसे मेरे सामने लाओ।’ मीरा ने जवाब दिया – ‘वह सामने बैठा है  मेरा स्वामी  नैनचोर जिसने मेरा दिल चुराया है और वह समाधि में चली गईं। इस घटना से राणा कुंभा का दिल टूट गया लेकिन फिर भी उसने एक अच्छे पति की भूमिका निभाई और मरते दम तक मीरा का साथ दिया।  हालांकि मीरा को राजगद्दी की कोई चाह नहीं थी फिर भी राणा के संबंधी मीरा को कई तरीकों से सताने लगे। कृष्ण के प्रति मीरा का प्रेम शुरुआत में बेहद निजी था लेकिन बाद में कभीकभी मीरा के मन में प्रेमानंद इतना उमड़ पड़ता था कि वह आम लोगों के सामने और धार्मिक उत्सवों में नाचनेगाने लगती थीं। वे रात में चुपचाप चित्तौड़ के किले से निकल जाती थीं और नगर में चल रहे सत्संग में हिस्सा लेती थीं। मीरा का देवर विक्रमादित्य जो चित्तौड़गढ़ का नया राजा बना बहुत कठोर था। मीरा की भक्ति उनका आम लोगों के साथ घुलनामिलना और नारीमर्यादा के प्रति उनकी लापरवाही का उसने कड़ा विरोध किया। उसने मीरा को मारने की कई बार कोशिश की। यहां तक कि एक बार उसने मीरा के पास फूलों की टोकरी में एक जहरीला सांप रखकर भेजा और मीरा को संदेश भिजवाया कि टोकरी में फूलों के हार हैं। ध्यान से उठने के बाद जब मीरा ने टोकरी खोली तो उसमें से फूलों के हार के साथ कृष्ण की एक सुंदर मूर्ति निकली। राणा का तैयार किया हुआ कांटो का बिस्तर भी मीरा के लिए फूलों का सेज बन गया जब मीरा उस पर सोने चलीं। जब यातनाएं बरदाश्त से बाहर हो गईं तो उन्होंने चित्तौड़ छोड़ दिया। वे पहले मेड़ता गईं लेकिन जब उन्हें वहां भी संतोश नहीं मिला तो कुछ समय के बाद उन्होने कृश्णभक्ति के केंद्र वृंदावन का रुख कर लिया। मीरा मानती थीं कि वह गोपी ललिता ही हैं जिन्होने फिर से जन्म लिया है। ललिता कृष्ण के प्रेम में दीवानी थीं। खैर मीरा ने अपनी तीर्थयात्रा जारी रखी वे एक गांव से दूसरे गांव नाचतीगाती पूरे उत्तर भारत में घूमती रहीं। माना जाता है कि उन्होंने अपने जीवन के अंतिम कुछ साल गुजरात के द्वारका में गुजारे। ऐसा कहा जाता है कि दर्शकों की पूरी भीड़ के सामने मीरा द्वारकाधीश की मूर्ति में समा गईं। “इंसान आमतौर पर शरीर मन और बहुत सारी भावनाओं से बना है। यही वजह है कि ज्यादातर लोग अपने शरीर मन और भावनाओं को समर्पित किए बिना किसी चीज के प्रति खुद को समर्पित नहीं कर सकते। विवाह का मतलब यही है कि आप एक इंसान के लिए अपनी हर चीज समर्पित कर दें अपना शरीर अपना मन और अपनी भावनाएं। आज भी कई इसाई संप्रदायों में नन बनने की दीक्षा पाने के लिए लड़कियां पहले जीसस के साथ विवाह करती हैं। कुछ लोगों के लिए यह समर्पण शरीर मन और भावनाओं के परे एक ऐसे धरातल पर पहुंच गया जो बिलकुल अलग था जहां यह उनके लिए परम सत्य बन गया था। ऐसे लोगों में से एक मीराबाई थीं जो कृष्ण को अपना पति मानती थीं।  कृष्ण को लेकर मीरा इतनी दीवानी थीं कि महज आठ साल की उम्र में मन ही मन उन्होंने कृष्ण से विवाह कर लिया। उनके भावों की तीव्रता इतनी गहन थी कि कृष्ण उनके लिए सच्चाई बन गए। यह मीरा के लिए कोई मतिभ्रम नहीं था यह एक सच्चाई थी कि कृष्ण उनके साथ उठतेबैठते थे घूमते थे। ऐसे में मीरा के पति को उनके साथ दिक्कत होने लगी क्योंकि वह हमेशा अपने दिव्य प्रेमी के साथ रहतीं। यहां तक कि मीरा ने अपने दिव्य प्रेमी के साथ संभोग भी किया। उनके पति ने हर संभव कोशिश की यह सब समझने की क्योंकि वह मीरा को वाकई प्यार करता था। लेकिन वह नहीं जान सका कि आखिर मीरा के साथ हो क्या रहा है। दरअसल मीरा जिस स्थिति से गुजर रही थीं और उनके साथ जो भी हो रहा था वह बहुत वास्तविक लगता था लेकिन उनके पति को कुछ भी नजर नहीं आता था। वह इतना निराश हो गया कि एक दिन उसने खुद को नीले रंग से पोत लिया कृष्ण की तरह के पोशाक पहन कर मीरा के पास आया। दुर्भाग्य से उसने गलत तरह के रंग का इस्तेमाल कर लिया जिसकी वजह से उसे एलर्जी हो गई और शरीर पर चकत्ते निकल आए।  मीरा के इर्द गिर्द के लोग शुरुआत में बड़े चकराए कि आखिर मीरा का क्या करें। बाद में जब कृष्ण के प्रति मीरा का प्रेम अपनी चरम ऊंचाइयों तक पहुंच गया तब लोगों को यह समझ आया कि वे कोई असाधारण औरत हैं। लोग उनका आदर करने लगे। यह देख कर कि वे ऐसी चीजें कर सकती हैं जो कोई और नहीं कर सकता उनके आसपास भीड़ इकट्ठी होने लगी। पति के मरने के बाद मीरा पर व्यभिचार का आरोप लगाया गया। उन दिनों व्यभिचार के लिए मत्यु दंड दिया जाता था। इसलिए शाही दरबार में उन्हें जहर पीने को दिया गया। उन्होंने कृष्ण को याद किया और जहर पीकर वहां से चल दीं। लोग उनके मरने का इंतजार कर रहे थे लेकिन वह स्वस्थ्य और प्रसन्न बनी रहीं। इस तरह की कई घटनाएं हुईं। दरअसल भक्ति ऐसी चीज है जो व्यक्ति को खुद से भी खाली कर देती है। जब मैं भक्ति कहता हूं तो मैं किसी मत या धारणा में विश्वास की बात नहीं कर रहा हूं। मेरा मतलब पूरे भरोसे और आस्था के साथ आगे बढ़ने से है। तो सवाल उठता है कि मैं भरोसा कैसे करूं आप इस धरती पर आराम से बैठे हैं यह भी भरोसा ही है। यह गोल धरती बड़ी तेजी से अपनी धुरी पर और सूरज के चारों ओर घूम रही है। मान लीजिए अचानक यह धरती माता उल्टी दिशा में घूमने का फैसला कर लें तो हो सकता है कि आप जहां बैठे हैं वहां से छिटक कर कहीं और चले जाएं। आप नहीं जानते आप कहां पहुंचेंगे।  तो आप आराम से बैठें मुस्कराएं दूसरों से बातें करें इन सबके लिए आपको बहुत ज्यादा भरोसे की जरूरत है। लेकिन यह सब आप अनजाने में और बिना प्रेमभाव के कर रहे हैं। इस भरोसे को पूरी जागरुकता और प्रेम के साथ करना सीखिए। यही भक्ति है। यह सृष्टि जैसी है उस पर वैसे ही भरोसा करते हुए अगर आपने जागरुकता और प्रेम के साथ यहां बैठना सीख लिया तो यही भक्ति है। भक्ति कोई मत या मान्यता नहीं है। भक्ति इस अस्तित्व में होने का सबसे खूबसूरत तरीका है।” जीव गोसांई वृंदावन में वैष्णवसंप्रदाय के मुखिया थे। मीरा जीव गोसांई के दर्शन करना चाहती थीं लेकिन उन्होंने मीरा से मिलने से मना कर दिया। उन्होंने मीरा को संदेशा भिजवाया कि वह किसी औरत को अपने सामने आने की इजाजत नहीं देंगे। मीराबाई ने इसके जवाब में अपना संदेश भिजवाया कि ‘वृंदावन में हर कोई औरत है। अगर यहां कोई पुरुष है तो केवल गिरिधर गोपाल। आज मुझे पता चला कि वृंदावन में कृष्ण के अलावा कोई और पुरुष भी है।’  इस जबाब से जीव गोसाईं बहुत शर्मिंदा हुए। वह फौरन मीरा से मिलने गए और उन्हें भरपूर सम्मान दिया।  मीरा ने गुरु के बारे में कहा है कि बिना गुरु धारण किए भक्ति नहीं होती। भक्तिपूर्ण इंसान ही प्रभु प्राप्ति का भेद बता सकता है। वही सच्चा गुरु है। स्वयं मीरा के पद से पता चलता है कि उनके गुरु रैदास थे। मीरा ने अनेक पदों व गीतों की रचना की। उनके पदों में उच्च आध्यात्मिक अनुभव हैं। उनमें दिए गए संदेश और अन्य संतों की शिक्षाओं में समानता नजर आती है। उनके पद उनकी आध्यात्मिक उंचाई के अनुभवों का आईना है। मीरा ने अन्य संतों की तरह कई भाषाओं का प्रयोग किया है जैसे  हिंदी गुजराती ब्रज अवधी भोजपुरी अरबी फारसी मारवाड़ी संस्कृत मैथिली और पंजाबी।  मीरा के पदों में भावनाओं की मार्मिक अभिव्यक्ति के साथसाथ प्रेम की ओजस्वी प्रवाहधारा और प्रीतम से वियोग की पीड़ा का मर्मभेदी वर्णन मिलता है। प्रेम की साक्षात् मूर्ति मीरा के बराबर शायद ही कोई कवि हो। मेरे तो गिरिधर गोपाल दूसरो न कोई।  जाके सिर मोर मुकुट मेरो पति सोई।  छांड़ि दई कुल की कानि कहा करै कोई।  संतन ढिग बैठि बैठि लोक लाज खोई।  अंसुवन जल सींचि सींचि प्रेम बेलि बोई।  दधि मथि घृत काढ़ि लियौ डारि दई छोई।  भगत देखि राजी भई जगत देखि रोई।  दासी मीरा लाल गिरिधर तारो अब मोई।   पायो जी मैंने नाम रतन धन पायो।  बस्तु अमोलक दी म्हारे सतगुरु किरपा कर अपनायो।  जनम जनम की पूंजी पाई जग में सभी खोवायो।  खरचै नहिं कोई चोर न लेवै दिनदिन बढ़त सवायो।  सत की नाव खेवहिया सतगुरु भवसागर तर आयो।  मीरा के प्रभु गिरधर नागर हरखहरख जस पायो।।'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29eb8be",
   "metadata": {},
   "source": [
    "This code will create a list `append_start_token` where each element is a sentence with start and end tokens added to it, which is a useful step in text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024fe185",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_start_token = [sentence_start_token + ' ' + x + ' ' + sentence_end_token for x in sentences ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8167a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START मीराबाई के बालमन में कृष्ण की ऐसी छवि बसी थी कि किशोरावस्था से लेकर मृत्यु तक उन्होंने कृष्ण को ही अपना सब कुछ माना। END',\n",
       " 'START जोधपुर के राठौड़ रतनसिंह जी की इकलौती पुत्री मीराबाई का जन्म सोलहवीं शताब्दी में हुआ था। END',\n",
       " 'START बचपन से ही वह कृष्णभक्ति में रम गई थीं। END',\n",
       " 'START मीराबाई के बचपन में हुई एक घटना की वजह से उनका कृष्णप्रेम अपनी चरम अवस्था तक पहुंचा। END',\n",
       " 'START एक दिन उनके पड़ोस में किसी बड़े आदमी के यहां बारात आई। END',\n",
       " 'START सभी औरतें छत पर खड़ी होकर बारात देख रही थीं। END',\n",
       " 'START मीरा भी बारात देखने लगीं। END',\n",
       " 'START बारात को देख मीरा ने अपनी माता से पूछा कि मेरा दूल्हा कौन है इस पर उनकी माता ने कृष्ण की मूर्ति की ओर इशारा कर के कह दिया कि यही तुम्हारे दूल्हा हैं। END',\n",
       " 'START बस यह बात मीरा के बालमन में एक गांठ की तरह बंध गई। END',\n",
       " 'START बाद में मीराबाई की शादी महाराणा सांगा के पुत्र भोजराज जो आगे चलकर महाराणा कुंभा कहलाए से कर दी गई। END',\n",
       " 'START इस शादी के लिए पहले तो मीराबाई ने मना कर दिया लेकिन जोर देने पर वह फूटफूट कर रोने लगीं। END',\n",
       " 'START शादी के बाद विदाई के समय वे कृष्ण की वही मूर्ति अपने साथ ले गईं जिसे उनकी माता ने उनका दूल्हा बताया था। END',\n",
       " 'START ससुराल में अपने घरेलू कामकाज निबटाने के बाद मीरा रोज कृष्ण के मंदिर चली जातीं और कृष्ण की पूजा करतीं उनकी मूर्ति के सामने गातीं और नृत्य करतीं। END',\n",
       " 'START उनके ससुराल वाले तुलजा भवानी यानी दुर्गा को कुलदेवी मानते थे। END',\n",
       " 'START जब मीरा ने कुलदेवी की पूजा करने से इनकार कर दिया तो परिवार वालों ने उनकी श्रद्धाभक्ति को मंजूरी नहीं दी। END',\n",
       " 'START मीराबाई की ननद उदाबाई ने उन्हें बदनाम करने के लिए उनके खिलाफ एक साजिश रची। END',\n",
       " 'START उसने राणा से कहा कि मीरा का किसी के साथ गुप्त प्रेम है और उसने मीरा को मंदिर में अपने प्रेमी से बात करते देखा है। END',\n",
       " 'START राणा कुंभा अपनी बहन के साथ आधी रात को मंदिर गया। END',\n",
       " 'START वह मंदिर का दरवाजा तोड़ कर अंदर पहुंचा और देखा कि मीरा अकेले ही कृष्ण की मूर्ति के सामने परम आनंद की अवस्था में बैठी मूर्ति से बातें कर रही थीं और मस्ती में गा रही थीं। END',\n",
       " 'START राणा मीरा पर चिल्लाया  ’मीरा तुम जिस प्रेमी से अभी बातें कर रही हो उसे मेरे सामने लाओ। END',\n",
       " 'START ’ मीरा ने जवाब दिया – ‘वह सामने बैठा है  मेरा स्वामी  नैनचोर जिसने मेरा दिल चुराया है और वह समाधि में चली गईं। END',\n",
       " 'START इस घटना से राणा कुंभा का दिल टूट गया लेकिन फिर भी उसने एक अच्छे पति की भूमिका निभाई और मरते दम तक मीरा का साथ दिया। END',\n",
       " 'START हालांकि मीरा को राजगद्दी की कोई चाह नहीं थी फिर भी राणा के संबंधी मीरा को कई तरीकों से सताने लगे। END',\n",
       " 'START कृष्ण के प्रति मीरा का प्रेम शुरुआत में बेहद निजी था लेकिन बाद में कभीकभी मीरा के मन में प्रेमानंद इतना उमड़ पड़ता था कि वह आम लोगों के सामने और धार्मिक उत्सवों में नाचनेगाने लगती थीं। END',\n",
       " 'START वे रात में चुपचाप चित्तौड़ के किले से निकल जाती थीं और नगर में चल रहे सत्संग में हिस्सा लेती थीं। END',\n",
       " 'START मीरा का देवर विक्रमादित्य जो चित्तौड़गढ़ का नया राजा बना बहुत कठोर था। END',\n",
       " 'START मीरा की भक्ति उनका आम लोगों के साथ घुलनामिलना और नारीमर्यादा के प्रति उनकी लापरवाही का उसने कड़ा विरोध किया। END',\n",
       " 'START उसने मीरा को मारने की कई बार कोशिश की। END',\n",
       " 'START यहां तक कि एक बार उसने मीरा के पास फूलों की टोकरी में एक जहरीला सांप रखकर भेजा और मीरा को संदेश भिजवाया कि टोकरी में फूलों के हार हैं। END',\n",
       " 'START ध्यान से उठने के बाद जब मीरा ने टोकरी खोली तो उसमें से फूलों के हार के साथ कृष्ण की एक सुंदर मूर्ति निकली। END',\n",
       " 'START राणा का तैयार किया हुआ कांटो का बिस्तर भी मीरा के लिए फूलों का सेज बन गया जब मीरा उस पर सोने चलीं। END',\n",
       " 'START जब यातनाएं बरदाश्त से बाहर हो गईं तो उन्होंने चित्तौड़ छोड़ दिया। END',\n",
       " 'START वे पहले मेड़ता गईं लेकिन जब उन्हें वहां भी संतोश नहीं मिला तो कुछ समय के बाद उन्होने कृश्णभक्ति के केंद्र वृंदावन का रुख कर लिया। END',\n",
       " 'START मीरा मानती थीं कि वह गोपी ललिता ही हैं जिन्होने फिर से जन्म लिया है। END',\n",
       " 'START ललिता कृष्ण के प्रेम में दीवानी थीं। END',\n",
       " 'START खैर मीरा ने अपनी तीर्थयात्रा जारी रखी वे एक गांव से दूसरे गांव नाचतीगाती पूरे उत्तर भारत में घूमती रहीं। END',\n",
       " 'START माना जाता है कि उन्होंने अपने जीवन के अंतिम कुछ साल गुजरात के द्वारका में गुजारे। END',\n",
       " 'START ऐसा कहा जाता है कि दर्शकों की पूरी भीड़ के सामने मीरा द्वारकाधीश की मूर्ति में समा गईं। END',\n",
       " 'START “इंसान आमतौर पर शरीर मन और बहुत सारी भावनाओं से बना है। END',\n",
       " 'START यही वजह है कि ज्यादातर लोग अपने शरीर मन और भावनाओं को समर्पित किए बिना किसी चीज के प्रति खुद को समर्पित नहीं कर सकते। END',\n",
       " 'START विवाह का मतलब यही है कि आप एक इंसान के लिए अपनी हर चीज समर्पित कर दें अपना शरीर अपना मन और अपनी भावनाएं। END',\n",
       " 'START आज भी कई इसाई संप्रदायों में नन बनने की दीक्षा पाने के लिए लड़कियां पहले जीसस के साथ विवाह करती हैं। END',\n",
       " 'START कुछ लोगों के लिए यह समर्पण शरीर मन और भावनाओं के परे एक ऐसे धरातल पर पहुंच गया जो बिलकुल अलग था जहां यह उनके लिए परम सत्य बन गया था। END',\n",
       " 'START ऐसे लोगों में से एक मीराबाई थीं जो कृष्ण को अपना पति मानती थीं। END',\n",
       " 'START कृष्ण को लेकर मीरा इतनी दीवानी थीं कि महज आठ साल की उम्र में मन ही मन उन्होंने कृष्ण से विवाह कर लिया। END',\n",
       " 'START उनके भावों की तीव्रता इतनी गहन थी कि कृष्ण उनके लिए सच्चाई बन गए। END',\n",
       " 'START यह मीरा के लिए कोई मतिभ्रम नहीं था यह एक सच्चाई थी कि कृष्ण उनके साथ उठतेबैठते थे घूमते थे। END',\n",
       " 'START ऐसे में मीरा के पति को उनके साथ दिक्कत होने लगी क्योंकि वह हमेशा अपने दिव्य प्रेमी के साथ रहतीं। END',\n",
       " 'START यहां तक कि मीरा ने अपने दिव्य प्रेमी के साथ संभोग भी किया। END',\n",
       " 'START उनके पति ने हर संभव कोशिश की यह सब समझने की क्योंकि वह मीरा को वाकई प्यार करता था। END',\n",
       " 'START लेकिन वह नहीं जान सका कि आखिर मीरा के साथ हो क्या रहा है। END',\n",
       " 'START दरअसल मीरा जिस स्थिति से गुजर रही थीं और उनके साथ जो भी हो रहा था वह बहुत वास्तविक लगता था लेकिन उनके पति को कुछ भी नजर नहीं आता था। END',\n",
       " 'START वह इतना निराश हो गया कि एक दिन उसने खुद को नीले रंग से पोत लिया कृष्ण की तरह के पोशाक पहन कर मीरा के पास आया। END',\n",
       " 'START दुर्भाग्य से उसने गलत तरह के रंग का इस्तेमाल कर लिया जिसकी वजह से उसे एलर्जी हो गई और शरीर पर चकत्ते निकल आए। END',\n",
       " 'START मीरा के इर्द गिर्द के लोग शुरुआत में बड़े चकराए कि आखिर मीरा का क्या करें। END',\n",
       " 'START बाद में जब कृष्ण के प्रति मीरा का प्रेम अपनी चरम ऊंचाइयों तक पहुंच गया तब लोगों को यह समझ आया कि वे कोई असाधारण औरत हैं। END',\n",
       " 'START लोग उनका आदर करने लगे। END',\n",
       " 'START यह देख कर कि वे ऐसी चीजें कर सकती हैं जो कोई और नहीं कर सकता उनके आसपास भीड़ इकट्ठी होने लगी। END',\n",
       " 'START पति के मरने के बाद मीरा पर व्यभिचार का आरोप लगाया गया। END',\n",
       " 'START उन दिनों व्यभिचार के लिए मत्यु दंड दिया जाता था। END',\n",
       " 'START इसलिए शाही दरबार में उन्हें जहर पीने को दिया गया। END',\n",
       " 'START उन्होंने कृष्ण को याद किया और जहर पीकर वहां से चल दीं। END',\n",
       " 'START लोग उनके मरने का इंतजार कर रहे थे लेकिन वह स्वस्थ्य और प्रसन्न बनी रहीं। END',\n",
       " 'START इस तरह की कई घटनाएं हुईं। END',\n",
       " 'START दरअसल भक्ति ऐसी चीज है जो व्यक्ति को खुद से भी खाली कर देती है। END',\n",
       " 'START जब मैं भक्ति कहता हूं तो मैं किसी मत या धारणा में विश्वास की बात नहीं कर रहा हूं। END',\n",
       " 'START मेरा मतलब पूरे भरोसे और आस्था के साथ आगे बढ़ने से है। END',\n",
       " 'START तो सवाल उठता है कि मैं भरोसा कैसे करूं आप इस धरती पर आराम से बैठे हैं यह भी भरोसा ही है। END',\n",
       " 'START यह गोल धरती बड़ी तेजी से अपनी धुरी पर और सूरज के चारों ओर घूम रही है। END',\n",
       " 'START मान लीजिए अचानक यह धरती माता उल्टी दिशा में घूमने का फैसला कर लें तो हो सकता है कि आप जहां बैठे हैं वहां से छिटक कर कहीं और चले जाएं। END',\n",
       " 'START आप नहीं जानते आप कहां पहुंचेंगे। END',\n",
       " 'START तो आप आराम से बैठें मुस्कराएं दूसरों से बातें करें इन सबके लिए आपको बहुत ज्यादा भरोसे की जरूरत है। END',\n",
       " 'START लेकिन यह सब आप अनजाने में और बिना प्रेमभाव के कर रहे हैं। END',\n",
       " 'START इस भरोसे को पूरी जागरुकता और प्रेम के साथ करना सीखिए। END',\n",
       " 'START यही भक्ति है। END',\n",
       " 'START यह सृष्टि जैसी है उस पर वैसे ही भरोसा करते हुए अगर आपने जागरुकता और प्रेम के साथ यहां बैठना सीख लिया तो यही भक्ति है। END',\n",
       " 'START भक्ति कोई मत या मान्यता नहीं है। END',\n",
       " 'START भक्ति इस अस्तित्व में होने का सबसे खूबसूरत तरीका है। END',\n",
       " 'START ” जीव गोसांई वृंदावन में वैष्णवसंप्रदाय के मुखिया थे। END',\n",
       " 'START मीरा जीव गोसांई के दर्शन करना चाहती थीं लेकिन उन्होंने मीरा से मिलने से मना कर दिया। END',\n",
       " 'START उन्होंने मीरा को संदेशा भिजवाया कि वह किसी औरत को अपने सामने आने की इजाजत नहीं देंगे। END',\n",
       " 'START मीराबाई ने इसके जवाब में अपना संदेश भिजवाया कि ‘वृंदावन में हर कोई औरत है। END',\n",
       " 'START अगर यहां कोई पुरुष है तो केवल गिरिधर गोपाल। END',\n",
       " 'START आज मुझे पता चला कि वृंदावन में कृष्ण के अलावा कोई और पुरुष भी है। END',\n",
       " 'START ’  इस जबाब से जीव गोसाईं बहुत शर्मिंदा हुए। END',\n",
       " 'START वह फौरन मीरा से मिलने गए और उन्हें भरपूर सम्मान दिया। END',\n",
       " 'START मीरा ने गुरु के बारे में कहा है कि बिना गुरु धारण किए भक्ति नहीं होती। END',\n",
       " 'START भक्तिपूर्ण इंसान ही प्रभु प्राप्ति का भेद बता सकता है। END',\n",
       " 'START वही सच्चा गुरु है। END',\n",
       " 'START स्वयं मीरा के पद से पता चलता है कि उनके गुरु रैदास थे। END',\n",
       " 'START मीरा ने अनेक पदों व गीतों की रचना की। END',\n",
       " 'START उनके पदों में उच्च आध्यात्मिक अनुभव हैं। END',\n",
       " 'START उनमें दिए गए संदेश और अन्य संतों की शिक्षाओं में समानता नजर आती है। END',\n",
       " 'START उनके पद उनकी आध्यात्मिक उंचाई के अनुभवों का आईना है। END',\n",
       " 'START मीरा ने अन्य संतों की तरह कई भाषाओं का प्रयोग किया है जैसे  हिंदी गुजराती ब्रज अवधी भोजपुरी अरबी फारसी मारवाड़ी संस्कृत मैथिली और पंजाबी। END',\n",
       " 'START मीरा के पदों में भावनाओं की मार्मिक अभिव्यक्ति के साथसाथ प्रेम की ओजस्वी प्रवाहधारा और प्रीतम से वियोग की पीड़ा का मर्मभेदी वर्णन मिलता है। END',\n",
       " 'START प्रेम की साक्षात् मूर्ति मीरा के बराबर शायद ही कोई कवि हो। END',\n",
       " 'START मेरे तो गिरिधर गोपाल दूसरो न कोई। END',\n",
       " 'START जाके सिर मोर मुकुट मेरो पति सोई। END',\n",
       " 'START छांड़ि दई कुल की कानि कहा करै कोई। END',\n",
       " 'START संतन ढिग बैठि बैठि लोक लाज खोई। END',\n",
       " 'START अंसुवन जल सींचि सींचि प्रेम बेलि बोई। END',\n",
       " 'START दधि मथि घृत काढ़ि लियौ डारि दई छोई। END',\n",
       " 'START भगत देखि राजी भई जगत देखि रोई। END',\n",
       " 'START दासी मीरा लाल गिरिधर तारो अब मोई। END',\n",
       " 'START पायो जी मैंने नाम रतन धन पायो। END',\n",
       " 'START बस्तु अमोलक दी म्हारे सतगुरु किरपा कर अपनायो। END',\n",
       " 'START जनम जनम की पूंजी पाई जग में सभी खोवायो। END',\n",
       " 'START खरचै नहिं कोई चोर न लेवै दिनदिन बढ़त सवायो। END',\n",
       " 'START सत की नाव खेवहिया सतगुरु भवसागर तर आयो। END',\n",
       " 'START मीरा के प्रभु गिरधर नागर हरखहरख जस पायो। END',\n",
       " 'START । END']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_start_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec7399",
   "metadata": {},
   "source": [
    "This code will tokenize each sentence in the `append_start_token` list into words and print the resulting word tokens for each sentence. This is a common step in natural language processing for breaking down text into its constituent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a800d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START', 'मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक', 'उन्होंने', 'कृष्ण', 'को', 'ही', 'अपना', 'सब', 'कुछ', 'माना', '।', 'END']\n",
      "['START', 'जोधपुर', 'के', 'राठौड़', 'रतनसिंह', 'जी', 'की', 'इकलौती', 'पुत्री', 'मीराबाई', 'का', 'जन्म', 'सोलहवीं', 'शताब्दी', 'में', 'हुआ', 'था', '।', 'END']\n",
      "['START', 'बचपन', 'से', 'ही', 'वह', 'कृष्णभक्ति', 'में', 'रम', 'गई', 'थीं', '।', 'END']\n",
      "['START', 'मीराबाई', 'के', 'बचपन', 'में', 'हुई', 'एक', 'घटना', 'की', 'वजह', 'से', 'उनका', 'कृष्णप्रेम', 'अपनी', 'चरम', 'अवस्था', 'तक', 'पहुंचा', '।', 'END']\n",
      "['START', 'एक', 'दिन', 'उनके', 'पड़ोस', 'में', 'किसी', 'बड़े', 'आदमी', 'के', 'यहां', 'बारात', 'आई', '।', 'END']\n",
      "['START', 'सभी', 'औरतें', 'छत', 'पर', 'खड़ी', 'होकर', 'बारात', 'देख', 'रही', 'थीं', '।', 'END']\n",
      "['START', 'मीरा', 'भी', 'बारात', 'देखने', 'लगीं', '।', 'END']\n",
      "['START', 'बारात', 'को', 'देख', 'मीरा', 'ने', 'अपनी', 'माता', 'से', 'पूछा', 'कि', 'मेरा', 'दूल्हा', 'कौन', 'है', 'इस', 'पर', 'उनकी', 'माता', 'ने', 'कृष्ण', 'की', 'मूर्ति', 'की', 'ओर', 'इशारा', 'कर', 'के', 'कह', 'दिया', 'कि', 'यही', 'तुम्हारे', 'दूल्हा', 'हैं', '।', 'END']\n",
      "['START', 'बस', 'यह', 'बात', 'मीरा', 'के', 'बालमन', 'में', 'एक', 'गांठ', 'की', 'तरह', 'बंध', 'गई', '।', 'END']\n",
      "['START', 'बाद', 'में', 'मीराबाई', 'की', 'शादी', 'महाराणा', 'सांगा', 'के', 'पुत्र', 'भोजराज', 'जो', 'आगे', 'चलकर', 'महाराणा', 'कुंभा', 'कहलाए', 'से', 'कर', 'दी', 'गई', '।', 'END']\n",
      "['START', 'इस', 'शादी', 'के', 'लिए', 'पहले', 'तो', 'मीराबाई', 'ने', 'मना', 'कर', 'दिया', 'लेकिन', 'जोर', 'देने', 'पर', 'वह', 'फूटफूट', 'कर', 'रोने', 'लगीं', '।', 'END']\n",
      "['START', 'शादी', 'के', 'बाद', 'विदाई', 'के', 'समय', 'वे', 'कृष्ण', 'की', 'वही', 'मूर्ति', 'अपने', 'साथ', 'ले', 'गईं', 'जिसे', 'उनकी', 'माता', 'ने', 'उनका', 'दूल्हा', 'बताया', 'था', '।', 'END']\n",
      "['START', 'ससुराल', 'में', 'अपने', 'घरेलू', 'कामकाज', 'निबटाने', 'के', 'बाद', 'मीरा', 'रोज', 'कृष्ण', 'के', 'मंदिर', 'चली', 'जातीं', 'और', 'कृष्ण', 'की', 'पूजा', 'करतीं', 'उनकी', 'मूर्ति', 'के', 'सामने', 'गातीं', 'और', 'नृत्य', 'करतीं', '।', 'END']\n",
      "['START', 'उनके', 'ससुराल', 'वाले', 'तुलजा', 'भवानी', 'यानी', 'दुर्गा', 'को', 'कुलदेवी', 'मानते', 'थे', '।', 'END']\n",
      "['START', 'जब', 'मीरा', 'ने', 'कुलदेवी', 'की', 'पूजा', 'करने', 'से', 'इनकार', 'कर', 'दिया', 'तो', 'परिवार', 'वालों', 'ने', 'उनकी', 'श्रद्धाभक्ति', 'को', 'मंजूरी', 'नहीं', 'दी', '।', 'END']\n",
      "['START', 'मीराबाई', 'की', 'ननद', 'उदाबाई', 'ने', 'उन्हें', 'बदनाम', 'करने', 'के', 'लिए', 'उनके', 'खिलाफ', 'एक', 'साजिश', 'रची', '।', 'END']\n",
      "['START', 'उसने', 'राणा', 'से', 'कहा', 'कि', 'मीरा', 'का', 'किसी', 'के', 'साथ', 'गुप्त', 'प्रेम', 'है', 'और', 'उसने', 'मीरा', 'को', 'मंदिर', 'में', 'अपने', 'प्रेमी', 'से', 'बात', 'करते', 'देखा', 'है', '।', 'END']\n",
      "['START', 'राणा', 'कुंभा', 'अपनी', 'बहन', 'के', 'साथ', 'आधी', 'रात', 'को', 'मंदिर', 'गया', '।', 'END']\n",
      "['START', 'वह', 'मंदिर', 'का', 'दरवाजा', 'तोड़', 'कर', 'अंदर', 'पहुंचा', 'और', 'देखा', 'कि', 'मीरा', 'अकेले', 'ही', 'कृष्ण', 'की', 'मूर्ति', 'के', 'सामने', 'परम', 'आनंद', 'की', 'अवस्था', 'में', 'बैठी', 'मूर्ति', 'से', 'बातें', 'कर', 'रही', 'थीं', 'और', 'मस्ती', 'में', 'गा', 'रही', 'थीं', '।', 'END']\n",
      "['START', 'राणा', 'मीरा', 'पर', 'चिल्लाया', '’मीरा', 'तुम', 'जिस', 'प्रेमी', 'से', 'अभी', 'बातें', 'कर', 'रही', 'हो', 'उसे', 'मेरे', 'सामने', 'लाओ', '।', 'END']\n",
      "['START', '’', 'मीरा', 'ने', 'जवाब', 'दिया', '–', '‘वह', 'सामने', 'बैठा', 'है', 'मेरा', 'स्वामी', 'नैनचोर', 'जिसने', 'मेरा', 'दिल', 'चुराया', 'है', 'और', 'वह', 'समाधि', 'में', 'चली', 'गईं', '।', 'END']\n",
      "['START', 'इस', 'घटना', 'से', 'राणा', 'कुंभा', 'का', 'दिल', 'टूट', 'गया', 'लेकिन', 'फिर', 'भी', 'उसने', 'एक', 'अच्छे', 'पति', 'की', 'भूमिका', 'निभाई', 'और', 'मरते', 'दम', 'तक', 'मीरा', 'का', 'साथ', 'दिया', '।', 'END']\n",
      "['START', 'हालांकि', 'मीरा', 'को', 'राजगद्दी', 'की', 'कोई', 'चाह', 'नहीं', 'थी', 'फिर', 'भी', 'राणा', 'के', 'संबंधी', 'मीरा', 'को', 'कई', 'तरीकों', 'से', 'सताने', 'लगे', '।', 'END']\n",
      "['START', 'कृष्ण', 'के', 'प्रति', 'मीरा', 'का', 'प्रेम', 'शुरुआत', 'में', 'बेहद', 'निजी', 'था', 'लेकिन', 'बाद', 'में', 'कभीकभी', 'मीरा', 'के', 'मन', 'में', 'प्रेमानंद', 'इतना', 'उमड़', 'पड़ता', 'था', 'कि', 'वह', 'आम', 'लोगों', 'के', 'सामने', 'और', 'धार्मिक', 'उत्सवों', 'में', 'नाचनेगाने', 'लगती', 'थीं', '।', 'END']\n",
      "['START', 'वे', 'रात', 'में', 'चुपचाप', 'चित्तौड़', 'के', 'किले', 'से', 'निकल', 'जाती', 'थीं', 'और', 'नगर', 'में', 'चल', 'रहे', 'सत्संग', 'में', 'हिस्सा', 'लेती', 'थीं', '।', 'END']\n",
      "['START', 'मीरा', 'का', 'देवर', 'विक्रमादित्य', 'जो', 'चित्तौड़गढ़', 'का', 'नया', 'राजा', 'बना', 'बहुत', 'कठोर', 'था', '।', 'END']\n",
      "['START', 'मीरा', 'की', 'भक्ति', 'उनका', 'आम', 'लोगों', 'के', 'साथ', 'घुलनामिलना', 'और', 'नारीमर्यादा', 'के', 'प्रति', 'उनकी', 'लापरवाही', 'का', 'उसने', 'कड़ा', 'विरोध', 'किया', '।', 'END']\n",
      "['START', 'उसने', 'मीरा', 'को', 'मारने', 'की', 'कई', 'बार', 'कोशिश', 'की', '।', 'END']\n",
      "['START', 'यहां', 'तक', 'कि', 'एक', 'बार', 'उसने', 'मीरा', 'के', 'पास', 'फूलों', 'की', 'टोकरी', 'में', 'एक', 'जहरीला', 'सांप', 'रखकर', 'भेजा', 'और', 'मीरा', 'को', 'संदेश', 'भिजवाया', 'कि', 'टोकरी', 'में', 'फूलों', 'के', 'हार', 'हैं', '।', 'END']\n",
      "['START', 'ध्यान', 'से', 'उठने', 'के', 'बाद', 'जब', 'मीरा', 'ने', 'टोकरी', 'खोली', 'तो', 'उसमें', 'से', 'फूलों', 'के', 'हार', 'के', 'साथ', 'कृष्ण', 'की', 'एक', 'सुंदर', 'मूर्ति', 'निकली', '।', 'END']\n",
      "['START', 'राणा', 'का', 'तैयार', 'किया', 'हुआ', 'कांटो', 'का', 'बिस्तर', 'भी', 'मीरा', 'के', 'लिए', 'फूलों', 'का', 'सेज', 'बन', 'गया', 'जब', 'मीरा', 'उस', 'पर', 'सोने', 'चलीं', '।', 'END']\n",
      "['START', 'जब', 'यातनाएं', 'बरदाश्त', 'से', 'बाहर', 'हो', 'गईं', 'तो', 'उन्होंने', 'चित्तौड़', 'छोड़', 'दिया', '।', 'END']\n",
      "['START', 'वे', 'पहले', 'मेड़ता', 'गईं', 'लेकिन', 'जब', 'उन्हें', 'वहां', 'भी', 'संतोश', 'नहीं', 'मिला', 'तो', 'कुछ', 'समय', 'के', 'बाद', 'उन्होने', 'कृश्णभक्ति', 'के', 'केंद्र', 'वृंदावन', 'का', 'रुख', 'कर', 'लिया', '।', 'END']\n",
      "['START', 'मीरा', 'मानती', 'थीं', 'कि', 'वह', 'गोपी', 'ललिता', 'ही', 'हैं', 'जिन्होने', 'फिर', 'से', 'जन्म', 'लिया', 'है', '।', 'END']\n",
      "['START', 'ललिता', 'कृष्ण', 'के', 'प्रेम', 'में', 'दीवानी', 'थीं', '।', 'END']\n",
      "['START', 'खैर', 'मीरा', 'ने', 'अपनी', 'तीर्थयात्रा', 'जारी', 'रखी', 'वे', 'एक', 'गांव', 'से', 'दूसरे', 'गांव', 'नाचतीगाती', 'पूरे', 'उत्तर', 'भारत', 'में', 'घूमती', 'रहीं', '।', 'END']\n",
      "['START', 'माना', 'जाता', 'है', 'कि', 'उन्होंने', 'अपने', 'जीवन', 'के', 'अंतिम', 'कुछ', 'साल', 'गुजरात', 'के', 'द्वारका', 'में', 'गुजारे', '।', 'END']\n",
      "['START', 'ऐसा', 'कहा', 'जाता', 'है', 'कि', 'दर्शकों', 'की', 'पूरी', 'भीड़', 'के', 'सामने', 'मीरा', 'द्वारकाधीश', 'की', 'मूर्ति', 'में', 'समा', 'गईं', '।', 'END']\n",
      "['START', '“इंसान', 'आमतौर', 'पर', 'शरीर', 'मन', 'और', 'बहुत', 'सारी', 'भावनाओं', 'से', 'बना', 'है', '।', 'END']\n",
      "['START', 'यही', 'वजह', 'है', 'कि', 'ज्यादातर', 'लोग', 'अपने', 'शरीर', 'मन', 'और', 'भावनाओं', 'को', 'समर्पित', 'किए', 'बिना', 'किसी', 'चीज', 'के', 'प्रति', 'खुद', 'को', 'समर्पित', 'नहीं', 'कर', 'सकते', '।', 'END']\n",
      "['START', 'विवाह', 'का', 'मतलब', 'यही', 'है', 'कि', 'आप', 'एक', 'इंसान', 'के', 'लिए', 'अपनी', 'हर', 'चीज', 'समर्पित', 'कर', 'दें', 'अपना', 'शरीर', 'अपना', 'मन', 'और', 'अपनी', 'भावनाएं', '।', 'END']\n",
      "['START', 'आज', 'भी', 'कई', 'इसाई', 'संप्रदायों', 'में', 'नन', 'बनने', 'की', 'दीक्षा', 'पाने', 'के', 'लिए', 'लड़कियां', 'पहले', 'जीसस', 'के', 'साथ', 'विवाह', 'करती', 'हैं', '।', 'END']\n",
      "['START', 'कुछ', 'लोगों', 'के', 'लिए', 'यह', 'समर्पण', 'शरीर', 'मन', 'और', 'भावनाओं', 'के', 'परे', 'एक', 'ऐसे', 'धरातल', 'पर', 'पहुंच', 'गया', 'जो', 'बिलकुल', 'अलग', 'था', 'जहां', 'यह', 'उनके', 'लिए', 'परम', 'सत्य', 'बन', 'गया', 'था', '।', 'END']\n",
      "['START', 'ऐसे', 'लोगों', 'में', 'से', 'एक', 'मीराबाई', 'थीं', 'जो', 'कृष्ण', 'को', 'अपना', 'पति', 'मानती', 'थीं', '।', 'END']\n",
      "['START', 'कृष्ण', 'को', 'लेकर', 'मीरा', 'इतनी', 'दीवानी', 'थीं', 'कि', 'महज', 'आठ', 'साल', 'की', 'उम्र', 'में', 'मन', 'ही', 'मन', 'उन्होंने', 'कृष्ण', 'से', 'विवाह', 'कर', 'लिया', '।', 'END']\n",
      "['START', 'उनके', 'भावों', 'की', 'तीव्रता', 'इतनी', 'गहन', 'थी', 'कि', 'कृष्ण', 'उनके', 'लिए', 'सच्चाई', 'बन', 'गए', '।', 'END']\n",
      "['START', 'यह', 'मीरा', 'के', 'लिए', 'कोई', 'मतिभ्रम', 'नहीं', 'था', 'यह', 'एक', 'सच्चाई', 'थी', 'कि', 'कृष्ण', 'उनके', 'साथ', 'उठतेबैठते', 'थे', 'घूमते', 'थे', '।', 'END']\n",
      "['START', 'ऐसे', 'में', 'मीरा', 'के', 'पति', 'को', 'उनके', 'साथ', 'दिक्कत', 'होने', 'लगी', 'क्योंकि', 'वह', 'हमेशा', 'अपने', 'दिव्य', 'प्रेमी', 'के', 'साथ', 'रहतीं', '।', 'END']\n",
      "['START', 'यहां', 'तक', 'कि', 'मीरा', 'ने', 'अपने', 'दिव्य', 'प्रेमी', 'के', 'साथ', 'संभोग', 'भी', 'किया', '।', 'END']\n",
      "['START', 'उनके', 'पति', 'ने', 'हर', 'संभव', 'कोशिश', 'की', 'यह', 'सब', 'समझने', 'की', 'क्योंकि', 'वह', 'मीरा', 'को', 'वाकई', 'प्यार', 'करता', 'था', '।', 'END']\n",
      "['START', 'लेकिन', 'वह', 'नहीं', 'जान', 'सका', 'कि', 'आखिर', 'मीरा', 'के', 'साथ', 'हो', 'क्या', 'रहा', 'है', '।', 'END']\n",
      "['START', 'दरअसल', 'मीरा', 'जिस', 'स्थिति', 'से', 'गुजर', 'रही', 'थीं', 'और', 'उनके', 'साथ', 'जो', 'भी', 'हो', 'रहा', 'था', 'वह', 'बहुत', 'वास्तविक', 'लगता', 'था', 'लेकिन', 'उनके', 'पति', 'को', 'कुछ', 'भी', 'नजर', 'नहीं', 'आता', 'था', '।', 'END']\n",
      "['START', 'वह', 'इतना', 'निराश', 'हो', 'गया', 'कि', 'एक', 'दिन', 'उसने', 'खुद', 'को', 'नीले', 'रंग', 'से', 'पोत', 'लिया', 'कृष्ण', 'की', 'तरह', 'के', 'पोशाक', 'पहन', 'कर', 'मीरा', 'के', 'पास', 'आया', '।', 'END']\n",
      "['START', 'दुर्भाग्य', 'से', 'उसने', 'गलत', 'तरह', 'के', 'रंग', 'का', 'इस्तेमाल', 'कर', 'लिया', 'जिसकी', 'वजह', 'से', 'उसे', 'एलर्जी', 'हो', 'गई', 'और', 'शरीर', 'पर', 'चकत्ते', 'निकल', 'आए', '।', 'END']\n",
      "['START', 'मीरा', 'के', 'इर्द', 'गिर्द', 'के', 'लोग', 'शुरुआत', 'में', 'बड़े', 'चकराए', 'कि', 'आखिर', 'मीरा', 'का', 'क्या', 'करें', '।', 'END']\n",
      "['START', 'बाद', 'में', 'जब', 'कृष्ण', 'के', 'प्रति', 'मीरा', 'का', 'प्रेम', 'अपनी', 'चरम', 'ऊंचाइयों', 'तक', 'पहुंच', 'गया', 'तब', 'लोगों', 'को', 'यह', 'समझ', 'आया', 'कि', 'वे', 'कोई', 'असाधारण', 'औरत', 'हैं', '।', 'END']\n",
      "['START', 'लोग', 'उनका', 'आदर', 'करने', 'लगे', '।', 'END']\n",
      "['START', 'यह', 'देख', 'कर', 'कि', 'वे', 'ऐसी', 'चीजें', 'कर', 'सकती', 'हैं', 'जो', 'कोई', 'और', 'नहीं', 'कर', 'सकता', 'उनके', 'आसपास', 'भीड़', 'इकट्ठी', 'होने', 'लगी', '।', 'END']\n",
      "['START', 'पति', 'के', 'मरने', 'के', 'बाद', 'मीरा', 'पर', 'व्यभिचार', 'का', 'आरोप', 'लगाया', 'गया', '।', 'END']\n",
      "['START', 'उन', 'दिनों', 'व्यभिचार', 'के', 'लिए', 'मत्यु', 'दंड', 'दिया', 'जाता', 'था', '।', 'END']\n",
      "['START', 'इसलिए', 'शाही', 'दरबार', 'में', 'उन्हें', 'जहर', 'पीने', 'को', 'दिया', 'गया', '।', 'END']\n",
      "['START', 'उन्होंने', 'कृष्ण', 'को', 'याद', 'किया', 'और', 'जहर', 'पीकर', 'वहां', 'से', 'चल', 'दीं', '।', 'END']\n",
      "['START', 'लोग', 'उनके', 'मरने', 'का', 'इंतजार', 'कर', 'रहे', 'थे', 'लेकिन', 'वह', 'स्वस्थ्य', 'और', 'प्रसन्न', 'बनी', 'रहीं', '।', 'END']\n",
      "['START', 'इस', 'तरह', 'की', 'कई', 'घटनाएं', 'हुईं', '।', 'END']\n",
      "['START', 'दरअसल', 'भक्ति', 'ऐसी', 'चीज', 'है', 'जो', 'व्यक्ति', 'को', 'खुद', 'से', 'भी', 'खाली', 'कर', 'देती', 'है', '।', 'END']\n",
      "['START', 'जब', 'मैं', 'भक्ति', 'कहता', 'हूं', 'तो', 'मैं', 'किसी', 'मत', 'या', 'धारणा', 'में', 'विश्वास', 'की', 'बात', 'नहीं', 'कर', 'रहा', 'हूं', '।', 'END']\n",
      "['START', 'मेरा', 'मतलब', 'पूरे', 'भरोसे', 'और', 'आस्था', 'के', 'साथ', 'आगे', 'बढ़ने', 'से', 'है', '।', 'END']\n",
      "['START', 'तो', 'सवाल', 'उठता', 'है', 'कि', 'मैं', 'भरोसा', 'कैसे', 'करूं', 'आप', 'इस', 'धरती', 'पर', 'आराम', 'से', 'बैठे', 'हैं', 'यह', 'भी', 'भरोसा', 'ही', 'है', '।', 'END']\n",
      "['START', 'यह', 'गोल', 'धरती', 'बड़ी', 'तेजी', 'से', 'अपनी', 'धुरी', 'पर', 'और', 'सूरज', 'के', 'चारों', 'ओर', 'घूम', 'रही', 'है', '।', 'END']\n",
      "['START', 'मान', 'लीजिए', 'अचानक', 'यह', 'धरती', 'माता', 'उल्टी', 'दिशा', 'में', 'घूमने', 'का', 'फैसला', 'कर', 'लें', 'तो', 'हो', 'सकता', 'है', 'कि', 'आप', 'जहां', 'बैठे', 'हैं', 'वहां', 'से', 'छिटक', 'कर', 'कहीं', 'और', 'चले', 'जाएं', '।', 'END']\n",
      "['START', 'आप', 'नहीं', 'जानते', 'आप', 'कहां', 'पहुंचेंगे', '।', 'END']\n",
      "['START', 'तो', 'आप', 'आराम', 'से', 'बैठें', 'मुस्कराएं', 'दूसरों', 'से', 'बातें', 'करें', 'इन', 'सबके', 'लिए', 'आपको', 'बहुत', 'ज्यादा', 'भरोसे', 'की', 'जरूरत', 'है', '।', 'END']\n",
      "['START', 'लेकिन', 'यह', 'सब', 'आप', 'अनजाने', 'में', 'और', 'बिना', 'प्रेमभाव', 'के', 'कर', 'रहे', 'हैं', '।', 'END']\n",
      "['START', 'इस', 'भरोसे', 'को', 'पूरी', 'जागरुकता', 'और', 'प्रेम', 'के', 'साथ', 'करना', 'सीखिए', '।', 'END']\n",
      "['START', 'यही', 'भक्ति', 'है', '।', 'END']\n",
      "['START', 'यह', 'सृष्टि', 'जैसी', 'है', 'उस', 'पर', 'वैसे', 'ही', 'भरोसा', 'करते', 'हुए', 'अगर', 'आपने', 'जागरुकता', 'और', 'प्रेम', 'के', 'साथ', 'यहां', 'बैठना', 'सीख', 'लिया', 'तो', 'यही', 'भक्ति', 'है', '।', 'END']\n",
      "['START', 'भक्ति', 'कोई', 'मत', 'या', 'मान्यता', 'नहीं', 'है', '।', 'END']\n",
      "['START', 'भक्ति', 'इस', 'अस्तित्व', 'में', 'होने', 'का', 'सबसे', 'खूबसूरत', 'तरीका', 'है', '।', 'END']\n",
      "['START', '”', 'जीव', 'गोसांई', 'वृंदावन', 'में', 'वैष्णवसंप्रदाय', 'के', 'मुखिया', 'थे', '।', 'END']\n",
      "['START', 'मीरा', 'जीव', 'गोसांई', 'के', 'दर्शन', 'करना', 'चाहती', 'थीं', 'लेकिन', 'उन्होंने', 'मीरा', 'से', 'मिलने', 'से', 'मना', 'कर', 'दिया', '।', 'END']\n",
      "['START', 'उन्होंने', 'मीरा', 'को', 'संदेशा', 'भिजवाया', 'कि', 'वह', 'किसी', 'औरत', 'को', 'अपने', 'सामने', 'आने', 'की', 'इजाजत', 'नहीं', 'देंगे', '।', 'END']\n",
      "['START', 'मीराबाई', 'ने', 'इसके', 'जवाब', 'में', 'अपना', 'संदेश', 'भिजवाया', 'कि', '‘वृंदावन', 'में', 'हर', 'कोई', 'औरत', 'है', '।', 'END']\n",
      "['START', 'अगर', 'यहां', 'कोई', 'पुरुष', 'है', 'तो', 'केवल', 'गिरिधर', 'गोपाल', '।', 'END']\n",
      "['START', 'आज', 'मुझे', 'पता', 'चला', 'कि', 'वृंदावन', 'में', 'कृष्ण', 'के', 'अलावा', 'कोई', 'और', 'पुरुष', 'भी', 'है', '।', 'END']\n",
      "['START', '’', 'इस', 'जबाब', 'से', 'जीव', 'गोसाईं', 'बहुत', 'शर्मिंदा', 'हुए', '।', 'END']\n",
      "['START', 'वह', 'फौरन', 'मीरा', 'से', 'मिलने', 'गए', 'और', 'उन्हें', 'भरपूर', 'सम्मान', 'दिया', '।', 'END']\n",
      "['START', 'मीरा', 'ने', 'गुरु', 'के', 'बारे', 'में', 'कहा', 'है', 'कि', 'बिना', 'गुरु', 'धारण', 'किए', 'भक्ति', 'नहीं', 'होती', '।', 'END']\n",
      "['START', 'भक्तिपूर्ण', 'इंसान', 'ही', 'प्रभु', 'प्राप्ति', 'का', 'भेद', 'बता', 'सकता', 'है', '।', 'END']\n",
      "['START', 'वही', 'सच्चा', 'गुरु', 'है', '।', 'END']\n",
      "['START', 'स्वयं', 'मीरा', 'के', 'पद', 'से', 'पता', 'चलता', 'है', 'कि', 'उनके', 'गुरु', 'रैदास', 'थे', '।', 'END']\n",
      "['START', 'मीरा', 'ने', 'अनेक', 'पदों', 'व', 'गीतों', 'की', 'रचना', 'की', '।', 'END']\n",
      "['START', 'उनके', 'पदों', 'में', 'उच्च', 'आध्यात्मिक', 'अनुभव', 'हैं', '।', 'END']\n",
      "['START', 'उनमें', 'दिए', 'गए', 'संदेश', 'और', 'अन्य', 'संतों', 'की', 'शिक्षाओं', 'में', 'समानता', 'नजर', 'आती', 'है', '।', 'END']\n",
      "['START', 'उनके', 'पद', 'उनकी', 'आध्यात्मिक', 'उंचाई', 'के', 'अनुभवों', 'का', 'आईना', 'है', '।', 'END']\n",
      "['START', 'मीरा', 'ने', 'अन्य', 'संतों', 'की', 'तरह', 'कई', 'भाषाओं', 'का', 'प्रयोग', 'किया', 'है', 'जैसे', 'हिंदी', 'गुजराती', 'ब्रज', 'अवधी', 'भोजपुरी', 'अरबी', 'फारसी', 'मारवाड़ी', 'संस्कृत', 'मैथिली', 'और', 'पंजाबी', '।', 'END']\n",
      "['START', 'मीरा', 'के', 'पदों', 'में', 'भावनाओं', 'की', 'मार्मिक', 'अभिव्यक्ति', 'के', 'साथसाथ', 'प्रेम', 'की', 'ओजस्वी', 'प्रवाहधारा', 'और', 'प्रीतम', 'से', 'वियोग', 'की', 'पीड़ा', 'का', 'मर्मभेदी', 'वर्णन', 'मिलता', 'है', '।', 'END']\n",
      "['START', 'प्रेम', 'की', 'साक्षात्', 'मूर्ति', 'मीरा', 'के', 'बराबर', 'शायद', 'ही', 'कोई', 'कवि', 'हो', '।', 'END']\n",
      "['START', 'मेरे', 'तो', 'गिरिधर', 'गोपाल', 'दूसरो', 'न', 'कोई', '।', 'END']\n",
      "['START', 'जाके', 'सिर', 'मोर', 'मुकुट', 'मेरो', 'पति', 'सोई', '।', 'END']\n",
      "['START', 'छांड़ि', 'दई', 'कुल', 'की', 'कानि', 'कहा', 'करै', 'कोई', '।', 'END']\n",
      "['START', 'संतन', 'ढिग', 'बैठि', 'बैठि', 'लोक', 'लाज', 'खोई', '।', 'END']\n",
      "['START', 'अंसुवन', 'जल', 'सींचि', 'सींचि', 'प्रेम', 'बेलि', 'बोई', '।', 'END']\n",
      "['START', 'दधि', 'मथि', 'घृत', 'काढ़ि', 'लियौ', 'डारि', 'दई', 'छोई', '।', 'END']\n",
      "['START', 'भगत', 'देखि', 'राजी', 'भई', 'जगत', 'देखि', 'रोई', '।', 'END']\n",
      "['START', 'दासी', 'मीरा', 'लाल', 'गिरिधर', 'तारो', 'अब', 'मोई', '।', 'END']\n",
      "['START', 'पायो', 'जी', 'मैंने', 'नाम', 'रतन', 'धन', 'पायो', '।', 'END']\n",
      "['START', 'बस्तु', 'अमोलक', 'दी', 'म्हारे', 'सतगुरु', 'किरपा', 'कर', 'अपनायो', '।', 'END']\n",
      "['START', 'जनम', 'जनम', 'की', 'पूंजी', 'पाई', 'जग', 'में', 'सभी', 'खोवायो', '।', 'END']\n",
      "['START', 'खरचै', 'नहिं', 'कोई', 'चोर', 'न', 'लेवै', 'दिनदिन', 'बढ़त', 'सवायो', '।', 'END']\n",
      "['START', 'सत', 'की', 'नाव', 'खेवहिया', 'सतगुरु', 'भवसागर', 'तर', 'आयो', '।', 'END']\n",
      "['START', 'मीरा', 'के', 'प्रभु', 'गिरधर', 'नागर', 'हरखहरख', 'जस', 'पायो', '।', 'END']\n",
      "['START', '।', 'END']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each sentence into words\n",
    "tokenized_conversation = [indic_tokenize.trivial_tokenize(sentence) for sentence in append_start_token]\n",
    "\n",
    "# Print the tokenized conversation\n",
    "for sentence in tokenized_conversation:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be76023",
   "metadata": {},
   "source": [
    "This code will give a count of how many unique word tokens are present in the text data. The result will be printed as \"Found X unique word tokens,\" where X is the count of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bed1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 699 unique word tokens.\n"
     ]
    }
   ],
   "source": [
    "# Count the word frequencies\n",
    "from collections import Counter\n",
    "word_freq = Counter(word for sent in tokenized_conversation for word in sent)\n",
    "print(\"Found %d unique word tokens.\" % len(word_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f912d",
   "metadata": {},
   "source": [
    "This code is building index-to-word and word-to-index mappings, as we are preparing the most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c398266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least frequent word in our vocabulary is 'जस' and appeared 1 times.\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocabulary_size = len(word_freq)\n",
    "index_to_word = list(word_freq.keys())\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = {w: i for i, w in enumerate(index_to_word)}\n",
    "print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % word_freq.most_common()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21223367",
   "metadata": {},
   "source": [
    "This code iterates through each tokenized sentence and replaces words that are not in the vocabulary with the `\"unknown_token\"`. It then prints the vocabulary size and shows an example sentence before and after this preprocessing step. This ensures that all words in the text data are represented within our predefined vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7011126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 699.\n",
      "\n",
      "Example sentence: 'मीराबाई के बालमन में कृष्ण की ऐसी छवि बसी थी कि किशोरावस्था से लेकर मृत्यु तक उन्होंने कृष्ण को ही अपना सब कुछ माना।'\n",
      "\n",
      "Example sentence after pre-processing: '['START', 'मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक', 'उन्होंने', 'कृष्ण', 'को', 'ही', 'अपना', 'सब', 'कुछ', 'माना', '।', 'END']'\n"
     ]
    }
   ],
   "source": [
    "# Replace all words not in our vocabulary with the unknown token\n",
    "for i, sent in enumerate(tokenized_conversation):\n",
    "    tokenized_conversation[i] = [w if w in word_freq else unknown_token for w in sent]\n",
    "\n",
    "print(\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "\n",
    "print(\"\\nExample sentence: '%s'\" % sentences[0])\n",
    "print(\"\\nExample sentence after pre-processing: '%s'\" % tokenized_conversation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862ca78",
   "metadata": {},
   "source": [
    "This code will print a list of the most common words in the text data, along with their respective frequencies. Thi step is useful for understanding which words are prevalent in the text and may be important for our task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e8baa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common words:\n",
      "'START': 112\n",
      "'।': 112\n",
      "'END': 112\n",
      "'के': 71\n",
      "'मीरा': 50\n",
      "'में': 45\n",
      "'की': 43\n",
      "'से': 39\n",
      "'है': 36\n",
      "'और': 31\n",
      "'कि': 29\n",
      "'को': 25\n",
      "'का': 25\n",
      "'कर': 25\n",
      "'कृष्ण': 19\n",
      "'उनके': 16\n",
      "'ने': 16\n",
      "'साथ': 16\n",
      "'वह': 14\n",
      "'थीं': 14\n",
      "'एक': 14\n",
      "'था': 13\n",
      "'यह': 13\n",
      "'नहीं': 13\n",
      "'पर': 12\n",
      "'भी': 12\n",
      "'तो': 12\n",
      "'कोई': 12\n",
      "'लिए': 11\n",
      "'दिया': 10\n",
      "'हैं': 10\n",
      "'ही': 9\n",
      "'लेकिन': 9\n",
      "'प्रेम': 9\n",
      "'गया': 9\n",
      "'मीराबाई': 8\n",
      "'अपनी': 8\n",
      "'इस': 8\n",
      "'मूर्ति': 8\n",
      "'बाद': 8\n",
      "'अपने': 8\n",
      "'उसने': 8\n",
      "'हो': 8\n",
      "'भक्ति': 8\n",
      "'उन्होंने': 7\n",
      "'जो': 7\n",
      "'सामने': 7\n",
      "'जब': 7\n",
      "'पति': 7\n",
      "'मन': 7\n",
      "'आप': 7\n",
      "'तक': 6\n",
      "'रही': 6\n",
      "'उनकी': 6\n",
      "'वे': 6\n",
      "'थे': 6\n",
      "'राणा': 6\n",
      "'लिया': 6\n",
      "'अपना': 5\n",
      "'कुछ': 5\n",
      "'किसी': 5\n",
      "'यहां': 5\n",
      "'यही': 5\n",
      "'तरह': 5\n",
      "'गईं': 5\n",
      "'कई': 5\n",
      "'लोगों': 5\n",
      "'बहुत': 5\n",
      "'किया': 5\n",
      "'शरीर': 5\n",
      "'थी': 4\n",
      "'गई': 4\n",
      "'उनका': 4\n",
      "'बारात': 4\n",
      "'माता': 4\n",
      "'मेरा': 4\n",
      "'मंदिर': 4\n",
      "'उन्हें': 4\n",
      "'कहा': 4\n",
      "'प्रेमी': 4\n",
      "'प्रति': 4\n",
      "'फूलों': 4\n",
      "'भावनाओं': 4\n",
      "'लोग': 4\n",
      "'गुरु': 4\n",
      "'ऐसी': 3\n",
      "'सब': 3\n",
      "'वजह': 3\n",
      "'देख': 3\n",
      "'दूल्हा': 3\n",
      "'बात': 3\n",
      "'शादी': 3\n",
      "'कुंभा': 3\n",
      "'दी': 3\n",
      "'पहले': 3\n",
      "'करने': 3\n",
      "'बातें': 3\n",
      "'फिर': 3\n",
      "'रहे': 3\n",
      "'टोकरी': 3\n",
      "'संदेश': 3\n",
      "'भिजवाया': 3\n",
      "'बन': 3\n",
      "'वहां': 3\n",
      "'वृंदावन': 3\n",
      "'जाता': 3\n",
      "'समर्पित': 3\n",
      "'बिना': 3\n",
      "'चीज': 3\n",
      "'खुद': 3\n",
      "'विवाह': 3\n",
      "'हर': 3\n",
      "'ऐसे': 3\n",
      "'गए': 3\n",
      "'होने': 3\n",
      "'रहा': 3\n",
      "'औरत': 3\n",
      "'सकता': 3\n",
      "'मैं': 3\n",
      "'भरोसे': 3\n",
      "'भरोसा': 3\n",
      "'धरती': 3\n",
      "'जीव': 3\n",
      "'गिरिधर': 3\n",
      "'पदों': 3\n",
      "'पायो': 3\n",
      "'बालमन': 2\n",
      "'लेकर': 2\n",
      "'माना': 2\n",
      "'जी': 2\n",
      "'जन्म': 2\n",
      "'हुआ': 2\n",
      "'बचपन': 2\n",
      "'घटना': 2\n",
      "'चरम': 2\n",
      "'अवस्था': 2\n",
      "'पहुंचा': 2\n",
      "'दिन': 2\n",
      "'बड़े': 2\n",
      "'सभी': 2\n",
      "'लगीं': 2\n",
      "'ओर': 2\n",
      "'महाराणा': 2\n",
      "'आगे': 2\n",
      "'मना': 2\n",
      "'समय': 2\n",
      "'वही': 2\n",
      "'ससुराल': 2\n",
      "'चली': 2\n",
      "'पूजा': 2\n",
      "'करतीं': 2\n",
      "'कुलदेवी': 2\n",
      "'करते': 2\n",
      "'देखा': 2\n",
      "'रात': 2\n",
      "'परम': 2\n",
      "'जिस': 2\n",
      "'उसे': 2\n",
      "'मेरे': 2\n",
      "'’': 2\n",
      "'जवाब': 2\n",
      "'दिल': 2\n",
      "'लगे': 2\n",
      "'शुरुआत': 2\n",
      "'इतना': 2\n",
      "'आम': 2\n",
      "'चित्तौड़': 2\n",
      "'निकल': 2\n",
      "'चल': 2\n",
      "'बना': 2\n",
      "'बार': 2\n",
      "'कोशिश': 2\n",
      "'पास': 2\n",
      "'हार': 2\n",
      "'उस': 2\n",
      "'मानती': 2\n",
      "'ललिता': 2\n",
      "'दीवानी': 2\n",
      "'गांव': 2\n",
      "'पूरे': 2\n",
      "'रहीं': 2\n",
      "'साल': 2\n",
      "'पूरी': 2\n",
      "'भीड़': 2\n",
      "'किए': 2\n",
      "'मतलब': 2\n",
      "'इंसान': 2\n",
      "'आज': 2\n",
      "'पहुंच': 2\n",
      "'जहां': 2\n",
      "'इतनी': 2\n",
      "'सच्चाई': 2\n",
      "'लगी': 2\n",
      "'क्योंकि': 2\n",
      "'दिव्य': 2\n",
      "'आखिर': 2\n",
      "'क्या': 2\n",
      "'दरअसल': 2\n",
      "'नजर': 2\n",
      "'रंग': 2\n",
      "'आया': 2\n",
      "'करें': 2\n",
      "'मरने': 2\n",
      "'व्यभिचार': 2\n",
      "'जहर': 2\n",
      "'हूं': 2\n",
      "'मत': 2\n",
      "'या': 2\n",
      "'आराम': 2\n",
      "'बैठे': 2\n",
      "'जागरुकता': 2\n",
      "'करना': 2\n",
      "'हुए': 2\n",
      "'अगर': 2\n",
      "'गोसांई': 2\n",
      "'मिलने': 2\n",
      "'पुरुष': 2\n",
      "'गोपाल': 2\n",
      "'पता': 2\n",
      "'प्रभु': 2\n",
      "'पद': 2\n",
      "'आध्यात्मिक': 2\n",
      "'अन्य': 2\n",
      "'संतों': 2\n",
      "'न': 2\n",
      "'दई': 2\n",
      "'बैठि': 2\n",
      "'सींचि': 2\n",
      "'देखि': 2\n",
      "'सतगुरु': 2\n",
      "'जनम': 2\n",
      "'छवि': 1\n",
      "'बसी': 1\n",
      "'किशोरावस्था': 1\n",
      "'मृत्यु': 1\n",
      "'जोधपुर': 1\n",
      "'राठौड़': 1\n",
      "'रतनसिंह': 1\n",
      "'इकलौती': 1\n",
      "'पुत्री': 1\n",
      "'सोलहवीं': 1\n",
      "'शताब्दी': 1\n",
      "'कृष्णभक्ति': 1\n",
      "'रम': 1\n",
      "'हुई': 1\n",
      "'कृष्णप्रेम': 1\n",
      "'पड़ोस': 1\n",
      "'आदमी': 1\n",
      "'आई': 1\n",
      "'औरतें': 1\n",
      "'छत': 1\n",
      "'खड़ी': 1\n",
      "'होकर': 1\n",
      "'देखने': 1\n",
      "'पूछा': 1\n",
      "'कौन': 1\n",
      "'इशारा': 1\n",
      "'कह': 1\n",
      "'तुम्हारे': 1\n",
      "'बस': 1\n",
      "'गांठ': 1\n",
      "'बंध': 1\n",
      "'सांगा': 1\n",
      "'पुत्र': 1\n",
      "'भोजराज': 1\n",
      "'चलकर': 1\n",
      "'कहलाए': 1\n",
      "'जोर': 1\n",
      "'देने': 1\n",
      "'फूटफूट': 1\n",
      "'रोने': 1\n",
      "'विदाई': 1\n",
      "'ले': 1\n",
      "'जिसे': 1\n",
      "'बताया': 1\n",
      "'घरेलू': 1\n",
      "'कामकाज': 1\n",
      "'निबटाने': 1\n",
      "'रोज': 1\n",
      "'जातीं': 1\n",
      "'गातीं': 1\n",
      "'नृत्य': 1\n",
      "'वाले': 1\n",
      "'तुलजा': 1\n",
      "'भवानी': 1\n",
      "'यानी': 1\n",
      "'दुर्गा': 1\n",
      "'मानते': 1\n",
      "'इनकार': 1\n",
      "'परिवार': 1\n",
      "'वालों': 1\n",
      "'श्रद्धाभक्ति': 1\n",
      "'मंजूरी': 1\n",
      "'ननद': 1\n",
      "'उदाबाई': 1\n",
      "'बदनाम': 1\n",
      "'खिलाफ': 1\n",
      "'साजिश': 1\n",
      "'रची': 1\n",
      "'गुप्त': 1\n",
      "'बहन': 1\n",
      "'आधी': 1\n",
      "'दरवाजा': 1\n",
      "'तोड़': 1\n",
      "'अंदर': 1\n",
      "'अकेले': 1\n",
      "'आनंद': 1\n",
      "'बैठी': 1\n",
      "'मस्ती': 1\n",
      "'गा': 1\n",
      "'चिल्लाया': 1\n",
      "'’मीरा': 1\n",
      "'तुम': 1\n",
      "'अभी': 1\n",
      "'लाओ': 1\n",
      "'–': 1\n",
      "'‘वह': 1\n",
      "'बैठा': 1\n",
      "'स्वामी': 1\n",
      "'नैनचोर': 1\n",
      "'जिसने': 1\n",
      "'चुराया': 1\n",
      "'समाधि': 1\n",
      "'टूट': 1\n",
      "'अच्छे': 1\n",
      "'भूमिका': 1\n",
      "'निभाई': 1\n",
      "'मरते': 1\n",
      "'दम': 1\n",
      "'हालांकि': 1\n",
      "'राजगद्दी': 1\n",
      "'चाह': 1\n",
      "'संबंधी': 1\n",
      "'तरीकों': 1\n",
      "'सताने': 1\n",
      "'बेहद': 1\n",
      "'निजी': 1\n",
      "'कभीकभी': 1\n",
      "'प्रेमानंद': 1\n",
      "'उमड़': 1\n",
      "'पड़ता': 1\n",
      "'धार्मिक': 1\n",
      "'उत्सवों': 1\n",
      "'नाचनेगाने': 1\n",
      "'लगती': 1\n",
      "'चुपचाप': 1\n",
      "'किले': 1\n",
      "'जाती': 1\n",
      "'नगर': 1\n",
      "'सत्संग': 1\n",
      "'हिस्सा': 1\n",
      "'लेती': 1\n",
      "'देवर': 1\n",
      "'विक्रमादित्य': 1\n",
      "'चित्तौड़गढ़': 1\n",
      "'नया': 1\n",
      "'राजा': 1\n",
      "'कठोर': 1\n",
      "'घुलनामिलना': 1\n",
      "'नारीमर्यादा': 1\n",
      "'लापरवाही': 1\n",
      "'कड़ा': 1\n",
      "'विरोध': 1\n",
      "'मारने': 1\n",
      "'जहरीला': 1\n",
      "'सांप': 1\n",
      "'रखकर': 1\n",
      "'भेजा': 1\n",
      "'ध्यान': 1\n",
      "'उठने': 1\n",
      "'खोली': 1\n",
      "'उसमें': 1\n",
      "'सुंदर': 1\n",
      "'निकली': 1\n",
      "'तैयार': 1\n",
      "'कांटो': 1\n",
      "'बिस्तर': 1\n",
      "'सेज': 1\n",
      "'सोने': 1\n",
      "'चलीं': 1\n",
      "'यातनाएं': 1\n",
      "'बरदाश्त': 1\n",
      "'बाहर': 1\n",
      "'छोड़': 1\n",
      "'मेड़ता': 1\n",
      "'संतोश': 1\n",
      "'मिला': 1\n",
      "'उन्होने': 1\n",
      "'कृश्णभक्ति': 1\n",
      "'केंद्र': 1\n",
      "'रुख': 1\n",
      "'गोपी': 1\n",
      "'जिन्होने': 1\n",
      "'खैर': 1\n",
      "'तीर्थयात्रा': 1\n",
      "'जारी': 1\n",
      "'रखी': 1\n",
      "'दूसरे': 1\n",
      "'नाचतीगाती': 1\n",
      "'उत्तर': 1\n",
      "'भारत': 1\n",
      "'घूमती': 1\n",
      "'जीवन': 1\n",
      "'अंतिम': 1\n",
      "'गुजरात': 1\n",
      "'द्वारका': 1\n",
      "'गुजारे': 1\n",
      "'ऐसा': 1\n",
      "'दर्शकों': 1\n",
      "'द्वारकाधीश': 1\n",
      "'समा': 1\n",
      "'“इंसान': 1\n",
      "'आमतौर': 1\n",
      "'सारी': 1\n",
      "'ज्यादातर': 1\n",
      "'सकते': 1\n",
      "'दें': 1\n",
      "'भावनाएं': 1\n",
      "'इसाई': 1\n",
      "'संप्रदायों': 1\n",
      "'नन': 1\n",
      "'बनने': 1\n",
      "'दीक्षा': 1\n",
      "'पाने': 1\n",
      "'लड़कियां': 1\n",
      "'जीसस': 1\n",
      "'करती': 1\n",
      "'समर्पण': 1\n",
      "'परे': 1\n",
      "'धरातल': 1\n",
      "'बिलकुल': 1\n",
      "'अलग': 1\n",
      "'सत्य': 1\n",
      "'महज': 1\n",
      "'आठ': 1\n",
      "'उम्र': 1\n",
      "'भावों': 1\n",
      "'तीव्रता': 1\n",
      "'गहन': 1\n",
      "'मतिभ्रम': 1\n",
      "'उठतेबैठते': 1\n",
      "'घूमते': 1\n",
      "'दिक्कत': 1\n",
      "'हमेशा': 1\n",
      "'रहतीं': 1\n",
      "'संभोग': 1\n",
      "'संभव': 1\n",
      "'समझने': 1\n",
      "'वाकई': 1\n",
      "'प्यार': 1\n",
      "'करता': 1\n",
      "'जान': 1\n",
      "'सका': 1\n",
      "'स्थिति': 1\n",
      "'गुजर': 1\n",
      "'वास्तविक': 1\n",
      "'लगता': 1\n",
      "'आता': 1\n",
      "'निराश': 1\n",
      "'नीले': 1\n",
      "'पोत': 1\n",
      "'पोशाक': 1\n",
      "'पहन': 1\n",
      "'दुर्भाग्य': 1\n",
      "'गलत': 1\n",
      "'इस्तेमाल': 1\n",
      "'जिसकी': 1\n",
      "'एलर्जी': 1\n",
      "'चकत्ते': 1\n",
      "'आए': 1\n",
      "'इर्द': 1\n",
      "'गिर्द': 1\n",
      "'चकराए': 1\n",
      "'ऊंचाइयों': 1\n",
      "'तब': 1\n",
      "'समझ': 1\n",
      "'असाधारण': 1\n",
      "'आदर': 1\n",
      "'चीजें': 1\n",
      "'सकती': 1\n",
      "'आसपास': 1\n",
      "'इकट्ठी': 1\n",
      "'आरोप': 1\n",
      "'लगाया': 1\n",
      "'उन': 1\n",
      "'दिनों': 1\n",
      "'मत्यु': 1\n",
      "'दंड': 1\n",
      "'इसलिए': 1\n",
      "'शाही': 1\n",
      "'दरबार': 1\n",
      "'पीने': 1\n",
      "'याद': 1\n",
      "'पीकर': 1\n",
      "'दीं': 1\n",
      "'इंतजार': 1\n",
      "'स्वस्थ्य': 1\n",
      "'प्रसन्न': 1\n",
      "'बनी': 1\n",
      "'घटनाएं': 1\n",
      "'हुईं': 1\n",
      "'व्यक्ति': 1\n",
      "'खाली': 1\n",
      "'देती': 1\n",
      "'कहता': 1\n",
      "'धारणा': 1\n",
      "'विश्वास': 1\n",
      "'आस्था': 1\n",
      "'बढ़ने': 1\n",
      "'सवाल': 1\n",
      "'उठता': 1\n",
      "'कैसे': 1\n",
      "'करूं': 1\n",
      "'गोल': 1\n",
      "'बड़ी': 1\n",
      "'तेजी': 1\n",
      "'धुरी': 1\n",
      "'सूरज': 1\n",
      "'चारों': 1\n",
      "'घूम': 1\n",
      "'मान': 1\n",
      "'लीजिए': 1\n",
      "'अचानक': 1\n",
      "'उल्टी': 1\n",
      "'दिशा': 1\n",
      "'घूमने': 1\n",
      "'फैसला': 1\n",
      "'लें': 1\n",
      "'छिटक': 1\n",
      "'कहीं': 1\n",
      "'चले': 1\n",
      "'जाएं': 1\n",
      "'जानते': 1\n",
      "'कहां': 1\n",
      "'पहुंचेंगे': 1\n",
      "'बैठें': 1\n",
      "'मुस्कराएं': 1\n",
      "'दूसरों': 1\n",
      "'इन': 1\n",
      "'सबके': 1\n",
      "'आपको': 1\n",
      "'ज्यादा': 1\n",
      "'जरूरत': 1\n",
      "'अनजाने': 1\n",
      "'प्रेमभाव': 1\n",
      "'सीखिए': 1\n",
      "'सृष्टि': 1\n",
      "'जैसी': 1\n",
      "'वैसे': 1\n",
      "'आपने': 1\n",
      "'बैठना': 1\n",
      "'सीख': 1\n",
      "'मान्यता': 1\n",
      "'अस्तित्व': 1\n",
      "'सबसे': 1\n",
      "'खूबसूरत': 1\n",
      "'तरीका': 1\n",
      "'”': 1\n",
      "'वैष्णवसंप्रदाय': 1\n",
      "'मुखिया': 1\n",
      "'दर्शन': 1\n",
      "'चाहती': 1\n",
      "'संदेशा': 1\n",
      "'आने': 1\n",
      "'इजाजत': 1\n",
      "'देंगे': 1\n",
      "'इसके': 1\n",
      "'‘वृंदावन': 1\n",
      "'केवल': 1\n",
      "'मुझे': 1\n",
      "'चला': 1\n",
      "'अलावा': 1\n",
      "'जबाब': 1\n",
      "'गोसाईं': 1\n",
      "'शर्मिंदा': 1\n",
      "'फौरन': 1\n",
      "'भरपूर': 1\n",
      "'सम्मान': 1\n",
      "'बारे': 1\n",
      "'धारण': 1\n",
      "'होती': 1\n",
      "'भक्तिपूर्ण': 1\n",
      "'प्राप्ति': 1\n",
      "'भेद': 1\n",
      "'बता': 1\n",
      "'सच्चा': 1\n",
      "'स्वयं': 1\n",
      "'चलता': 1\n",
      "'रैदास': 1\n",
      "'अनेक': 1\n",
      "'व': 1\n",
      "'गीतों': 1\n",
      "'रचना': 1\n",
      "'उच्च': 1\n",
      "'अनुभव': 1\n",
      "'उनमें': 1\n",
      "'दिए': 1\n",
      "'शिक्षाओं': 1\n",
      "'समानता': 1\n",
      "'आती': 1\n",
      "'उंचाई': 1\n",
      "'अनुभवों': 1\n",
      "'आईना': 1\n",
      "'भाषाओं': 1\n",
      "'प्रयोग': 1\n",
      "'जैसे': 1\n",
      "'हिंदी': 1\n",
      "'गुजराती': 1\n",
      "'ब्रज': 1\n",
      "'अवधी': 1\n",
      "'भोजपुरी': 1\n",
      "'अरबी': 1\n",
      "'फारसी': 1\n",
      "'मारवाड़ी': 1\n",
      "'संस्कृत': 1\n",
      "'मैथिली': 1\n",
      "'पंजाबी': 1\n",
      "'मार्मिक': 1\n",
      "'अभिव्यक्ति': 1\n",
      "'साथसाथ': 1\n",
      "'ओजस्वी': 1\n",
      "'प्रवाहधारा': 1\n",
      "'प्रीतम': 1\n",
      "'वियोग': 1\n",
      "'पीड़ा': 1\n",
      "'मर्मभेदी': 1\n",
      "'वर्णन': 1\n",
      "'मिलता': 1\n",
      "'साक्षात्': 1\n",
      "'बराबर': 1\n",
      "'शायद': 1\n",
      "'कवि': 1\n",
      "'दूसरो': 1\n",
      "'जाके': 1\n",
      "'सिर': 1\n",
      "'मोर': 1\n",
      "'मुकुट': 1\n",
      "'मेरो': 1\n",
      "'सोई': 1\n",
      "'छांड़ि': 1\n",
      "'कुल': 1\n",
      "'कानि': 1\n",
      "'करै': 1\n",
      "'संतन': 1\n",
      "'ढिग': 1\n",
      "'लोक': 1\n",
      "'लाज': 1\n",
      "'खोई': 1\n",
      "'अंसुवन': 1\n",
      "'जल': 1\n",
      "'बेलि': 1\n",
      "'बोई': 1\n",
      "'दधि': 1\n",
      "'मथि': 1\n",
      "'घृत': 1\n",
      "'काढ़ि': 1\n",
      "'लियौ': 1\n",
      "'डारि': 1\n",
      "'छोई': 1\n",
      "'भगत': 1\n",
      "'राजी': 1\n",
      "'भई': 1\n",
      "'जगत': 1\n",
      "'रोई': 1\n",
      "'दासी': 1\n",
      "'लाल': 1\n",
      "'तारो': 1\n",
      "'अब': 1\n",
      "'मोई': 1\n",
      "'मैंने': 1\n",
      "'नाम': 1\n",
      "'रतन': 1\n",
      "'धन': 1\n",
      "'बस्तु': 1\n",
      "'अमोलक': 1\n",
      "'म्हारे': 1\n",
      "'किरपा': 1\n",
      "'अपनायो': 1\n",
      "'पूंजी': 1\n",
      "'पाई': 1\n",
      "'जग': 1\n",
      "'खोवायो': 1\n",
      "'खरचै': 1\n",
      "'नहिं': 1\n",
      "'चोर': 1\n",
      "'लेवै': 1\n",
      "'दिनदिन': 1\n",
      "'बढ़त': 1\n",
      "'सवायो': 1\n",
      "'सत': 1\n",
      "'नाव': 1\n",
      "'खेवहिया': 1\n",
      "'भवसागर': 1\n",
      "'तर': 1\n",
      "'आयो': 1\n",
      "'गिरधर': 1\n",
      "'नागर': 1\n",
      "'हरखहरख': 1\n",
      "'जस': 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words\n",
    "most_common_words = word_freq.most_common()\n",
    "print(\"The most common words:\")\n",
    "for word, frequency in most_common_words:\n",
    "    print(f\"'{word}': {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20be4bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START मीराबाई के बालमन में कृष्ण की ऐसी छवि बसी थी कि किशोरावस्था से लेकर मृत्यु तक उन्होंने कृष्ण को ही अपना सब कुछ माना। END',\n",
       " 'START जोधपुर के राठौड़ रतनसिंह जी की इकलौती पुत्री मीराबाई का जन्म सोलहवीं शताब्दी में हुआ था। END',\n",
       " 'START बचपन से ही वह कृष्णभक्ति में रम गई थीं। END',\n",
       " 'START मीराबाई के बचपन में हुई एक घटना की वजह से उनका कृष्णप्रेम अपनी चरम अवस्था तक पहुंचा। END',\n",
       " 'START एक दिन उनके पड़ोस में किसी बड़े आदमी के यहां बारात आई। END']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_start_token[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5462a7e5",
   "metadata": {},
   "source": [
    "The `Counter class` from the collections module is used to count the bigrams, and ngrams from NLTK is used to generate bigrams from the list of words in the text.\n",
    "The `%time` magic command is used to measure the execution time of the code cell.\n",
    "The code will print the top 10 most common bigrams in the text, along with their counts. This is useful for analyzing patterns and relationships between words in the text data. Smilarly we are also finding most common trigram, quadgram, pentagram and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971cebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 µs, sys: 21 µs, total: 464 µs\n",
      "Wall time: 467 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('मीरा', 'के'), 13),\n",
       " (('के', 'साथ'), 11),\n",
       " (('मीरा', 'ने'), 9),\n",
       " (('के', 'लिए'), 8),\n",
       " (('है', 'कि'), 8),\n",
       " (('कृष्ण', 'की'), 7),\n",
       " (('मीरा', 'को'), 7),\n",
       " (('मीरा', 'का'), 6),\n",
       " (('के', 'बाद'), 5),\n",
       " (('कृष्ण', 'के'), 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "bigram_counts = Counter(ngrams(text.split(), 2))\n",
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7169300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 368 µs, sys: 32 µs, total: 400 µs\n",
      "Wall time: 403 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('मीरा', 'के'), 13),\n",
       " (('के', 'साथ'), 11),\n",
       " (('मीरा', 'ने'), 9),\n",
       " (('के', 'लिए'), 8),\n",
       " (('है', 'कि'), 8),\n",
       " (('कृष्ण', 'की'), 7),\n",
       " (('मीरा', 'को'), 7),\n",
       " (('मीरा', 'का'), 6),\n",
       " (('के', 'बाद'), 5),\n",
       " (('कृष्ण', 'के'), 5)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import collections\n",
    "def ngrams(text, n=2):\n",
    "    return zip(*[text[i:] for i in range(n)])\n",
    "bigram_counts = collections.Counter(ngrams(text.split(), 2))\n",
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b73bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('शरीर', 'मन', 'और'), 3),\n",
       " (('के', 'बालमन', 'में'), 2),\n",
       " (('उन्होंने', 'कृष्ण', 'को'), 2),\n",
       " (('मीरा', 'ने', 'अपनी'), 2),\n",
       " (('उनकी', 'माता', 'ने'), 2),\n",
       " (('कृष्ण', 'की', 'मूर्ति'), 2),\n",
       " (('के', 'बाद', 'मीरा'), 2),\n",
       " (('मूर्ति', 'के', 'सामने'), 2),\n",
       " (('जब', 'मीरा', 'ने'), 2),\n",
       " (('उसने', 'मीरा', 'को'), 2)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_counts = Counter(ngrams(text.split(), 3))\n",
    "trigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f852533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('कृष्ण', 'के', 'प्रति', 'मीरा'), 2),\n",
       " (('के', 'प्रति', 'मीरा', 'का'), 2),\n",
       " (('प्रति', 'मीरा', 'का', 'प्रेम'), 2),\n",
       " (('शरीर', 'मन', 'और', 'भावनाओं'), 2),\n",
       " (('थी', 'कि', 'कृष्ण', 'उनके'), 2),\n",
       " (('अपने', 'दिव्य', 'प्रेमी', 'के'), 2),\n",
       " (('दिव्य', 'प्रेमी', 'के', 'साथ'), 2),\n",
       " (('जागरुकता', 'और', 'प्रेम', 'के'), 2),\n",
       " (('और', 'प्रेम', 'के', 'साथ'), 2),\n",
       " (('मीराबाई', 'के', 'बालमन', 'में'), 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadgram_counts = Counter(ngrams(text.replace('&', 'i').split(), 4))\n",
    "quadgram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13dd96c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('कृष्ण', 'के', 'प्रति', 'मीरा', 'का'), 2),\n",
       " (('के', 'प्रति', 'मीरा', 'का', 'प्रेम'), 2),\n",
       " (('अपने', 'दिव्य', 'प्रेमी', 'के', 'साथ'), 2),\n",
       " (('जागरुकता', 'और', 'प्रेम', 'के', 'साथ'), 2),\n",
       " (('मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण'), 1),\n",
       " (('के', 'बालमन', 'में', 'कृष्ण', 'की'), 1),\n",
       " (('बालमन', 'में', 'कृष्ण', 'की', 'ऐसी'), 1),\n",
       " (('में', 'कृष्ण', 'की', 'ऐसी', 'छवि'), 1),\n",
       " (('कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी'), 1),\n",
       " (('की', 'ऐसी', 'छवि', 'बसी', 'थी'), 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pentagram_counts = Counter(ngrams(text.split(), 5))\n",
    "pentagram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d0c2ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('कृष्ण', 'के', 'प्रति', 'मीरा', 'का', 'प्रेम'), 2),\n",
       " (('मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की'), 1),\n",
       " (('के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी'), 1),\n",
       " (('बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि'), 1),\n",
       " (('में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी'), 1),\n",
       " (('कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी'), 1),\n",
       " (('की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि'), 1),\n",
       " (('ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था'), 1),\n",
       " (('छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से'), 1),\n",
       " (('बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर'), 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hexagram_counts = Counter(ngrams(text.split(), 6))\n",
    "hexagram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a337a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी'), 1),\n",
       " (('के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि'), 1),\n",
       " (('बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी'), 1),\n",
       " (('में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी'), 1),\n",
       " (('कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि'), 1),\n",
       " (('की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था'), 1),\n",
       " (('ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से'), 1),\n",
       " (('छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर'), 1),\n",
       " (('बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु'), 1),\n",
       " (('थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक'), 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heptagram_counts = Counter(ngrams(text.split(), 7))\n",
    "heptagram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "321944d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि'), 1),\n",
       " (('के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी'), 1),\n",
       " (('बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी'), 1),\n",
       " (('में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि'), 1),\n",
       " (('कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था'), 1),\n",
       " (('की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से'), 1),\n",
       " (('ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर'), 1),\n",
       " (('छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु'), 1),\n",
       " (('बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक'), 1),\n",
       " (('थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक', 'उन्होंने'), 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octagram_counts = Counter(ngrams(text.split(), 8))\n",
    "octagram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "396ef274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी'), 1),\n",
       " (('के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी'), 1),\n",
       " (('बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि'), 1),\n",
       " (('में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था'), 1),\n",
       " (('कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से'), 1),\n",
       " (('की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर'), 1),\n",
       " (('ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु'), 1),\n",
       " (('छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक'), 1),\n",
       " (('बसी', 'थी', 'कि', 'किशोरावस्था', 'से', 'लेकर', 'मृत्यु', 'तक', 'उन्होंने'),\n",
       "  1),\n",
       " (('थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर',\n",
       "   'मृत्यु',\n",
       "   'तक',\n",
       "   'उन्होंने',\n",
       "   'कृष्ण'),\n",
       "  1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eneagram_counts = Counter(ngrams(text.split(), 9))\n",
    "eneagram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a512958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('मीराबाई', 'के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी'),\n",
       "  1),\n",
       " (('के', 'बालमन', 'में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि'), 1),\n",
       " (('बालमन',\n",
       "   'में',\n",
       "   'कृष्ण',\n",
       "   'की',\n",
       "   'ऐसी',\n",
       "   'छवि',\n",
       "   'बसी',\n",
       "   'थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था'),\n",
       "  1),\n",
       " (('में', 'कृष्ण', 'की', 'ऐसी', 'छवि', 'बसी', 'थी', 'कि', 'किशोरावस्था', 'से'),\n",
       "  1),\n",
       " (('कृष्ण',\n",
       "   'की',\n",
       "   'ऐसी',\n",
       "   'छवि',\n",
       "   'बसी',\n",
       "   'थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर'),\n",
       "  1),\n",
       " (('की',\n",
       "   'ऐसी',\n",
       "   'छवि',\n",
       "   'बसी',\n",
       "   'थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर',\n",
       "   'मृत्यु'),\n",
       "  1),\n",
       " (('ऐसी',\n",
       "   'छवि',\n",
       "   'बसी',\n",
       "   'थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर',\n",
       "   'मृत्यु',\n",
       "   'तक'),\n",
       "  1),\n",
       " (('छवि',\n",
       "   'बसी',\n",
       "   'थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर',\n",
       "   'मृत्यु',\n",
       "   'तक',\n",
       "   'उन्होंने'),\n",
       "  1),\n",
       " (('बसी',\n",
       "   'थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर',\n",
       "   'मृत्यु',\n",
       "   'तक',\n",
       "   'उन्होंने',\n",
       "   'कृष्ण'),\n",
       "  1),\n",
       " (('थी',\n",
       "   'कि',\n",
       "   'किशोरावस्था',\n",
       "   'से',\n",
       "   'लेकर',\n",
       "   'मृत्यु',\n",
       "   'तक',\n",
       "   'उन्होंने',\n",
       "   'कृष्ण',\n",
       "   'को'),\n",
       "  1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decagram_counts = Counter(ngrams(text.split(), 10))\n",
    "decagram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fde2ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मीराबाई के बालमन में कृष्ण की ऐसी छवि बसी थी कि किशोरावस्था से लेकर मृत्यु तक उन्होंने कृष्ण को ही अपना सब कुछ माना। जोधपुर के राठौड़ रतनसिंह जी की इकलौती पुत्री मीराबाई का जन्म सोलहवीं शताब्दी में हुआ था। बचपन से ही वह कृष्णभक्ति में रम गई थीं।  मीराबाई के बचपन में हुई एक घटना की वजह से उनका कृष्णप्रेम अपनी चरम अवस्था तक पहुंचा। एक दिन उनके पड़ोस में किसी बड़े आदमी के यहां बारात आई। सभी औरतें छत पर खड़ी होकर बारात देख रही थीं। मीरा भी बारात देखने लगीं। बारात को देख मीरा ने अपनी माता से पूछा कि मेरा दूल्हा कौन है इस पर उनकी माता ने कृष्ण की मूर्ति की ओर इशारा कर के कह दिया कि यही तुम्हारे दूल्हा हैं। बस यह बात मीरा के बालमन में एक गांठ की तरह बंध गई।  बाद में मीराबाई की शादी महाराणा सांगा के पुत्र भोजराज जो आगे चलकर महाराणा कुंभा कहलाए से कर दी गई। इस शादी के लिए पहले तो मीराबाई ने मना कर दिया लेकिन जोर देने पर वह फूटफूट कर रोने लगीं। शादी के बाद विदाई के समय वे कृष्ण की वही मूर्ति अपने साथ ले गईं जिसे उनकी माता ने उनका दूल्हा बताया था। ससुराल में अपने घरेलू कामकाज निबटाने के बाद मीरा रोज '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4f17fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3795a95",
   "metadata": {},
   "source": [
    "This code splits each sentence into words using space as the delimiter, and then it selects the first word (the word at index 0) from each sentence. The resulting `first_words` list will contain the first word of each sentence in the same order as they appear in the `sentences` list. Later on we are trying to find the `most_commmon_first_word` and their `frequency` to get a better understanding which words are used to start a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9f96a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first word from each sentence\n",
    "first_words = [sentence.split()[0] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea5b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common first words in sentences:\n",
      "'मीरा': 11\n",
      "'उनके': 5\n",
      "'मीराबाई': 4\n",
      "'इस': 4\n",
      "'यह': 4\n",
      "'जब': 3\n",
      "'राणा': 3\n",
      "'वह': 3\n",
      "'बाद': 2\n",
      "'उसने': 2\n",
      "'’': 2\n",
      "'कृष्ण': 2\n",
      "'वे': 2\n",
      "'यहां': 2\n",
      "'यही': 2\n",
      "'आज': 2\n",
      "'ऐसे': 2\n",
      "'लेकिन': 2\n",
      "'दरअसल': 2\n",
      "'लोग': 2\n",
      "'उन्होंने': 2\n",
      "'तो': 2\n",
      "'भक्ति': 2\n",
      "'जोधपुर': 1\n",
      "'बचपन': 1\n",
      "'एक': 1\n",
      "'सभी': 1\n",
      "'बारात': 1\n",
      "'बस': 1\n",
      "'शादी': 1\n",
      "'ससुराल': 1\n",
      "'हालांकि': 1\n",
      "'ध्यान': 1\n",
      "'ललिता': 1\n",
      "'खैर': 1\n",
      "'माना': 1\n",
      "'ऐसा': 1\n",
      "'“इंसान': 1\n",
      "'विवाह': 1\n",
      "'कुछ': 1\n",
      "'दुर्भाग्य': 1\n",
      "'पति': 1\n",
      "'उन': 1\n",
      "'इसलिए': 1\n",
      "'मेरा': 1\n",
      "'मान': 1\n",
      "'आप': 1\n",
      "'”': 1\n",
      "'अगर': 1\n",
      "'भक्तिपूर्ण': 1\n",
      "'वही': 1\n",
      "'स्वयं': 1\n",
      "'उनमें': 1\n",
      "'प्रेम': 1\n",
      "'मेरे': 1\n",
      "'जाके': 1\n",
      "'छांड़ि': 1\n",
      "'संतन': 1\n",
      "'अंसुवन': 1\n",
      "'दधि': 1\n",
      "'भगत': 1\n",
      "'दासी': 1\n",
      "'पायो': 1\n",
      "'बस्तु': 1\n",
      "'जनम': 1\n",
      "'खरचै': 1\n",
      "'सत': 1\n",
      "'।': 1\n"
     ]
    }
   ],
   "source": [
    "# Extract the first word from each sentence\n",
    "first_words = [sentence.split()[0] for sentence in sentences]\n",
    "\n",
    "# Count the frequency of each first word\n",
    "word_freq = nltk.FreqDist(first_words)\n",
    "\n",
    "# Get the most common first words\n",
    "most_common_first_words = word_freq.most_common()\n",
    "print(\"The most common first words in sentences:\")\n",
    "for word, frequency in most_common_first_words:\n",
    "    print(f\"'{word}': {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e104d6",
   "metadata": {},
   "source": [
    "# Preparing training data\n",
    "\n",
    "In this code, we are preparing training data for a sequence-to-sequence model. We are using X_train and y_train to represent input sequences and corresponding target sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39a3de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = [[sentence_start_token] for sent,times in first_word_counts if sent != 'o.']\n",
    "#y_train = [sent for sent in first_word_counts if sent != 'o.']\n",
    "X_train = [[sentence_start_token] for sent in first_words if sent != 'मीरा।']\n",
    "y_train = [[sent] for sent in first_words if sent != 'मीरा।']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87681776",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [item for sublist in X_train for item in sublist]\n",
    "y_train = [item for sublist in y_train for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7af0cfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START',\n",
       " 'START']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa2b2833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मीराबाई', 'जोधपुर', 'बचपन', 'मीराबाई', 'एक', 'सभी', 'मीरा', 'बारात', 'बस', 'बाद', 'इस', 'शादी', 'ससुराल', 'उनके', 'जब', 'मीराबाई', 'उसने', 'राणा', 'वह', 'राणा', '’', 'इस', 'हालांकि', 'कृष्ण', 'वे', 'मीरा', 'मीरा', 'उसने', 'यहां', 'ध्यान', 'राणा', 'जब', 'वे', 'मीरा', 'ललिता', 'खैर', 'माना', 'ऐसा', '“इंसान', 'यही', 'विवाह', 'आज', 'कुछ', 'ऐसे', 'कृष्ण', 'उनके', 'यह', 'ऐसे', 'यहां', 'उनके', 'लेकिन', 'दरअसल', 'वह', 'दुर्भाग्य', 'मीरा', 'बाद', 'लोग', 'यह', 'पति', 'उन', 'इसलिए', 'उन्होंने', 'लोग', 'इस', 'दरअसल', 'जब', 'मेरा', 'तो', 'यह', 'मान', 'आप', 'तो', 'लेकिन', 'इस', 'यही', 'यह', 'भक्ति', 'भक्ति', '”', 'मीरा', 'उन्होंने', 'मीराबाई', 'अगर', 'आज', '’', 'वह', 'मीरा', 'भक्तिपूर्ण', 'वही', 'स्वयं', 'मीरा', 'उनके', 'उनमें', 'उनके', 'मीरा', 'मीरा', 'प्रेम', 'मेरे', 'जाके', 'छांड़ि', 'संतन', 'अंसुवन', 'दधि', 'भगत', 'दासी', 'पायो', 'बस्तु', 'जनम', 'खरचै', 'सत', 'मीरा', '।']\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7f22437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ec415",
   "metadata": {},
   "source": [
    "This function takes two arrays (`arr1` and `arr2`) and shuffles them in the same order, ensuring that the elements in both arrays correspond to each other after the shuffle. This is useful in randomizing the order of elements while maintaining the relationship between two sets of data.For thi purpose we've implemented the Fisher-Yates shuffle algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f4e9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fisher_yates (arr1, arr2):\n",
    "     \n",
    "    # We will Start from the last element\n",
    "    # and swap one by one.\n",
    "    n = len(arr1)\n",
    "    if n != len(arr2):\n",
    "        return None\n",
    "    \n",
    "    for i in range(n - 1, 0, -1):\n",
    "\n",
    "        # Pick a random index from 0 to i\n",
    "        j = random.randint(0, i)\n",
    "        #print(i, j)\n",
    "\n",
    "        # Swap arr[i] with the element at random index\n",
    "        arr1[i], arr1[j] = arr1[j], arr1[i]\n",
    "        arr2[i], arr2[j] = arr2[j], arr2[i]\n",
    "        \n",
    "    return arr1, arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dfee5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = fisher_yates(X_train, y_train)\n",
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "359989ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['सभी', 'मेरा', 'जब', 'मीराबाई', 'प्रेम', 'मीराबाई', 'हालांकि', 'इस', 'मीरा', 'मेरे', 'मीराबाई', 'तो', 'स्वयं', 'खरचै', 'दरअसल', 'वही', 'मीरा', 'पायो', 'एक', 'उनके', 'यहां', 'जाके', 'कृष्ण', 'यही', 'मीरा', 'कुछ', 'दरअसल', 'विवाह', 'उसने', 'दुर्भाग्य', 'पति', 'उनके', 'मीरा', 'लोग', 'उन्होंने', 'दधि', 'तो', 'ससुराल', 'माना', '।', 'आप', 'यह', 'खैर', 'यह', 'भक्तिपूर्ण', 'ऐसे', '’', 'राणा', 'मीरा', 'बारात', 'बचपन', 'जब', 'जब', 'ललिता', 'उन', 'इस', 'ध्यान', 'संतन', 'ऐसे', 'मीरा', 'बस्तु', 'दासी', 'कृष्ण', 'सत', 'उनके', '”', 'उन्होंने', 'वह', 'लोग', 'यह', 'यही', 'इस', '“इंसान', 'मीराबाई', 'वे', 'मान', 'यह', 'शादी', 'वह', 'वह', 'मीरा', 'छांड़ि', 'इसलिए', 'मीरा', 'बाद', 'बाद', '’', 'भक्ति', 'इस', 'उनके', 'लेकिन', 'यहां', 'जोधपुर', 'वे', 'अगर', 'ऐसा', 'उनमें', 'बस', 'मीरा', 'आज', 'लेकिन', 'राणा', 'उनके', 'मीरा', 'अंसुवन', 'जनम', 'भगत', 'राणा', 'मीरा', 'भक्ति', 'आज', 'उसने']\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4596860",
   "metadata": {},
   "source": [
    "The code below assumes that `X_train` and `y_train` contain words that are present in the `word_to_index` mapping. If any word is not found in the mapping, it won't be included in the `X_tokens` and `y_tokens` lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99bf37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = [[word_to_index[symbol]] for symbol,word in zip(X_train, y_train) if word in word_to_index]\n",
    "y_tokens = [[word_to_index[word]] for symbol,word in zip(X_train, y_train) if word in word_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f30b81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef25201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tokens\n",
    "y_train = y_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ce29c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cb3dd55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0], [0], [0], [0], [0]], [[63], [78], [152], [1], [171]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5], y_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54149e1",
   "metadata": {},
   "source": [
    "This code helps analyze the distribution of n-grams in the text for various values of n, which is useful for understanding the linguistic patterns and structures in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80ad639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram- 2 length: 1557\n",
      "ngram- 3 length: 1723\n",
      "ngram- 4 length: 1751\n",
      "ngram- 5 length: 1755\n",
      "ngram- 6 length: 1757\n",
      "ngram- 7 length: 1757\n",
      "ngram- 8 length: 1756\n",
      "ngram- 9 length: 1755\n",
      "ngram- 10 length: 1754\n",
      "ngram- 11 length: 1753\n",
      "ngram- 12 length: 1752\n",
      "ngram- 13 length: 1751\n",
      "ngram- 14 length: 1750\n",
      "ngram- 15 length: 1749\n",
      "ngram- 16 length: 1748\n",
      "ngram- 17 length: 1747\n",
      "ngram- 18 length: 1746\n",
      "ngram- 19 length: 1745\n",
      "ngram- 20 length: 1744\n"
     ]
    }
   ],
   "source": [
    "ngrams_up_to_20 = []\n",
    "for i in range(2, 21):\n",
    "    ngram_counts = Counter(ngrams(text.split(), i))\n",
    "    print('ngram-', i, 'length:', len(ngram_counts))\n",
    "    ngrams_up_to_20.append(ngram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8f36eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('मीरा', 'के'), 13),\n",
       " (('के', 'साथ'), 11),\n",
       " (('मीरा', 'ने'), 9),\n",
       " (('के', 'लिए'), 8),\n",
       " (('है', 'कि'), 8),\n",
       " (('कृष्ण', 'की'), 7),\n",
       " (('मीरा', 'को'), 7),\n",
       " (('मीरा', 'का'), 6),\n",
       " (('के', 'बाद'), 5),\n",
       " (('कृष्ण', 'के'), 5)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_up_to_20[0].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c79d4101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('शरीर', 'मन', 'और'), 3),\n",
       " (('के', 'बालमन', 'में'), 2),\n",
       " (('उन्होंने', 'कृष्ण', 'को'), 2),\n",
       " (('मीरा', 'ने', 'अपनी'), 2),\n",
       " (('उनकी', 'माता', 'ने'), 2),\n",
       " (('कृष्ण', 'की', 'मूर्ति'), 2),\n",
       " (('के', 'बाद', 'मीरा'), 2),\n",
       " (('मूर्ति', 'के', 'सामने'), 2),\n",
       " (('जब', 'मीरा', 'ने'), 2),\n",
       " (('उसने', 'मीरा', 'को'), 2)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_up_to_20[1].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbea0546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('कृष्ण', 'के', 'प्रति', 'मीरा'), 2),\n",
       " (('के', 'प्रति', 'मीरा', 'का'), 2),\n",
       " (('प्रति', 'मीरा', 'का', 'प्रेम'), 2),\n",
       " (('शरीर', 'मन', 'और', 'भावनाओं'), 2),\n",
       " (('थी', 'कि', 'कृष्ण', 'उनके'), 2),\n",
       " (('अपने', 'दिव्य', 'प्रेमी', 'के'), 2),\n",
       " (('दिव्य', 'प्रेमी', 'के', 'साथ'), 2),\n",
       " (('जागरुकता', 'और', 'प्रेम', 'के'), 2),\n",
       " (('और', 'प्रेम', 'के', 'साथ'), 2),\n",
       " (('मीराबाई', 'के', 'बालमन', 'में'), 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_up_to_20[2].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d73c178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('मीरा', 'के'), 'मीरा', 'के')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_to_learn = bigram_counts.most_common(100)\n",
    "bigrams_to_learn[0][0], bigrams_to_learn[0][0][0], bigrams_to_learn[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d49a9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1557,\n",
       " [(('मीरा', 'के'), 13),\n",
       "  (('के', 'साथ'), 11),\n",
       "  (('मीरा', 'ने'), 9),\n",
       "  (('के', 'लिए'), 8),\n",
       "  (('है', 'कि'), 8),\n",
       "  (('कृष्ण', 'की'), 7),\n",
       "  (('मीरा', 'को'), 7),\n",
       "  (('मीरा', 'का'), 6),\n",
       "  (('के', 'बाद'), 5),\n",
       "  (('कृष्ण', 'के'), 5),\n",
       "  (('कृष्ण', 'को'), 4),\n",
       "  (('के', 'सामने'), 4),\n",
       "  (('के', 'प्रति'), 4),\n",
       "  (('मन', 'और'), 4),\n",
       "  (('थी', 'कि'), 3),\n",
       "  (('उन्होंने', 'कृष्ण'), 3),\n",
       "  (('की', 'मूर्ति'), 3),\n",
       "  (('की', 'तरह'), 3),\n",
       "  (('बाद', 'में'), 3),\n",
       "  (('जब', 'मीरा'), 3),\n",
       "  (('कि', 'मीरा'), 3),\n",
       "  (('उसने', 'मीरा'), 3),\n",
       "  (('थीं', 'और'), 3),\n",
       "  (('कि', 'वह'), 3),\n",
       "  (('लोगों', 'के'), 3),\n",
       "  (('भिजवाया', 'कि'), 3),\n",
       "  (('शरीर', 'मन'), 3),\n",
       "  (('नहीं', 'कर'), 3),\n",
       "  (('उनके', 'साथ'), 3),\n",
       "  (('मीराबाई', 'के'), 2),\n",
       "  (('के', 'बालमन'), 2),\n",
       "  (('बालमन', 'में'), 2),\n",
       "  (('में', 'कृष्ण'), 2),\n",
       "  (('वजह', 'से'), 2),\n",
       "  (('अपनी', 'चरम'), 2),\n",
       "  (('एक', 'दिन'), 2),\n",
       "  (('रही', 'थीं।'), 2),\n",
       "  (('थीं।', 'मीरा'), 2),\n",
       "  (('ने', 'अपनी'), 2),\n",
       "  (('उनकी', 'माता'), 2),\n",
       "  (('माता', 'ने'), 2),\n",
       "  (('में', 'एक'), 2),\n",
       "  (('मीराबाई', 'की'), 2),\n",
       "  (('शादी', 'के'), 2),\n",
       "  (('मीराबाई', 'ने'), 2),\n",
       "  (('मना', 'कर'), 2),\n",
       "  (('कर', 'दिया'), 2),\n",
       "  (('में', 'अपने'), 2),\n",
       "  (('बाद', 'मीरा'), 2),\n",
       "  (('की', 'पूजा'), 2),\n",
       "  (('मूर्ति', 'के'), 2),\n",
       "  (('है', 'और'), 2),\n",
       "  (('को', 'मंदिर'), 2),\n",
       "  (('प्रेमी', 'से'), 2),\n",
       "  (('राणा', 'कुंभा'), 2),\n",
       "  (('से', 'बातें'), 2),\n",
       "  (('बातें', 'कर'), 2),\n",
       "  (('कर', 'रही'), 2),\n",
       "  (('रही', 'थीं'), 2),\n",
       "  (('मीरा', 'पर'), 2),\n",
       "  (('फिर', 'भी'), 2),\n",
       "  (('प्रति', 'मीरा'), 2),\n",
       "  (('का', 'प्रेम'), 2),\n",
       "  (('शुरुआत', 'में'), 2),\n",
       "  (('था', 'लेकिन'), 2),\n",
       "  (('आम', 'लोगों'), 2),\n",
       "  (('की', 'कई'), 2),\n",
       "  (('यहां', 'तक'), 2),\n",
       "  (('तक', 'कि'), 2),\n",
       "  (('कि', 'एक'), 2),\n",
       "  (('के', 'पास'), 2),\n",
       "  (('टोकरी', 'में'), 2),\n",
       "  (('संदेश', 'भिजवाया'), 2),\n",
       "  (('फूलों', 'के'), 2),\n",
       "  (('के', 'हार'), 2),\n",
       "  (('बन', 'गया'), 2),\n",
       "  (('उस', 'पर'), 2),\n",
       "  (('कर', 'लिया।'), 2),\n",
       "  (('थीं', 'कि'), 2),\n",
       "  (('जाता', 'है'), 2),\n",
       "  (('और', 'भावनाओं'), 2),\n",
       "  (('को', 'समर्पित'), 2),\n",
       "  (('खुद', 'को'), 2),\n",
       "  (('कि', 'आप'), 2),\n",
       "  (('पहुंच', 'गया'), 2),\n",
       "  (('उनके', 'लिए'), 2),\n",
       "  (('कि', 'कृष्ण'), 2),\n",
       "  (('कृष्ण', 'उनके'), 2),\n",
       "  (('पति', 'को'), 2),\n",
       "  (('क्योंकि', 'वह'), 2),\n",
       "  (('अपने', 'दिव्य'), 2),\n",
       "  (('दिव्य', 'प्रेमी'), 2),\n",
       "  (('प्रेमी', 'के'), 2),\n",
       "  (('उनके', 'पति'), 2),\n",
       "  (('यह', 'सब'), 2),\n",
       "  (('लेकिन', 'वह'), 2),\n",
       "  (('कि', 'आखिर'), 2),\n",
       "  (('आखिर', 'मीरा'), 2),\n",
       "  (('तरह', 'के'), 2),\n",
       "  (('कि', 'वे'), 2),\n",
       "  (('कोई', 'और'), 2),\n",
       "  (('वहां', 'से'), 2),\n",
       "  (('कर', 'रहे'), 2),\n",
       "  (('मत', 'या'), 2),\n",
       "  (('आराम', 'से'), 2),\n",
       "  (('बैठे', 'हैं'), 2),\n",
       "  (('है।', 'यह'), 2),\n",
       "  (('जागरुकता', 'और'), 2),\n",
       "  (('और', 'प्रेम'), 2),\n",
       "  (('प्रेम', 'के'), 2),\n",
       "  (('यही', 'भक्ति'), 2),\n",
       "  (('भक्ति', 'है।'), 2),\n",
       "  (('है।', 'भक्ति'), 2),\n",
       "  (('जीव', 'गोसांई'), 2),\n",
       "  (('वृंदावन', 'में'), 2),\n",
       "  (('थे।', 'मीरा'), 2),\n",
       "  (('उन्होंने', 'मीरा'), 2),\n",
       "  (('मीरा', 'से'), 2),\n",
       "  (('से', 'मिलने'), 2),\n",
       "  (('पदों', 'में'), 2),\n",
       "  (('अन्य', 'संतों'), 2),\n",
       "  (('संतों', 'की'), 2),\n",
       "  (('प्रेम', 'की'), 2),\n",
       "  (('की', 'ऐसी'), 1),\n",
       "  (('ऐसी', 'छवि'), 1),\n",
       "  (('छवि', 'बसी'), 1),\n",
       "  (('बसी', 'थी'), 1),\n",
       "  (('कि', 'किशोरावस्था'), 1),\n",
       "  (('किशोरावस्था', 'से'), 1),\n",
       "  (('से', 'लेकर'), 1),\n",
       "  (('लेकर', 'मृत्यु'), 1),\n",
       "  (('मृत्यु', 'तक'), 1),\n",
       "  (('तक', 'उन्होंने'), 1),\n",
       "  (('को', 'ही'), 1),\n",
       "  (('ही', 'अपना'), 1),\n",
       "  (('अपना', 'सब'), 1),\n",
       "  (('सब', 'कुछ'), 1),\n",
       "  (('कुछ', 'माना।'), 1),\n",
       "  (('माना।', 'जोधपुर'), 1),\n",
       "  (('जोधपुर', 'के'), 1),\n",
       "  (('के', 'राठौड़'), 1),\n",
       "  (('राठौड़', 'रतनसिंह'), 1),\n",
       "  (('रतनसिंह', 'जी'), 1),\n",
       "  (('जी', 'की'), 1),\n",
       "  (('की', 'इकलौती'), 1),\n",
       "  (('इकलौती', 'पुत्री'), 1),\n",
       "  (('पुत्री', 'मीराबाई'), 1),\n",
       "  (('मीराबाई', 'का'), 1),\n",
       "  (('का', 'जन्म'), 1),\n",
       "  (('जन्म', 'सोलहवीं'), 1),\n",
       "  (('सोलहवीं', 'शताब्दी'), 1),\n",
       "  (('शताब्दी', 'में'), 1),\n",
       "  (('में', 'हुआ'), 1),\n",
       "  (('हुआ', 'था।'), 1),\n",
       "  (('था।', 'बचपन'), 1),\n",
       "  (('बचपन', 'से'), 1),\n",
       "  (('से', 'ही'), 1),\n",
       "  (('ही', 'वह'), 1),\n",
       "  (('वह', 'कृष्णभक्ति'), 1),\n",
       "  (('कृष्णभक्ति', 'में'), 1),\n",
       "  (('में', 'रम'), 1),\n",
       "  (('रम', 'गई'), 1),\n",
       "  (('गई', 'थीं।'), 1),\n",
       "  (('थीं।', 'मीराबाई'), 1),\n",
       "  (('के', 'बचपन'), 1),\n",
       "  (('बचपन', 'में'), 1),\n",
       "  (('में', 'हुई'), 1),\n",
       "  (('हुई', 'एक'), 1),\n",
       "  (('एक', 'घटना'), 1),\n",
       "  (('घटना', 'की'), 1),\n",
       "  (('की', 'वजह'), 1),\n",
       "  (('से', 'उनका'), 1),\n",
       "  (('उनका', 'कृष्णप्रेम'), 1),\n",
       "  (('कृष्णप्रेम', 'अपनी'), 1),\n",
       "  (('चरम', 'अवस्था'), 1),\n",
       "  (('अवस्था', 'तक'), 1),\n",
       "  (('तक', 'पहुंचा।'), 1),\n",
       "  (('पहुंचा।', 'एक'), 1),\n",
       "  (('दिन', 'उनके'), 1),\n",
       "  (('उनके', 'पड़ोस'), 1),\n",
       "  (('पड़ोस', 'में'), 1),\n",
       "  (('में', 'किसी'), 1),\n",
       "  (('किसी', 'बड़े'), 1),\n",
       "  (('बड़े', 'आदमी'), 1),\n",
       "  (('आदमी', 'के'), 1),\n",
       "  (('के', 'यहां'), 1),\n",
       "  (('यहां', 'बारात'), 1),\n",
       "  (('बारात', 'आई।'), 1),\n",
       "  (('आई।', 'सभी'), 1),\n",
       "  (('सभी', 'औरतें'), 1),\n",
       "  (('औरतें', 'छत'), 1),\n",
       "  (('छत', 'पर'), 1),\n",
       "  (('पर', 'खड़ी'), 1),\n",
       "  (('खड़ी', 'होकर'), 1),\n",
       "  (('होकर', 'बारात'), 1),\n",
       "  (('बारात', 'देख'), 1),\n",
       "  (('देख', 'रही'), 1),\n",
       "  (('मीरा', 'भी'), 1),\n",
       "  (('भी', 'बारात'), 1),\n",
       "  (('बारात', 'देखने'), 1),\n",
       "  (('देखने', 'लगीं।'), 1),\n",
       "  (('लगीं।', 'बारात'), 1),\n",
       "  (('बारात', 'को'), 1),\n",
       "  (('को', 'देख'), 1),\n",
       "  (('देख', 'मीरा'), 1),\n",
       "  (('अपनी', 'माता'), 1),\n",
       "  (('माता', 'से'), 1),\n",
       "  (('से', 'पूछा'), 1),\n",
       "  (('पूछा', 'कि'), 1),\n",
       "  (('कि', 'मेरा'), 1),\n",
       "  (('मेरा', 'दूल्हा'), 1),\n",
       "  (('दूल्हा', 'कौन'), 1),\n",
       "  (('कौन', 'है'), 1),\n",
       "  (('है', 'इस'), 1),\n",
       "  (('इस', 'पर'), 1),\n",
       "  (('पर', 'उनकी'), 1),\n",
       "  (('ने', 'कृष्ण'), 1),\n",
       "  (('मूर्ति', 'की'), 1),\n",
       "  (('की', 'ओर'), 1),\n",
       "  (('ओर', 'इशारा'), 1),\n",
       "  (('इशारा', 'कर'), 1),\n",
       "  (('कर', 'के'), 1),\n",
       "  (('के', 'कह'), 1),\n",
       "  (('कह', 'दिया'), 1),\n",
       "  (('दिया', 'कि'), 1),\n",
       "  (('कि', 'यही'), 1),\n",
       "  (('यही', 'तुम्हारे'), 1),\n",
       "  (('तुम्हारे', 'दूल्हा'), 1),\n",
       "  (('दूल्हा', 'हैं।'), 1),\n",
       "  (('हैं।', 'बस'), 1),\n",
       "  (('बस', 'यह'), 1),\n",
       "  (('यह', 'बात'), 1),\n",
       "  (('बात', 'मीरा'), 1),\n",
       "  (('एक', 'गांठ'), 1),\n",
       "  (('गांठ', 'की'), 1),\n",
       "  (('तरह', 'बंध'), 1),\n",
       "  (('बंध', 'गई।'), 1),\n",
       "  (('गई।', 'बाद'), 1),\n",
       "  (('में', 'मीराबाई'), 1),\n",
       "  (('की', 'शादी'), 1),\n",
       "  (('शादी', 'महाराणा'), 1),\n",
       "  (('महाराणा', 'सांगा'), 1),\n",
       "  (('सांगा', 'के'), 1),\n",
       "  (('के', 'पुत्र'), 1),\n",
       "  (('पुत्र', 'भोजराज'), 1),\n",
       "  (('भोजराज', 'जो'), 1),\n",
       "  (('जो', 'आगे'), 1),\n",
       "  (('आगे', 'चलकर'), 1),\n",
       "  (('चलकर', 'महाराणा'), 1),\n",
       "  (('महाराणा', 'कुंभा'), 1),\n",
       "  (('कुंभा', 'कहलाए'), 1),\n",
       "  (('कहलाए', 'से'), 1),\n",
       "  (('से', 'कर'), 1),\n",
       "  (('कर', 'दी'), 1),\n",
       "  (('दी', 'गई।'), 1),\n",
       "  (('गई।', 'इस'), 1),\n",
       "  (('इस', 'शादी'), 1),\n",
       "  (('लिए', 'पहले'), 1),\n",
       "  (('पहले', 'तो'), 1),\n",
       "  (('तो', 'मीराबाई'), 1),\n",
       "  (('ने', 'मना'), 1),\n",
       "  (('दिया', 'लेकिन'), 1),\n",
       "  (('लेकिन', 'जोर'), 1),\n",
       "  (('जोर', 'देने'), 1),\n",
       "  (('देने', 'पर'), 1),\n",
       "  (('पर', 'वह'), 1),\n",
       "  (('वह', 'फूटफूट'), 1),\n",
       "  (('फूटफूट', 'कर'), 1),\n",
       "  (('कर', 'रोने'), 1),\n",
       "  (('रोने', 'लगीं।'), 1),\n",
       "  (('लगीं।', 'शादी'), 1),\n",
       "  (('बाद', 'विदाई'), 1),\n",
       "  (('विदाई', 'के'), 1),\n",
       "  (('के', 'समय'), 1),\n",
       "  (('समय', 'वे'), 1),\n",
       "  (('वे', 'कृष्ण'), 1),\n",
       "  (('की', 'वही'), 1),\n",
       "  (('वही', 'मूर्ति'), 1),\n",
       "  (('मूर्ति', 'अपने'), 1),\n",
       "  (('अपने', 'साथ'), 1),\n",
       "  (('साथ', 'ले'), 1),\n",
       "  (('ले', 'गईं'), 1),\n",
       "  (('गईं', 'जिसे'), 1),\n",
       "  (('जिसे', 'उनकी'), 1),\n",
       "  (('ने', 'उनका'), 1),\n",
       "  (('उनका', 'दूल्हा'), 1),\n",
       "  (('दूल्हा', 'बताया'), 1),\n",
       "  (('बताया', 'था।'), 1),\n",
       "  (('था।', 'ससुराल'), 1),\n",
       "  (('ससुराल', 'में'), 1),\n",
       "  (('अपने', 'घरेलू'), 1),\n",
       "  (('घरेलू', 'कामकाज'), 1),\n",
       "  (('कामकाज', 'निबटाने'), 1),\n",
       "  (('निबटाने', 'के'), 1),\n",
       "  (('मीरा', 'रोज'), 1),\n",
       "  (('रोज', 'कृष्ण'), 1),\n",
       "  (('के', 'मंदिर'), 1),\n",
       "  (('मंदिर', 'चली'), 1),\n",
       "  (('चली', 'जातीं'), 1),\n",
       "  (('जातीं', 'और'), 1),\n",
       "  (('और', 'कृष्ण'), 1),\n",
       "  (('पूजा', 'करतीं'), 1),\n",
       "  (('करतीं', 'उनकी'), 1),\n",
       "  (('उनकी', 'मूर्ति'), 1),\n",
       "  (('सामने', 'गातीं'), 1),\n",
       "  (('गातीं', 'और'), 1),\n",
       "  (('और', 'नृत्य'), 1),\n",
       "  (('नृत्य', 'करतीं।'), 1),\n",
       "  (('करतीं।', 'उनके'), 1),\n",
       "  (('उनके', 'ससुराल'), 1),\n",
       "  (('ससुराल', 'वाले'), 1),\n",
       "  (('वाले', 'तुलजा'), 1),\n",
       "  (('तुलजा', 'भवानी'), 1),\n",
       "  (('भवानी', 'यानी'), 1),\n",
       "  (('यानी', 'दुर्गा'), 1),\n",
       "  (('दुर्गा', 'को'), 1),\n",
       "  (('को', 'कुलदेवी'), 1),\n",
       "  (('कुलदेवी', 'मानते'), 1),\n",
       "  (('मानते', 'थे।'), 1),\n",
       "  (('थे।', 'जब'), 1),\n",
       "  (('ने', 'कुलदेवी'), 1),\n",
       "  (('कुलदेवी', 'की'), 1),\n",
       "  (('पूजा', 'करने'), 1),\n",
       "  (('करने', 'से'), 1),\n",
       "  (('से', 'इनकार'), 1),\n",
       "  (('इनकार', 'कर'), 1),\n",
       "  (('दिया', 'तो'), 1),\n",
       "  (('तो', 'परिवार'), 1),\n",
       "  (('परिवार', 'वालों'), 1),\n",
       "  (('वालों', 'ने'), 1),\n",
       "  (('ने', 'उनकी'), 1),\n",
       "  (('उनकी', 'श्रद्धाभक्ति'), 1),\n",
       "  (('श्रद्धाभक्ति', 'को'), 1),\n",
       "  (('को', 'मंजूरी'), 1),\n",
       "  (('मंजूरी', 'नहीं'), 1),\n",
       "  (('नहीं', 'दी।'), 1),\n",
       "  (('दी।', 'मीराबाई'), 1),\n",
       "  (('की', 'ननद'), 1),\n",
       "  (('ननद', 'उदाबाई'), 1),\n",
       "  (('उदाबाई', 'ने'), 1),\n",
       "  (('ने', 'उन्हें'), 1),\n",
       "  (('उन्हें', 'बदनाम'), 1),\n",
       "  (('बदनाम', 'करने'), 1),\n",
       "  (('करने', 'के'), 1),\n",
       "  (('लिए', 'उनके'), 1),\n",
       "  (('उनके', 'खिलाफ'), 1),\n",
       "  (('खिलाफ', 'एक'), 1),\n",
       "  (('एक', 'साजिश'), 1),\n",
       "  (('साजिश', 'रची।'), 1),\n",
       "  (('रची।', 'उसने'), 1),\n",
       "  (('उसने', 'राणा'), 1),\n",
       "  (('राणा', 'से'), 1),\n",
       "  (('से', 'कहा'), 1),\n",
       "  (('कहा', 'कि'), 1),\n",
       "  (('का', 'किसी'), 1),\n",
       "  (('किसी', 'के'), 1),\n",
       "  (('साथ', 'गुप्त'), 1),\n",
       "  (('गुप्त', 'प्रेम'), 1),\n",
       "  (('प्रेम', 'है'), 1),\n",
       "  (('और', 'उसने'), 1),\n",
       "  (('मंदिर', 'में'), 1),\n",
       "  (('अपने', 'प्रेमी'), 1),\n",
       "  (('से', 'बात'), 1),\n",
       "  (('बात', 'करते'), 1),\n",
       "  (('करते', 'देखा'), 1),\n",
       "  (('देखा', 'है।'), 1),\n",
       "  (('है।', 'राणा'), 1),\n",
       "  (('कुंभा', 'अपनी'), 1),\n",
       "  (('अपनी', 'बहन'), 1),\n",
       "  (('बहन', 'के'), 1),\n",
       "  (('साथ', 'आधी'), 1),\n",
       "  (('आधी', 'रात'), 1),\n",
       "  (('रात', 'को'), 1),\n",
       "  (('मंदिर', 'गया।'), 1),\n",
       "  (('गया।', 'वह'), 1),\n",
       "  (('वह', 'मंदिर'), 1),\n",
       "  (('मंदिर', 'का'), 1),\n",
       "  (('का', 'दरवाजा'), 1),\n",
       "  (('दरवाजा', 'तोड़'), 1),\n",
       "  (('तोड़', 'कर'), 1),\n",
       "  (('कर', 'अंदर'), 1),\n",
       "  (('अंदर', 'पहुंचा'), 1),\n",
       "  (('पहुंचा', 'और'), 1),\n",
       "  (('और', 'देखा'), 1),\n",
       "  (('देखा', 'कि'), 1),\n",
       "  (('मीरा', 'अकेले'), 1),\n",
       "  (('अकेले', 'ही'), 1),\n",
       "  (('ही', 'कृष्ण'), 1),\n",
       "  (('सामने', 'परम'), 1),\n",
       "  (('परम', 'आनंद'), 1),\n",
       "  (('आनंद', 'की'), 1),\n",
       "  (('की', 'अवस्था'), 1),\n",
       "  (('अवस्था', 'में'), 1),\n",
       "  (('में', 'बैठी'), 1),\n",
       "  (('बैठी', 'मूर्ति'), 1),\n",
       "  (('मूर्ति', 'से'), 1),\n",
       "  (('और', 'मस्ती'), 1),\n",
       "  (('मस्ती', 'में'), 1),\n",
       "  (('में', 'गा'), 1),\n",
       "  (('गा', 'रही'), 1),\n",
       "  (('थीं।', 'राणा'), 1),\n",
       "  (('राणा', 'मीरा'), 1),\n",
       "  (('पर', 'चिल्लाया'), 1),\n",
       "  (('चिल्लाया', '’मीरा'), 1),\n",
       "  (('’मीरा', 'तुम'), 1),\n",
       "  (('तुम', 'जिस'), 1),\n",
       "  (('जिस', 'प्रेमी'), 1),\n",
       "  (('से', 'अभी'), 1),\n",
       "  (('अभी', 'बातें'), 1),\n",
       "  (('रही', 'हो'), 1),\n",
       "  (('हो', 'उसे'), 1),\n",
       "  (('उसे', 'मेरे'), 1),\n",
       "  (('मेरे', 'सामने'), 1),\n",
       "  (('सामने', 'लाओ।’'), 1),\n",
       "  (('लाओ।’', 'मीरा'), 1),\n",
       "  (('ने', 'जवाब'), 1),\n",
       "  (('जवाब', 'दिया'), 1),\n",
       "  (('दिया', '–'), 1),\n",
       "  (('–', '‘वह'), 1),\n",
       "  (('‘वह', 'सामने'), 1),\n",
       "  (('सामने', 'बैठा'), 1),\n",
       "  (('बैठा', 'है'), 1),\n",
       "  (('है', 'मेरा'), 1),\n",
       "  (('मेरा', 'स्वामी'), 1),\n",
       "  (('स्वामी', 'नैनचोर'), 1),\n",
       "  (('नैनचोर', 'जिसने'), 1),\n",
       "  (('जिसने', 'मेरा'), 1),\n",
       "  (('मेरा', 'दिल'), 1),\n",
       "  (('दिल', 'चुराया'), 1),\n",
       "  (('चुराया', 'है'), 1),\n",
       "  (('और', 'वह'), 1),\n",
       "  (('वह', 'समाधि'), 1),\n",
       "  (('समाधि', 'में'), 1),\n",
       "  (('में', 'चली'), 1),\n",
       "  (('चली', 'गईं।'), 1),\n",
       "  (('गईं।', 'इस'), 1),\n",
       "  (('इस', 'घटना'), 1),\n",
       "  (('घटना', 'से'), 1),\n",
       "  (('से', 'राणा'), 1),\n",
       "  (('कुंभा', 'का'), 1),\n",
       "  (('का', 'दिल'), 1),\n",
       "  (('दिल', 'टूट'), 1),\n",
       "  (('टूट', 'गया'), 1),\n",
       "  (('गया', 'लेकिन'), 1),\n",
       "  (('लेकिन', 'फिर'), 1),\n",
       "  (('भी', 'उसने'), 1),\n",
       "  (('उसने', 'एक'), 1),\n",
       "  (('एक', 'अच्छे'), 1),\n",
       "  (('अच्छे', 'पति'), 1),\n",
       "  (('पति', 'की'), 1),\n",
       "  (('की', 'भूमिका'), 1),\n",
       "  (('भूमिका', 'निभाई'), 1),\n",
       "  (('निभाई', 'और'), 1),\n",
       "  (('और', 'मरते'), 1),\n",
       "  (('मरते', 'दम'), 1),\n",
       "  (('दम', 'तक'), 1),\n",
       "  (('तक', 'मीरा'), 1),\n",
       "  (('का', 'साथ'), 1),\n",
       "  (('साथ', 'दिया।'), 1),\n",
       "  (('दिया।', 'हालांकि'), 1),\n",
       "  (('हालांकि', 'मीरा'), 1),\n",
       "  (('को', 'राजगद्दी'), 1),\n",
       "  (('राजगद्दी', 'की'), 1),\n",
       "  (('की', 'कोई'), 1),\n",
       "  (('कोई', 'चाह'), 1),\n",
       "  (('चाह', 'नहीं'), 1),\n",
       "  (('नहीं', 'थी'), 1),\n",
       "  (('थी', 'फिर'), 1),\n",
       "  (('भी', 'राणा'), 1),\n",
       "  (('राणा', 'के'), 1),\n",
       "  (('के', 'संबंधी'), 1),\n",
       "  (('संबंधी', 'मीरा'), 1),\n",
       "  (('को', 'कई'), 1),\n",
       "  (('कई', 'तरीकों'), 1),\n",
       "  (('तरीकों', 'से'), 1),\n",
       "  (('से', 'सताने'), 1),\n",
       "  (('सताने', 'लगे।'), 1),\n",
       "  (('लगे।', 'कृष्ण'), 1),\n",
       "  (('प्रेम', 'शुरुआत'), 1),\n",
       "  (('में', 'बेहद'), 1),\n",
       "  (('बेहद', 'निजी'), 1),\n",
       "  (('निजी', 'था'), 1),\n",
       "  (('लेकिन', 'बाद'), 1),\n",
       "  (('में', 'कभीकभी'), 1),\n",
       "  (('कभीकभी', 'मीरा'), 1),\n",
       "  (('के', 'मन'), 1),\n",
       "  (('मन', 'में'), 1),\n",
       "  (('में', 'प्रेमानंद'), 1),\n",
       "  (('प्रेमानंद', 'इतना'), 1),\n",
       "  (('इतना', 'उमड़'), 1),\n",
       "  (('उमड़', 'पड़ता'), 1),\n",
       "  (('पड़ता', 'था'), 1),\n",
       "  (('था', 'कि'), 1),\n",
       "  (('वह', 'आम'), 1),\n",
       "  (('सामने', 'और'), 1),\n",
       "  (('और', 'धार्मिक'), 1),\n",
       "  (('धार्मिक', 'उत्सवों'), 1),\n",
       "  (('उत्सवों', 'में'), 1),\n",
       "  (('में', 'नाचनेगाने'), 1),\n",
       "  (('नाचनेगाने', 'लगती'), 1),\n",
       "  (('लगती', 'थीं।'), 1),\n",
       "  (('थीं।', 'वे'), 1),\n",
       "  (('वे', 'रात'), 1),\n",
       "  (('रात', 'में'), 1),\n",
       "  (('में', 'चुपचाप'), 1),\n",
       "  (('चुपचाप', 'चित्तौड़'), 1),\n",
       "  (('चित्तौड़', 'के'), 1),\n",
       "  (('के', 'किले'), 1),\n",
       "  (('किले', 'से'), 1),\n",
       "  (('से', 'निकल'), 1),\n",
       "  (('निकल', 'जाती'), 1),\n",
       "  (('जाती', 'थीं'), 1),\n",
       "  (('और', 'नगर'), 1),\n",
       "  (('नगर', 'में'), 1),\n",
       "  (('में', 'चल'), 1),\n",
       "  (('चल', 'रहे'), 1),\n",
       "  (('रहे', 'सत्संग'), 1),\n",
       "  (('सत्संग', 'में'), 1),\n",
       "  (('में', 'हिस्सा'), 1),\n",
       "  (('हिस्सा', 'लेती'), 1),\n",
       "  (('लेती', 'थीं।'), 1),\n",
       "  (('का', 'देवर'), 1),\n",
       "  (('देवर', 'विक्रमादित्य'), 1),\n",
       "  (('विक्रमादित्य', 'जो'), 1),\n",
       "  (('जो', 'चित्तौड़गढ़'), 1),\n",
       "  (('चित्तौड़गढ़', 'का'), 1),\n",
       "  (('का', 'नया'), 1),\n",
       "  (('नया', 'राजा'), 1),\n",
       "  (('राजा', 'बना'), 1),\n",
       "  (('बना', 'बहुत'), 1),\n",
       "  (('बहुत', 'कठोर'), 1),\n",
       "  (('कठोर', 'था।'), 1),\n",
       "  (('था।', 'मीरा'), 1),\n",
       "  (('मीरा', 'की'), 1),\n",
       "  (('की', 'भक्ति'), 1),\n",
       "  (('भक्ति', 'उनका'), 1),\n",
       "  (('उनका', 'आम'), 1),\n",
       "  (('साथ', 'घुलनामिलना'), 1),\n",
       "  (('घुलनामिलना', 'और'), 1),\n",
       "  (('और', 'नारीमर्यादा'), 1),\n",
       "  (('नारीमर्यादा', 'के'), 1),\n",
       "  (('प्रति', 'उनकी'), 1),\n",
       "  (('उनकी', 'लापरवाही'), 1),\n",
       "  (('लापरवाही', 'का'), 1),\n",
       "  (('का', 'उसने'), 1),\n",
       "  (('उसने', 'कड़ा'), 1),\n",
       "  (('कड़ा', 'विरोध'), 1),\n",
       "  (('विरोध', 'किया।'), 1),\n",
       "  (('किया।', 'उसने'), 1),\n",
       "  (('को', 'मारने'), 1),\n",
       "  (('मारने', 'की'), 1),\n",
       "  (('कई', 'बार'), 1),\n",
       "  (('बार', 'कोशिश'), 1),\n",
       "  (('कोशिश', 'की।'), 1),\n",
       "  (('की।', 'यहां'), 1),\n",
       "  (('एक', 'बार'), 1),\n",
       "  (('बार', 'उसने'), 1),\n",
       "  (('पास', 'फूलों'), 1),\n",
       "  (('फूलों', 'की'), 1),\n",
       "  (('की', 'टोकरी'), 1),\n",
       "  (('एक', 'जहरीला'), 1),\n",
       "  (('जहरीला', 'सांप'), 1),\n",
       "  (('सांप', 'रखकर'), 1),\n",
       "  (('रखकर', 'भेजा'), 1),\n",
       "  (('भेजा', 'और'), 1),\n",
       "  (('और', 'मीरा'), 1),\n",
       "  (('को', 'संदेश'), 1),\n",
       "  (('कि', 'टोकरी'), 1),\n",
       "  (('में', 'फूलों'), 1),\n",
       "  (('हार', 'हैं।'), 1),\n",
       "  (('हैं।', 'ध्यान'), 1),\n",
       "  (('ध्यान', 'से'), 1),\n",
       "  (('से', 'उठने'), 1),\n",
       "  (('उठने', 'के'), 1),\n",
       "  (('बाद', 'जब'), 1),\n",
       "  (('ने', 'टोकरी'), 1),\n",
       "  (('टोकरी', 'खोली'), 1),\n",
       "  (('खोली', 'तो'), 1),\n",
       "  (('तो', 'उसमें'), 1),\n",
       "  (('उसमें', 'से'), 1),\n",
       "  (('से', 'फूलों'), 1),\n",
       "  (('हार', 'के'), 1),\n",
       "  (('साथ', 'कृष्ण'), 1),\n",
       "  (('की', 'एक'), 1),\n",
       "  (('एक', 'सुंदर'), 1),\n",
       "  (('सुंदर', 'मूर्ति'), 1),\n",
       "  (('मूर्ति', 'निकली।'), 1),\n",
       "  (('निकली।', 'राणा'), 1),\n",
       "  (('राणा', 'का'), 1),\n",
       "  (('का', 'तैयार'), 1),\n",
       "  (('तैयार', 'किया'), 1),\n",
       "  (('किया', 'हुआ'), 1),\n",
       "  (('हुआ', 'कांटो'), 1),\n",
       "  (('कांटो', 'का'), 1),\n",
       "  (('का', 'बिस्तर'), 1),\n",
       "  (('बिस्तर', 'भी'), 1),\n",
       "  (('भी', 'मीरा'), 1),\n",
       "  (('लिए', 'फूलों'), 1),\n",
       "  (('फूलों', 'का'), 1),\n",
       "  (('का', 'सेज'), 1),\n",
       "  (('सेज', 'बन'), 1),\n",
       "  (('गया', 'जब'), 1),\n",
       "  (('मीरा', 'उस'), 1),\n",
       "  (('पर', 'सोने'), 1),\n",
       "  (('सोने', 'चलीं।'), 1),\n",
       "  (('चलीं।', 'जब'), 1),\n",
       "  (('जब', 'यातनाएं'), 1),\n",
       "  (('यातनाएं', 'बरदाश्त'), 1),\n",
       "  (('बरदाश्त', 'से'), 1),\n",
       "  (('से', 'बाहर'), 1),\n",
       "  (('बाहर', 'हो'), 1),\n",
       "  (('हो', 'गईं'), 1),\n",
       "  (('गईं', 'तो'), 1),\n",
       "  (('तो', 'उन्होंने'), 1),\n",
       "  (('उन्होंने', 'चित्तौड़'), 1),\n",
       "  (('चित्तौड़', 'छोड़'), 1),\n",
       "  (('छोड़', 'दिया।'), 1),\n",
       "  (('दिया।', 'वे'), 1),\n",
       "  (('वे', 'पहले'), 1),\n",
       "  (('पहले', 'मेड़ता'), 1),\n",
       "  (('मेड़ता', 'गईं'), 1),\n",
       "  (('गईं', 'लेकिन'), 1),\n",
       "  (('लेकिन', 'जब'), 1),\n",
       "  (('जब', 'उन्हें'), 1),\n",
       "  (('उन्हें', 'वहां'), 1),\n",
       "  (('वहां', 'भी'), 1),\n",
       "  (('भी', 'संतोश'), 1),\n",
       "  (('संतोश', 'नहीं'), 1),\n",
       "  (('नहीं', 'मिला'), 1),\n",
       "  (('मिला', 'तो'), 1),\n",
       "  (('तो', 'कुछ'), 1),\n",
       "  (('कुछ', 'समय'), 1),\n",
       "  (('समय', 'के'), 1),\n",
       "  (('बाद', 'उन्होने'), 1),\n",
       "  (('उन्होने', 'कृश्णभक्ति'), 1),\n",
       "  (('कृश्णभक्ति', 'के'), 1),\n",
       "  (('के', 'केंद्र'), 1),\n",
       "  (('केंद्र', 'वृंदावन'), 1),\n",
       "  (('वृंदावन', 'का'), 1),\n",
       "  (('का', 'रुख'), 1),\n",
       "  (('रुख', 'कर'), 1),\n",
       "  (('लिया।', 'मीरा'), 1),\n",
       "  (('मीरा', 'मानती'), 1),\n",
       "  (('मानती', 'थीं'), 1),\n",
       "  (('वह', 'गोपी'), 1),\n",
       "  (('गोपी', 'ललिता'), 1),\n",
       "  (('ललिता', 'ही'), 1),\n",
       "  (('ही', 'हैं'), 1),\n",
       "  (('हैं', 'जिन्होने'), 1),\n",
       "  (('जिन्होने', 'फिर'), 1),\n",
       "  (('फिर', 'से'), 1),\n",
       "  (('से', 'जन्म'), 1),\n",
       "  (('जन्म', 'लिया'), 1),\n",
       "  (('लिया', 'है।'), 1),\n",
       "  (('है।', 'ललिता'), 1),\n",
       "  (('ललिता', 'कृष्ण'), 1),\n",
       "  (('के', 'प्रेम'), 1),\n",
       "  (('प्रेम', 'में'), 1),\n",
       "  (('में', 'दीवानी'), 1),\n",
       "  (('दीवानी', 'थीं।'), 1),\n",
       "  (('थीं।', 'खैर'), 1),\n",
       "  (('खैर', 'मीरा'), 1),\n",
       "  (('अपनी', 'तीर्थयात्रा'), 1),\n",
       "  (('तीर्थयात्रा', 'जारी'), 1),\n",
       "  (('जारी', 'रखी'), 1),\n",
       "  (('रखी', 'वे'), 1),\n",
       "  (('वे', 'एक'), 1),\n",
       "  (('एक', 'गांव'), 1),\n",
       "  (('गांव', 'से'), 1),\n",
       "  (('से', 'दूसरे'), 1),\n",
       "  (('दूसरे', 'गांव'), 1),\n",
       "  (('गांव', 'नाचतीगाती'), 1),\n",
       "  (('नाचतीगाती', 'पूरे'), 1),\n",
       "  (('पूरे', 'उत्तर'), 1),\n",
       "  (('उत्तर', 'भारत'), 1),\n",
       "  (('भारत', 'में'), 1),\n",
       "  (('में', 'घूमती'), 1),\n",
       "  (('घूमती', 'रहीं।'), 1),\n",
       "  (('रहीं।', 'माना'), 1),\n",
       "  (('माना', 'जाता'), 1),\n",
       "  (('कि', 'उन्होंने'), 1),\n",
       "  (('उन्होंने', 'अपने'), 1),\n",
       "  (('अपने', 'जीवन'), 1),\n",
       "  (('जीवन', 'के'), 1),\n",
       "  (('के', 'अंतिम'), 1),\n",
       "  (('अंतिम', 'कुछ'), 1),\n",
       "  (('कुछ', 'साल'), 1),\n",
       "  (('साल', 'गुजरात'), 1),\n",
       "  (('गुजरात', 'के'), 1),\n",
       "  (('के', 'द्वारका'), 1),\n",
       "  (('द्वारका', 'में'), 1),\n",
       "  (('में', 'गुजारे।'), 1),\n",
       "  (('गुजारे।', 'ऐसा'), 1),\n",
       "  (('ऐसा', 'कहा'), 1),\n",
       "  (('कहा', 'जाता'), 1),\n",
       "  (('कि', 'दर्शकों'), 1),\n",
       "  (('दर्शकों', 'की'), 1),\n",
       "  (('की', 'पूरी'), 1),\n",
       "  (('पूरी', 'भीड़'), 1),\n",
       "  (('भीड़', 'के'), 1),\n",
       "  (('सामने', 'मीरा'), 1),\n",
       "  (('मीरा', 'द्वारकाधीश'), 1),\n",
       "  (('द्वारकाधीश', 'की'), 1),\n",
       "  (('मूर्ति', 'में'), 1),\n",
       "  (('में', 'समा'), 1),\n",
       "  (('समा', 'गईं।'), 1),\n",
       "  (('गईं।', '“इंसान'), 1),\n",
       "  (('“इंसान', 'आमतौर'), 1),\n",
       "  (('आमतौर', 'पर'), 1),\n",
       "  (('पर', 'शरीर'), 1),\n",
       "  (('और', 'बहुत'), 1),\n",
       "  (('बहुत', 'सारी'), 1),\n",
       "  (('सारी', 'भावनाओं'), 1),\n",
       "  (('भावनाओं', 'से'), 1),\n",
       "  (('से', 'बना'), 1),\n",
       "  (('बना', 'है।'), 1),\n",
       "  (('है।', 'यही'), 1),\n",
       "  (('यही', 'वजह'), 1),\n",
       "  (('वजह', 'है'), 1),\n",
       "  (('कि', 'ज्यादातर'), 1),\n",
       "  (('ज्यादातर', 'लोग'), 1),\n",
       "  (('लोग', 'अपने'), 1),\n",
       "  (('अपने', 'शरीर'), 1),\n",
       "  (('भावनाओं', 'को'), 1),\n",
       "  (('समर्पित', 'किए'), 1),\n",
       "  (('किए', 'बिना'), 1),\n",
       "  (('बिना', 'किसी'), 1),\n",
       "  (('किसी', 'चीज'), 1),\n",
       "  (('चीज', 'के'), 1),\n",
       "  (('प्रति', 'खुद'), 1),\n",
       "  (('समर्पित', 'नहीं'), 1),\n",
       "  (('कर', 'सकते।'), 1),\n",
       "  (('सकते।', 'विवाह'), 1),\n",
       "  (('विवाह', 'का'), 1),\n",
       "  (('का', 'मतलब'), 1),\n",
       "  (('मतलब', 'यही'), 1),\n",
       "  (('यही', 'है'), 1),\n",
       "  (('आप', 'एक'), 1),\n",
       "  (('एक', 'इंसान'), 1),\n",
       "  (('इंसान', 'के'), 1),\n",
       "  (('लिए', 'अपनी'), 1),\n",
       "  (('अपनी', 'हर'), 1),\n",
       "  (('हर', 'चीज'), 1),\n",
       "  (('चीज', 'समर्पित'), 1),\n",
       "  (('समर्पित', 'कर'), 1),\n",
       "  (('कर', 'दें'), 1),\n",
       "  (('दें', 'अपना'), 1),\n",
       "  (('अपना', 'शरीर'), 1),\n",
       "  (('शरीर', 'अपना'), 1),\n",
       "  (('अपना', 'मन'), 1),\n",
       "  (('और', 'अपनी'), 1),\n",
       "  (('अपनी', 'भावनाएं।'), 1),\n",
       "  (('भावनाएं।', 'आज'), 1),\n",
       "  (('आज', 'भी'), 1),\n",
       "  (('भी', 'कई'), 1),\n",
       "  (('कई', 'इसाई'), 1),\n",
       "  (('इसाई', 'संप्रदायों'), 1),\n",
       "  (('संप्रदायों', 'में'), 1),\n",
       "  (('में', 'नन'), 1),\n",
       "  (('नन', 'बनने'), 1),\n",
       "  (('बनने', 'की'), 1),\n",
       "  (('की', 'दीक्षा'), 1),\n",
       "  (('दीक्षा', 'पाने'), 1),\n",
       "  (('पाने', 'के'), 1),\n",
       "  (('लिए', 'लड़कियां'), 1),\n",
       "  (('लड़कियां', 'पहले'), 1),\n",
       "  (('पहले', 'जीसस'), 1),\n",
       "  (('जीसस', 'के'), 1),\n",
       "  (('साथ', 'विवाह'), 1),\n",
       "  (('विवाह', 'करती'), 1),\n",
       "  (('करती', 'हैं।'), 1),\n",
       "  (('हैं।', 'कुछ'), 1),\n",
       "  (('कुछ', 'लोगों'), 1),\n",
       "  (('लिए', 'यह'), 1),\n",
       "  (('यह', 'समर्पण'), 1),\n",
       "  (('समर्पण', 'शरीर'), 1),\n",
       "  (('भावनाओं', 'के'), 1),\n",
       "  (('के', 'परे'), 1),\n",
       "  (('परे', 'एक'), 1),\n",
       "  (('एक', 'ऐसे'), 1),\n",
       "  (('ऐसे', 'धरातल'), 1),\n",
       "  (('धरातल', 'पर'), 1),\n",
       "  (('पर', 'पहुंच'), 1),\n",
       "  (('गया', 'जो'), 1),\n",
       "  (('जो', 'बिलकुल'), 1),\n",
       "  (('बिलकुल', 'अलग'), 1),\n",
       "  (('अलग', 'था'), 1),\n",
       "  (('था', 'जहां'), 1),\n",
       "  (('जहां', 'यह'), 1),\n",
       "  (('यह', 'उनके'), 1),\n",
       "  (('लिए', 'परम'), 1),\n",
       "  (('परम', 'सत्य'), 1),\n",
       "  (('सत्य', 'बन'), 1),\n",
       "  (('गया', 'था।'), 1),\n",
       "  (('था।', 'ऐसे'), 1),\n",
       "  (('ऐसे', 'लोगों'), 1),\n",
       "  (('लोगों', 'में'), 1),\n",
       "  (('में', 'से'), 1),\n",
       "  (('से', 'एक'), 1),\n",
       "  (('एक', 'मीराबाई'), 1),\n",
       "  (('मीराबाई', 'थीं'), 1),\n",
       "  (('थीं', 'जो'), 1),\n",
       "  (('जो', 'कृष्ण'), 1),\n",
       "  (('को', 'अपना'), 1),\n",
       "  (('अपना', 'पति'), 1),\n",
       "  (('पति', 'मानती'), 1),\n",
       "  (('मानती', 'थीं।'), 1),\n",
       "  (('थीं।', 'कृष्ण'), 1),\n",
       "  (('को', 'लेकर'), 1),\n",
       "  (('लेकर', 'मीरा'), 1),\n",
       "  (('मीरा', 'इतनी'), 1),\n",
       "  (('इतनी', 'दीवानी'), 1),\n",
       "  (('दीवानी', 'थीं'), 1),\n",
       "  (('कि', 'महज'), 1),\n",
       "  (('महज', 'आठ'), 1),\n",
       "  (('आठ', 'साल'), 1),\n",
       "  (('साल', 'की'), 1),\n",
       "  (('की', 'उम्र'), 1),\n",
       "  (('उम्र', 'में'), 1),\n",
       "  (('में', 'मन'), 1),\n",
       "  (('मन', 'ही'), 1),\n",
       "  (('ही', 'मन'), 1),\n",
       "  (('मन', 'उन्होंने'), 1),\n",
       "  (('कृष्ण', 'से'), 1),\n",
       "  (('से', 'विवाह'), 1),\n",
       "  (('विवाह', 'कर'), 1),\n",
       "  (('लिया।', 'उनके'), 1),\n",
       "  (('उनके', 'भावों'), 1),\n",
       "  (('भावों', 'की'), 1),\n",
       "  (('की', 'तीव्रता'), 1),\n",
       "  (('तीव्रता', 'इतनी'), 1),\n",
       "  (('इतनी', 'गहन'), 1),\n",
       "  (('गहन', 'थी'), 1),\n",
       "  (('लिए', 'सच्चाई'), 1),\n",
       "  (('सच्चाई', 'बन'), 1),\n",
       "  (('बन', 'गए।'), 1),\n",
       "  (('गए।', 'यह'), 1),\n",
       "  (('यह', 'मीरा'), 1),\n",
       "  (('लिए', 'कोई'), 1),\n",
       "  (('कोई', 'मतिभ्रम'), 1),\n",
       "  (('मतिभ्रम', 'नहीं'), 1),\n",
       "  (('नहीं', 'था'), 1),\n",
       "  (('था', 'यह'), 1),\n",
       "  (('यह', 'एक'), 1),\n",
       "  (('एक', 'सच्चाई'), 1),\n",
       "  (('सच्चाई', 'थी'), 1),\n",
       "  (('साथ', 'उठतेबैठते'), 1),\n",
       "  (('उठतेबैठते', 'थे'), 1),\n",
       "  (('थे', 'घूमते'), 1),\n",
       "  (('घूमते', 'थे।'), 1),\n",
       "  (('थे।', 'ऐसे'), 1),\n",
       "  (('ऐसे', 'में'), 1),\n",
       "  (('में', 'मीरा'), 1),\n",
       "  (('के', 'पति'), 1),\n",
       "  (('को', 'उनके'), 1),\n",
       "  (('साथ', 'दिक्कत'), 1),\n",
       "  (('दिक्कत', 'होने'), 1),\n",
       "  (('होने', 'लगी'), 1),\n",
       "  (('लगी', 'क्योंकि'), 1),\n",
       "  (('वह', 'हमेशा'), 1),\n",
       "  (('हमेशा', 'अपने'), 1),\n",
       "  (('साथ', 'रहतीं।'), 1),\n",
       "  (('रहतीं।', 'यहां'), 1),\n",
       "  (('ने', 'अपने'), 1),\n",
       "  (('साथ', 'संभोग'), 1),\n",
       "  (('संभोग', 'भी'), 1),\n",
       "  (('भी', 'किया।'), 1),\n",
       "  (('किया।', 'उनके'), 1),\n",
       "  (('पति', 'ने'), 1),\n",
       "  (('ने', 'हर'), 1),\n",
       "  (('हर', 'संभव'), 1),\n",
       "  (('संभव', 'कोशिश'), 1),\n",
       "  (('कोशिश', 'की'), 1),\n",
       "  (('की', 'यह'), 1),\n",
       "  (('सब', 'समझने'), 1),\n",
       "  (('समझने', 'की'), 1),\n",
       "  (('की', 'क्योंकि'), 1),\n",
       "  (('वह', 'मीरा'), 1),\n",
       "  (('को', 'वाकई'), 1),\n",
       "  (('वाकई', 'प्यार'), 1),\n",
       "  (('प्यार', 'करता'), 1),\n",
       "  (('करता', 'था।'), 1),\n",
       "  (('था।', 'लेकिन'), 1),\n",
       "  (('वह', 'नहीं'), 1),\n",
       "  (('नहीं', 'जान'), 1),\n",
       "  (('जान', 'सका'), 1),\n",
       "  (('सका', 'कि'), 1),\n",
       "  (('साथ', 'हो'), 1),\n",
       "  (('हो', 'क्या'), 1),\n",
       "  (('क्या', 'रहा'), 1),\n",
       "  (('रहा', 'है।'), 1),\n",
       "  (('है।', 'दरअसल'), 1),\n",
       "  (('दरअसल', 'मीरा'), 1),\n",
       "  (('मीरा', 'जिस'), 1),\n",
       "  (('जिस', 'स्थिति'), 1),\n",
       "  (('स्थिति', 'से'), 1),\n",
       "  (('से', 'गुजर'), 1),\n",
       "  (('गुजर', 'रही'), 1),\n",
       "  (('और', 'उनके'), 1),\n",
       "  (('साथ', 'जो'), 1),\n",
       "  (('जो', 'भी'), 1),\n",
       "  (('भी', 'हो'), 1),\n",
       "  (('हो', 'रहा'), 1),\n",
       "  (('रहा', 'था'), 1),\n",
       "  (('था', 'वह'), 1),\n",
       "  (('वह', 'बहुत'), 1),\n",
       "  (('बहुत', 'वास्तविक'), 1),\n",
       "  (('वास्तविक', 'लगता'), 1),\n",
       "  (('लगता', 'था'), 1),\n",
       "  (('लेकिन', 'उनके'), 1),\n",
       "  (('को', 'कुछ'), 1),\n",
       "  (('कुछ', 'भी'), 1),\n",
       "  (('भी', 'नजर'), 1),\n",
       "  (('नजर', 'नहीं'), 1),\n",
       "  (('नहीं', 'आता'), 1),\n",
       "  (('आता', 'था।'), 1),\n",
       "  (('था।', 'वह'), 1),\n",
       "  (('वह', 'इतना'), 1),\n",
       "  (('इतना', 'निराश'), 1),\n",
       "  (('निराश', 'हो'), 1),\n",
       "  (('हो', 'गया'), 1),\n",
       "  (('गया', 'कि'), 1),\n",
       "  (('दिन', 'उसने'), 1),\n",
       "  (('उसने', 'खुद'), 1),\n",
       "  (('को', 'नीले'), 1),\n",
       "  (('नीले', 'रंग'), 1),\n",
       "  (('रंग', 'से'), 1),\n",
       "  (('से', 'पोत'), 1),\n",
       "  (('पोत', 'लिया'), 1),\n",
       "  (('लिया', 'कृष्ण'), 1),\n",
       "  (('के', 'पोशाक'), 1),\n",
       "  (('पोशाक', 'पहन'), 1),\n",
       "  (('पहन', 'कर'), 1),\n",
       "  (('कर', 'मीरा'), 1),\n",
       "  (('पास', 'आया।'), 1),\n",
       "  (('आया।', 'दुर्भाग्य'), 1),\n",
       "  (('दुर्भाग्य', 'से'), 1),\n",
       "  (('से', 'उसने'), 1),\n",
       "  (('उसने', 'गलत'), 1),\n",
       "  (('गलत', 'तरह'), 1),\n",
       "  (('के', 'रंग'), 1),\n",
       "  (('रंग', 'का'), 1),\n",
       "  (('का', 'इस्तेमाल'), 1),\n",
       "  (('इस्तेमाल', 'कर'), 1),\n",
       "  (('कर', 'लिया'), 1),\n",
       "  (('लिया', 'जिसकी'), 1),\n",
       "  (('जिसकी', 'वजह'), 1),\n",
       "  (('से', 'उसे'), 1),\n",
       "  (('उसे', 'एलर्जी'), 1),\n",
       "  (('एलर्जी', 'हो'), 1),\n",
       "  (('हो', 'गई'), 1),\n",
       "  (('गई', 'और'), 1),\n",
       "  (('और', 'शरीर'), 1),\n",
       "  (('शरीर', 'पर'), 1),\n",
       "  (('पर', 'चकत्ते'), 1),\n",
       "  (('चकत्ते', 'निकल'), 1),\n",
       "  (('निकल', 'आए।'), 1),\n",
       "  (('आए।', 'मीरा'), 1),\n",
       "  (('के', 'इर्द'), 1),\n",
       "  (('इर्द', 'गिर्द'), 1),\n",
       "  (('गिर्द', 'के'), 1),\n",
       "  (('के', 'लोग'), 1),\n",
       "  (('लोग', 'शुरुआत'), 1),\n",
       "  (('में', 'बड़े'), 1),\n",
       "  (('बड़े', 'चकराए'), 1),\n",
       "  (('चकराए', 'कि'), 1),\n",
       "  (('का', 'क्या'), 1),\n",
       "  (('क्या', 'करें।'), 1),\n",
       "  (('करें।', 'बाद'), 1),\n",
       "  (('में', 'जब'), 1),\n",
       "  (('जब', 'कृष्ण'), 1),\n",
       "  (('प्रेम', 'अपनी'), 1),\n",
       "  (('चरम', 'ऊंचाइयों'), 1),\n",
       "  (('ऊंचाइयों', 'तक'), 1),\n",
       "  (('तक', 'पहुंच'), 1),\n",
       "  (('गया', 'तब'), 1),\n",
       "  (('तब', 'लोगों'), 1),\n",
       "  (('लोगों', 'को'), 1),\n",
       "  (('को', 'यह'), 1),\n",
       "  (('यह', 'समझ'), 1),\n",
       "  (('समझ', 'आया'), 1),\n",
       "  (('आया', 'कि'), 1),\n",
       "  (('वे', 'कोई'), 1),\n",
       "  (('कोई', 'असाधारण'), 1),\n",
       "  (('असाधारण', 'औरत'), 1),\n",
       "  (('औरत', 'हैं।'), 1),\n",
       "  (('हैं।', 'लोग'), 1),\n",
       "  (('लोग', 'उनका'), 1),\n",
       "  (('उनका', 'आदर'), 1),\n",
       "  (('आदर', 'करने'), 1),\n",
       "  (('करने', 'लगे।'), 1),\n",
       "  (('लगे।', 'यह'), 1),\n",
       "  (('यह', 'देख'), 1),\n",
       "  (('देख', 'कर'), 1),\n",
       "  (('कर', 'कि'), 1),\n",
       "  (('वे', 'ऐसी'), 1),\n",
       "  (('ऐसी', 'चीजें'), 1),\n",
       "  (('चीजें', 'कर'), 1),\n",
       "  (('कर', 'सकती'), 1),\n",
       "  (('सकती', 'हैं'), 1),\n",
       "  ...])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngrams_up_to_20[0].most_common()), ngrams_up_to_20[0].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "144fdcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123,\n",
       " [(('मीरा', 'के'), 13),\n",
       "  (('के', 'साथ'), 11),\n",
       "  (('मीरा', 'ने'), 9),\n",
       "  (('के', 'लिए'), 8),\n",
       "  (('है', 'कि'), 8),\n",
       "  (('कृष्ण', 'की'), 7),\n",
       "  (('मीरा', 'को'), 7),\n",
       "  (('मीरा', 'का'), 6),\n",
       "  (('के', 'बाद'), 5),\n",
       "  (('कृष्ण', 'के'), 5),\n",
       "  (('कृष्ण', 'को'), 4),\n",
       "  (('के', 'सामने'), 4),\n",
       "  (('के', 'प्रति'), 4),\n",
       "  (('मन', 'और'), 4),\n",
       "  (('थी', 'कि'), 3),\n",
       "  (('उन्होंने', 'कृष्ण'), 3),\n",
       "  (('की', 'मूर्ति'), 3),\n",
       "  (('की', 'तरह'), 3),\n",
       "  (('बाद', 'में'), 3),\n",
       "  (('जब', 'मीरा'), 3),\n",
       "  (('कि', 'मीरा'), 3),\n",
       "  (('उसने', 'मीरा'), 3),\n",
       "  (('थीं', 'और'), 3),\n",
       "  (('कि', 'वह'), 3),\n",
       "  (('लोगों', 'के'), 3),\n",
       "  (('भिजवाया', 'कि'), 3),\n",
       "  (('शरीर', 'मन'), 3),\n",
       "  (('नहीं', 'कर'), 3),\n",
       "  (('उनके', 'साथ'), 3),\n",
       "  (('मीराबाई', 'के'), 2),\n",
       "  (('के', 'बालमन'), 2),\n",
       "  (('बालमन', 'में'), 2),\n",
       "  (('में', 'कृष्ण'), 2),\n",
       "  (('वजह', 'से'), 2),\n",
       "  (('अपनी', 'चरम'), 2),\n",
       "  (('एक', 'दिन'), 2),\n",
       "  (('रही', 'थीं।'), 2),\n",
       "  (('थीं।', 'मीरा'), 2),\n",
       "  (('ने', 'अपनी'), 2),\n",
       "  (('उनकी', 'माता'), 2),\n",
       "  (('माता', 'ने'), 2),\n",
       "  (('में', 'एक'), 2),\n",
       "  (('मीराबाई', 'की'), 2),\n",
       "  (('शादी', 'के'), 2),\n",
       "  (('मीराबाई', 'ने'), 2),\n",
       "  (('मना', 'कर'), 2),\n",
       "  (('कर', 'दिया'), 2),\n",
       "  (('में', 'अपने'), 2),\n",
       "  (('बाद', 'मीरा'), 2),\n",
       "  (('की', 'पूजा'), 2),\n",
       "  (('मूर्ति', 'के'), 2),\n",
       "  (('है', 'और'), 2),\n",
       "  (('को', 'मंदिर'), 2),\n",
       "  (('प्रेमी', 'से'), 2),\n",
       "  (('राणा', 'कुंभा'), 2),\n",
       "  (('से', 'बातें'), 2),\n",
       "  (('बातें', 'कर'), 2),\n",
       "  (('कर', 'रही'), 2),\n",
       "  (('रही', 'थीं'), 2),\n",
       "  (('मीरा', 'पर'), 2),\n",
       "  (('फिर', 'भी'), 2),\n",
       "  (('प्रति', 'मीरा'), 2),\n",
       "  (('का', 'प्रेम'), 2),\n",
       "  (('शुरुआत', 'में'), 2),\n",
       "  (('था', 'लेकिन'), 2),\n",
       "  (('आम', 'लोगों'), 2),\n",
       "  (('की', 'कई'), 2),\n",
       "  (('यहां', 'तक'), 2),\n",
       "  (('तक', 'कि'), 2),\n",
       "  (('कि', 'एक'), 2),\n",
       "  (('के', 'पास'), 2),\n",
       "  (('टोकरी', 'में'), 2),\n",
       "  (('संदेश', 'भिजवाया'), 2),\n",
       "  (('फूलों', 'के'), 2),\n",
       "  (('के', 'हार'), 2),\n",
       "  (('बन', 'गया'), 2),\n",
       "  (('उस', 'पर'), 2),\n",
       "  (('कर', 'लिया।'), 2),\n",
       "  (('थीं', 'कि'), 2),\n",
       "  (('जाता', 'है'), 2),\n",
       "  (('और', 'भावनाओं'), 2),\n",
       "  (('को', 'समर्पित'), 2),\n",
       "  (('खुद', 'को'), 2),\n",
       "  (('कि', 'आप'), 2),\n",
       "  (('पहुंच', 'गया'), 2),\n",
       "  (('उनके', 'लिए'), 2),\n",
       "  (('कि', 'कृष्ण'), 2),\n",
       "  (('कृष्ण', 'उनके'), 2),\n",
       "  (('पति', 'को'), 2),\n",
       "  (('क्योंकि', 'वह'), 2),\n",
       "  (('अपने', 'दिव्य'), 2),\n",
       "  (('दिव्य', 'प्रेमी'), 2),\n",
       "  (('प्रेमी', 'के'), 2),\n",
       "  (('उनके', 'पति'), 2),\n",
       "  (('यह', 'सब'), 2),\n",
       "  (('लेकिन', 'वह'), 2),\n",
       "  (('कि', 'आखिर'), 2),\n",
       "  (('आखिर', 'मीरा'), 2),\n",
       "  (('तरह', 'के'), 2),\n",
       "  (('कि', 'वे'), 2),\n",
       "  (('कोई', 'और'), 2),\n",
       "  (('वहां', 'से'), 2),\n",
       "  (('कर', 'रहे'), 2),\n",
       "  (('मत', 'या'), 2),\n",
       "  (('आराम', 'से'), 2),\n",
       "  (('बैठे', 'हैं'), 2),\n",
       "  (('है।', 'यह'), 2),\n",
       "  (('जागरुकता', 'और'), 2),\n",
       "  (('और', 'प्रेम'), 2),\n",
       "  (('प्रेम', 'के'), 2),\n",
       "  (('यही', 'भक्ति'), 2),\n",
       "  (('भक्ति', 'है।'), 2),\n",
       "  (('है।', 'भक्ति'), 2),\n",
       "  (('जीव', 'गोसांई'), 2),\n",
       "  (('वृंदावन', 'में'), 2),\n",
       "  (('थे।', 'मीरा'), 2),\n",
       "  (('उन्होंने', 'मीरा'), 2),\n",
       "  (('मीरा', 'से'), 2),\n",
       "  (('से', 'मिलने'), 2),\n",
       "  (('पदों', 'में'), 2),\n",
       "  (('अन्य', 'संतों'), 2),\n",
       "  (('संतों', 'की'), 2),\n",
       "  (('प्रेम', 'की'), 2)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(filter(lambda x: 1 < int(x[1]), ngrams_up_to_20[0].most_common()))\n",
    "len(l), l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47119bb6",
   "metadata": {},
   "source": [
    "The `remove_periods` function is designed to filter out n-grams that contain specific characters (periods, single quotes, etc.), within any of their constituent words. This function is used as a filter to process or clean n-grams based on the presence of specific characters within their words. It will return `True` for n-grams that don't contain those characters and `False` for n-grams that do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c676caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_periods(ngram):\n",
    "    for wrd in ngram[0]:\n",
    "        if '।' in wrd or \"’\" in wrd or \"‘\" in wrd:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f13020",
   "metadata": {},
   "source": [
    "The `my_filter` function is designed to filter a list of n-grams based on two criteria:\n",
    "\n",
    "1. The n-grams should contain at least one occurrence (count) greater than 1.\n",
    "2. The n-grams should pass the remove_periods function's filter, meaning they should not contain specific characters ('।', \"’\", or \"‘\") within any of their constituent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dae0a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(ngrams):\n",
    "    return filter(remove_periods, list(filter(lambda x: 1 < int(x[1]), ngrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da666a97",
   "metadata": {},
   "source": [
    "These `X_train_example` and `y_train_example` lists represent training data for the language model, where each element in these lists contains the index of a word in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a08cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_to_learn = ngrams_up_to_20[0]\n",
    "X_train_example = [[word_to_index[sent[0][0]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]\n",
    "y_train_example = [[word_to_index[sent[0][1]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8acdffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[71], [2], [71], [2], [81], [5], [71], [71], [2], [5]],\n",
       " [[2], [125], [75], [111], [11], [6], [18], [32], [99], [2]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_example[0:10], y_train_example[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92ef632d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 116)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_example), len(y_train_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9b6a74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('शरीर', 'मन', 'और'),\n",
       " ('के', 'बालमन', 'में'),\n",
       " ('उन्होंने', 'कृष्ण', 'को'),\n",
       " ('मीरा', 'ने', 'अपनी'),\n",
       " ('उनकी', 'माता', 'ने'),\n",
       " ('कृष्ण', 'की', 'मूर्ति'),\n",
       " ('के', 'बाद', 'मीरा'),\n",
       " ('मूर्ति', 'के', 'सामने'),\n",
       " ('जब', 'मीरा', 'ने'),\n",
       " ('उसने', 'मीरा', 'को'),\n",
       " ('बातें', 'कर', 'रही'),\n",
       " ('रही', 'थीं', 'और'),\n",
       " ('कृष्ण', 'के', 'प्रति'),\n",
       " ('के', 'प्रति', 'मीरा'),\n",
       " ('प्रति', 'मीरा', 'का'),\n",
       " ('मीरा', 'का', 'प्रेम'),\n",
       " ('आम', 'लोगों', 'के'),\n",
       " ('यहां', 'तक', 'कि'),\n",
       " ('मीरा', 'के', 'पास'),\n",
       " ('संदेश', 'भिजवाया', 'कि'),\n",
       " ('फूलों', 'के', 'हार'),\n",
       " ('मीरा', 'के', 'लिए'),\n",
       " ('जाता', 'है', 'कि'),\n",
       " ('मन', 'और', 'भावनाओं'),\n",
       " ('है', 'कि', 'आप'),\n",
       " ('थी', 'कि', 'कृष्ण'),\n",
       " ('कि', 'कृष्ण', 'उनके'),\n",
       " ('अपने', 'दिव्य', 'प्रेमी'),\n",
       " ('दिव्य', 'प्रेमी', 'के'),\n",
       " ('प्रेमी', 'के', 'साथ'),\n",
       " ('कि', 'आखिर', 'मीरा'),\n",
       " ('जागरुकता', 'और', 'प्रेम'),\n",
       " ('और', 'प्रेम', 'के'),\n",
       " ('प्रेम', 'के', 'साथ'),\n",
       " ('मीरा', 'से', 'मिलने'),\n",
       " ('अन्य', 'संतों', 'की')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_to_learn = ngrams_up_to_20[1].copy()\n",
    "[sent[0] for sent in my_filter(trigrams_to_learn.most_common())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c4e7d",
   "metadata": {},
   "source": [
    "In this code, we are extending the existing `X_train_example` and `y_train_example` lists with additional training data based on the filtered trigrams from `trigrams_to_learn`. The code extracts sequences of word indices from these trigrams for both input and output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af7a41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_example.extend([[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(trigrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])])\n",
    "y_train_example.extend([[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(trigrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "878d7fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 152)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_example), len(y_train_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b31977d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_example[1575:1585], y_train_example[1575:1585]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dfed3d",
   "metadata": {},
   "source": [
    "In this code, we are preparing training data using bigrams from `ngrams_up_to_20[0]`. After creating the training data, we are applying the Fisher-Yates shuffle to randomize the order of elements within `X_train_2` and `y_train_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90978538",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_to_learn = ngrams_up_to_20[0]\n",
    "X_train_2 = [[word_to_index[sent[0][0]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]\n",
    "y_train_2 = [[word_to_index[sent[0][1]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]\n",
    "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "720feb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 116)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85625a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[87], [306], [4], [11], [2], [18], [16], [5], [231], [4]],\n",
       " [[70], [4], [124], [39], [280], [346], [11], [18], [138], [5]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2[0:10], y_train_2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54432edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 116)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd62fe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[87], [306], [4], [11], [2], [18], [16], [5], [231], [4]],\n",
       " [[70], [4], [124], [39], [280], [346], [11], [18], [138], [5]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2[0:10], y_train_2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33d914a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]],\n",
       " [[63], [78], [152], [1], [171], [1], [217], [82], [71], [196]],\n",
       " 112,\n",
       " 112)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:10], y_train[0:10], len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "593f9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.extend(X_train_2)\n",
    "y_train.extend(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55551e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 228)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d631a9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0], [115]),\n",
       " ([50], [51]),\n",
       " ([0], [345]),\n",
       " ([0], [196]),\n",
       " ([0], [82]),\n",
       " ([186], [87]),\n",
       " ([0], [82]),\n",
       " ([0], [1]),\n",
       " ([11], [405]),\n",
       " ([60], [16])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(zip(X_train, y_train)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46617bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('शरीर', 'मन', 'और'), 3),\n",
       " (('के', 'बालमन', 'में'), 2),\n",
       " (('उन्होंने', 'कृष्ण', 'को'), 2),\n",
       " (('मीरा', 'ने', 'अपनी'), 2),\n",
       " (('उनकी', 'माता', 'ने'), 2),\n",
       " (('कृष्ण', 'की', 'मूर्ति'), 2),\n",
       " (('के', 'बाद', 'मीरा'), 2),\n",
       " (('मूर्ति', 'के', 'सामने'), 2),\n",
       " (('जब', 'मीरा', 'ने'), 2),\n",
       " (('उसने', 'मीरा', 'को'), 2)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_to_learn = ngrams_up_to_20[1]\n",
    "ngrams_to_learn.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c99e1c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('शरीर', 'मन', 'और'),\n",
       " ('के', 'बालमन', 'में'),\n",
       " ('उन्होंने', 'कृष्ण', 'को'),\n",
       " ('मीरा', 'ने', 'अपनी'),\n",
       " ('उनकी', 'माता', 'ने'),\n",
       " ('कृष्ण', 'की', 'मूर्ति'),\n",
       " ('के', 'बाद', 'मीरा'),\n",
       " ('मूर्ति', 'के', 'सामने'),\n",
       " ('जब', 'मीरा', 'ने'),\n",
       " ('उसने', 'मीरा', 'को')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[0] for sent in my_filter(ngrams_to_learn.most_common(10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "194fb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('शरीर', 'मन'),\n",
       " ('के', 'बालमन'),\n",
       " ('उन्होंने', 'कृष्ण'),\n",
       " ('मीरा', 'ने'),\n",
       " ('उनकी', 'माता'),\n",
       " ('कृष्ण', 'की'),\n",
       " ('के', 'बाद'),\n",
       " ('मूर्ति', 'के'),\n",
       " ('जब', 'मीरा'),\n",
       " ('उसने', 'मीरा')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[0][:-1] for sent in my_filter(ngrams_to_learn.most_common(10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3598a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('मन', 'और'),\n",
       " ('बालमन', 'में'),\n",
       " ('कृष्ण', 'को'),\n",
       " ('ने', 'अपनी'),\n",
       " ('माता', 'ने'),\n",
       " ('की', 'मूर्ति'),\n",
       " ('बाद', 'मीरा'),\n",
       " ('के', 'सामने'),\n",
       " ('मीरा', 'ने'),\n",
       " ('मीरा', 'को')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[0][1:] for sent in my_filter(ngrams_to_learn.most_common(10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "600d0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[341, 231, 138],\n",
       " [2, 3, 4],\n",
       " [17, 5, 18],\n",
       " [71, 75, 50],\n",
       " [83, 76, 75],\n",
       " [5, 6, 84],\n",
       " [2, 99, 71],\n",
       " [84, 2, 141],\n",
       " [152, 71, 75],\n",
       " [167, 71, 18]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[word_to_index[w] for w in sent[0]] for sent in my_filter(ngrams_to_learn.most_common(10))\n",
    "    if all([w in word_to_index for w in sent[0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e43ba9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[341, 231],\n",
       " [2, 3],\n",
       " [17, 5],\n",
       " [71, 75],\n",
       " [83, 76],\n",
       " [5, 6],\n",
       " [2, 99],\n",
       " [84, 2],\n",
       " [152, 71],\n",
       " [167, 71]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common(10))\n",
    "    if all([w in word_to_index for w in sent[0]])]\n",
    "X_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0525578d",
   "metadata": {},
   "source": [
    "The code further modifies the `y_train_2` variable to contain the indices of words in the second position of a trigram for a subset of the most common trigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f70b983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[231, 138],\n",
       " [3, 4],\n",
       " [5, 18],\n",
       " [75, 50],\n",
       " [76, 75],\n",
       " [6, 84],\n",
       " [99, 71],\n",
       " [2, 141],\n",
       " [71, 75],\n",
       " [71, 18]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common(10))\n",
    "    if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c1da5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[152, 71], [231, 138], [186, 87], [70, 43], [2, 99]],\n",
       " [[71, 75], [138, 343], [87, 70], [43, 138], [99, 71]],\n",
       " 36,\n",
       " 36)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
    "X_train_2[0:5], y_train_2[0:5], len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bc96cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(ngrams):\n",
    "    return filter(remove_periods, ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5f552",
   "metadata": {},
   "source": [
    "Here we've made several modifications to the `X_train_2` and `y_train_2` training data by limiting the number of training examples to 2000 and we also applied the `Fisher-Yates shuffle` to randomize the order of these examples. Finally, we've displayed the first 5 elements and the lengths of both lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "710421dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[199, 89], [11, 39], [60, 528], [390, 391], [18, 278]],\n",
       " [[89, 200], [39, 310], [528, 529], [391, 392], [278, 279]],\n",
       " 1384,\n",
       " 1384)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "X_train_2 = X_train_2[:2000]\n",
    "y_train_2 = y_train_2[:2000]\n",
    "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
    "X_train_2[0:5], y_train_2[0:5], len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1646e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[341, 231], [2, 3], [17, 5], [71, 75], [83, 76]] [[231, 138], [3, 4], [5, 18], [75, 50], [76, 75]] 1384 1384\n"
     ]
    }
   ],
   "source": [
    "ngrams_to_learn = ngrams_up_to_20[1]\n",
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "print(X_train_2[0:5], y_train_2[0:5], len(X_train_2), len(y_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4f70f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['END']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b391e0d",
   "metadata": {},
   "source": [
    "The code below is useful for identifying and counting trigrams that represent the end of sentences based on the presence of the `\"END\"` token in the output data `(y_train_2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef2c1031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_eos(trigram):\n",
    "    if trigram[1] == word_to_index['END']:\n",
    "          return True  \n",
    "    return False\n",
    "\n",
    "trigrams_eos = list(filter(check_eos, y_train_2))\n",
    "len(trigrams_eos), trigrams_eos[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d773c",
   "metadata": {},
   "source": [
    "This code is effectively collecting and processing training data from multiple sets of n-grams and adding them to the existing training data, allowing us to work with a more extensive dataset for training the model. The `tqdm` library provides a progress bar to track the progress of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05b98414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 367.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1, len(ngrams_up_to_20))):\n",
    "    ngrams_to_learn = ngrams_up_to_20[i]\n",
    "    X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "                   if all([w in word_to_index for w in sent[0]])]\n",
    "    y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "                   if all([w in word_to_index for w in sent[0]])]\n",
    "    X_train_2 = X_train_2[:2000]\n",
    "    y_train_2 = y_train_2[:2000]\n",
    "    X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
    "    X_train.extend(X_train_2)\n",
    "    y_train.extend(y_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250e3a0",
   "metadata": {},
   "source": [
    "This code is using the `random.sample` function to randomly sample 100 pairs of elements from the `X_train` and `y_train` lists, which are zipped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d4eb2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([231, 138, 343, 2, 370, 45, 371, 372], [138, 343, 2, 370, 45, 371, 372, 66]), ([6, 84, 2, 141, 183, 184, 6, 52, 4, 185, 84, 13, 186, 87, 70, 43, 138, 187, 4], [84, 2, 141, 183, 184, 6, 52, 4, 185, 84, 13, 186, 87, 70, 43, 138, 187, 4, 188]), ([71, 134, 5, 2, 135, 136, 137, 138, 5], [134, 5, 2, 135, 136, 137, 138, 5, 6]), ([71, 2, 568, 695, 696, 697], [2, 568, 695, 696, 697, 698]), ([106, 478], [478, 13]), ([69, 71, 75, 50, 76, 13, 77, 11, 78, 79, 80, 81, 82, 66, 83, 76], [71, 75, 50, 76, 13, 77, 11, 78, 79, 80, 81, 82, 66, 83, 76, 75]), ([354, 485, 13, 509, 510, 511, 13], [485, 13, 509, 510, 511, 13, 186]), ([498, 4, 499, 32, 500], [4, 499, 32, 500, 87]), ([66, 524, 19, 481, 173, 525, 526, 527, 519], [524, 19, 481, 173, 525, 526, 527, 519, 138]), ([5], [18]), ([138, 455, 458], [455, 458, 300]), ([71, 75, 50], [75, 50, 315]), ([122, 219], [219, 436]), ([353, 90, 81, 11, 354, 45, 355, 2, 111, 50, 356, 349, 346, 87, 357, 20, 341, 20, 231], [90, 81, 11, 354, 45, 355, 2, 111, 50, 356, 349, 346, 87, 357, 20, 341, 20, 231, 138]), ([2, 27, 28, 29], [27, 28, 29, 6]), ([71, 75, 50, 76, 13], [75, 50, 76, 13, 77]), ([55, 578, 4], [578, 4, 582]), ([4, 5, 6, 7, 8, 9, 10, 11, 12, 13], [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]), ([0], [677]), ([184, 6, 52, 4, 185, 84, 13, 186, 87, 70], [6, 52, 4, 185, 84, 13, 186, 87, 70, 43]), ([469, 261, 470, 471, 113, 469, 57, 472], [261, 470, 471, 113, 469, 57, 472, 473]), ([329, 330, 2, 331], [330, 2, 331, 4]), ([567, 355, 19, 568, 569, 32, 570, 571], [355, 19, 568, 569, 32, 570, 571, 441]), ([9, 10], [10, 11]), ([160, 161], [161, 75]), ([115, 55, 212], [55, 212, 18]), ([666, 29, 667, 668], [29, 667, 668, 669]), ([2, 593], [593, 32]), ([491, 2, 492], [2, 492, 85]), ([18, 416, 417, 13, 418, 308, 5, 6, 97, 2, 419, 420], [416, 417, 13, 418, 308, 5, 6, 97, 2, 419, 420, 87]), ([152, 295], [295, 296]), ([162, 300, 72, 301, 159], [300, 72, 301, 159, 302]), ([554, 555, 11, 306, 4, 5], [555, 11, 306, 4, 5, 2]), ([99, 71, 66, 445], [71, 66, 445, 32]), ([43, 138, 187], [138, 187, 4]), ([271, 272, 6, 273], [272, 6, 273, 4]), ([156, 75, 83, 157], [75, 83, 157, 18]), ([32, 57, 2, 125, 170, 171, 81], [57, 2, 125, 170, 171, 81, 138]), ([689, 6], [6, 690]), ([412, 37, 115, 55, 212, 18, 22, 72], [37, 115, 55, 212, 18, 22, 72, 413]), ([69, 87, 11, 122, 7, 439, 87, 440, 92, 105], [87, 11, 122, 7, 439, 87, 440, 92, 105, 219]), ([439, 87, 440, 92, 105, 219, 138, 159, 87, 441, 55, 442, 336, 443], [87, 440, 92, 105, 219, 138, 159, 87, 441, 55, 442, 336, 443, 391]), ([102, 2, 103, 104, 105, 106, 107], [2, 103, 104, 105, 106, 107, 101]), ([248, 249, 250, 4, 251], [249, 250, 4, 251, 252]), ([691, 674, 692], [674, 692, 693]), ([321, 322, 323, 4], [322, 323, 4, 324]), ([220, 159], [159, 10]), ([82, 46, 13, 168, 108, 32], [46, 13, 168, 108, 32, 206]), ([579, 580], [580, 6]), ([2, 221, 71, 18, 222, 223, 13], [221, 71, 18, 222, 223, 13, 224]), ([152, 71, 75], [71, 75, 149]), ([125, 170, 171, 81, 138, 167, 71], [170, 171, 81, 138, 167, 71, 18]), ([167, 423, 97, 2, 417, 32, 424, 87, 308, 425, 47, 13, 195, 426, 194, 42, 138, 341, 66], [423, 97, 2, 417, 32, 424, 87, 308, 425, 47, 13, 195, 426, 194, 42, 138, 341, 66, 427]), ([77, 11, 78, 79, 80, 81, 82, 66, 83, 76, 75, 5, 6, 84, 6, 85, 86, 87], [11, 78, 79, 80, 81, 82, 66, 83, 76, 75, 5, 6, 84, 6, 85, 86, 87, 2]), ([9, 10, 11, 12, 13, 14], [10, 11, 12, 13, 14, 15]), ([578, 4, 582], [4, 582, 583]), ([192, 409, 13, 410, 70, 43, 138, 55, 125, 105, 72, 194, 407, 37, 39, 259, 411], [409, 13, 410, 70, 43, 138, 55, 125, 105, 72, 194, 407, 37, 39, 259, 411, 412]), ([301, 159, 302, 113, 22, 121], [159, 302, 113, 22, 121, 2]), ([378, 313, 43], [313, 43, 11]), ([4, 582, 583], [582, 583, 584]), ([230, 71, 2, 231, 4, 232, 233, 234, 235, 37, 11, 39, 236, 237, 2, 141, 138, 238], [71, 2, 231, 4, 232, 233, 234, 235, 37, 11, 39, 236, 237, 2, 141, 138, 238, 239]), ([55, 125, 390, 391, 392, 393, 39, 394, 124, 395, 172, 2], [125, 390, 391, 392, 393, 39, 394, 124, 395, 172, 2, 125]), ([5, 2, 135, 136, 137, 138, 5], [2, 135, 136, 137, 138, 5, 6]), ([0], [82]), ([587, 588, 6, 97, 222, 595, 32, 596, 267, 81, 597, 598, 599, 600, 601], [588, 6, 97, 222, 595, 32, 596, 267, 81, 597, 598, 599, 600, 601, 602]), ([299, 127, 115, 152, 162, 300], [127, 115, 152, 162, 300, 72]), ([36, 288, 32, 289, 72, 71, 2, 111, 272, 32, 290, 291, 178, 152], [288, 32, 289, 72, 71, 2, 111, 272, 32, 290, 291, 178, 152, 71]), ([11, 273, 4, 272, 2], [273, 4, 272, 2, 280]), ([71, 2, 429, 430, 2, 345, 227, 4, 58, 431, 11, 405, 71, 32], [2, 429, 430, 2, 345, 227, 4, 58, 431, 11, 405, 71, 32, 406]), ([560, 71, 13], [71, 13, 542]), ([268, 6], [6, 222]), ([485, 13], [13, 509]), ([227, 4, 228, 229, 37, 115, 99, 4, 230, 71, 2, 231, 4, 232, 233, 234, 235, 37], [4, 228, 229, 37, 115, 99, 4, 230, 71, 2, 231, 4, 232, 233, 234, 235, 37, 11]), ([4, 45, 274, 275, 276, 277, 138, 71, 18, 278], [45, 274, 275, 276, 277, 138, 71, 18, 278, 279]), ([32, 596, 267, 81, 597, 598, 599, 600], [596, 267, 81, 597, 598, 599, 600, 601]), ([2, 88, 89, 11], [88, 89, 11, 90]), ([124], [395]), ([71, 536, 537, 2, 540, 520, 541, 43, 115, 17, 71, 13], [536, 537, 2, 540, 520, 541, 43, 115, 17, 71, 13, 542]), ([159, 302], [302, 113]), ([374, 375, 37, 376], [375, 37, 376, 94]), ([172, 13, 193], [13, 193, 186]), ([171, 227, 4, 228, 229, 37, 115, 99, 4, 230, 71], [227, 4, 228, 229, 37, 115, 99, 4, 230, 71, 2]), ([346, 347, 348], [347, 348, 57]), ([75, 50, 76, 13, 77, 11, 78, 79, 80, 81, 82], [50, 76, 13, 77, 11, 78, 79, 80, 81, 82, 66]), ([599, 600, 601, 602, 603, 604, 605, 606, 607], [600, 601, 602, 603, 604, 605, 606, 607, 138]), ([141, 202, 81, 78, 203, 204, 205, 78, 206], [202, 81, 78, 203, 204, 205, 78, 206, 207]), ([179, 180, 87, 181, 53, 138, 174, 11, 71, 182, 19, 5], [180, 87, 181, 53, 138, 174, 11, 71, 182, 19, 5, 6]), ([132, 133, 2, 99, 71, 134, 5, 2, 135, 136], [133, 2, 99, 71, 134, 5, 2, 135, 136, 137]), ([90, 81], [81, 11]), ([194, 407, 37, 39, 259, 411, 412], [407, 37, 39, 259, 411, 412, 37]), ([473, 474, 4, 475, 6, 95, 159, 87], [474, 4, 475, 6, 95, 159, 87, 407]), ([32, 500, 87, 501, 113, 194, 441, 81], [500, 87, 501, 113, 194, 441, 81, 11]), ([141, 183, 184, 6, 52, 4, 185, 84, 13, 186, 87, 70, 43, 138, 187, 4, 188], [183, 184, 6, 52, 4, 185, 84, 13, 186, 87, 70, 43, 138, 187, 4, 188, 70]), ([82, 46, 13, 168, 108, 32, 206, 209, 178, 115, 210, 72, 167], [46, 13, 168, 108, 32, 206, 209, 178, 115, 210, 72, 167, 45]), ([408, 261, 7, 349, 81, 105, 466, 18, 350], [261, 7, 349, 81, 105, 466, 18, 350, 13]), ([11, 354, 45, 355, 2, 111, 50, 356], [354, 45, 355, 2, 111, 50, 356, 349]), ([231, 19, 231, 17, 5, 13], [19, 231, 17, 5, 13, 352]), ([112, 299, 127, 115], [299, 127, 115, 152]), ([2, 226, 71, 32, 171, 227, 4, 228], [226, 71, 32, 171, 227, 4, 228, 229]), ([696, 697], [697, 698])]\n"
     ]
    }
   ],
   "source": [
    "print(random.sample(list(zip(X_train, y_train)), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ba9a08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12468, 12468)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61959952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38df5479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START',\n",
       " 'जब',\n",
       " 'मैं',\n",
       " 'भक्ति',\n",
       " 'कहता',\n",
       " 'हूं',\n",
       " 'तो',\n",
       " 'मैं',\n",
       " 'किसी',\n",
       " 'मत',\n",
       " 'या',\n",
       " 'धारणा',\n",
       " 'में',\n",
       " 'विश्वास',\n",
       " 'की',\n",
       " 'बात',\n",
       " 'नहीं',\n",
       " 'कर',\n",
       " 'रहा',\n",
       " 'हूं',\n",
       " '।',\n",
       " 'END']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_conversation[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f0712ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 408,\n",
       " 71,\n",
       " 192,\n",
       " 409,\n",
       " 13,\n",
       " 410,\n",
       " 70,\n",
       " 43,\n",
       " 138,\n",
       " 55,\n",
       " 125,\n",
       " 105,\n",
       " 72,\n",
       " 194,\n",
       " 407,\n",
       " 37,\n",
       " 39,\n",
       " 259,\n",
       " 411,\n",
       " 412,\n",
       " 37,\n",
       " 115,\n",
       " 55,\n",
       " 212,\n",
       " 18,\n",
       " 22,\n",
       " 72,\n",
       " 413,\n",
       " 159,\n",
       " 414,\n",
       " 37,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[word_to_index[w] for w in sent] for sent in tokenized_conversation if all([w in word_to_index for w in sent])][51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0ad2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full_sentences = [[word_to_index[w] for w in sent[:-1]] for sent in tokenized_conversation\n",
    "                         if all([w in word_to_index for w in sent])]\n",
    "y_train_full_sentences = [[word_to_index[w] for w in sent[1:]] for sent in tokenized_conversation\n",
    "                         if all([w in word_to_index for w in sent])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9ed1edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 5, 18, 19, 20, 21, 22, 23, 24], [0, 26, 2, 27, 28, 29, 6, 30, 31, 1, 32, 33, 34, 35, 4, 36, 37, 24], [0, 38, 13, 19, 39, 40, 4, 41, 42, 43, 24], [0, 1, 2, 38, 4, 44, 45, 46, 6, 47, 13, 48, 49, 50, 51, 52, 16, 53, 24], [0, 45, 54, 55, 56, 4, 57, 58, 59, 2, 60, 61, 62, 24]] [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 5, 18, 19, 20, 21, 22, 23, 24, 25], [26, 2, 27, 28, 29, 6, 30, 31, 1, 32, 33, 34, 35, 4, 36, 37, 24, 25], [38, 13, 19, 39, 40, 4, 41, 42, 43, 24, 25], [1, 2, 38, 4, 44, 45, 46, 6, 47, 13, 48, 49, 50, 51, 52, 16, 53, 24, 25], [45, 54, 55, 56, 4, 57, 58, 59, 2, 60, 61, 62, 24, 25]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full_sentences[0:5], y_train_full_sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15dc60ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START', 'दरअसल', 'मीरा', 'जिस', 'स्थिति', 'से', 'गुजर', 'रही', 'थीं', 'और', 'उनके', 'साथ', 'जो', 'भी', 'हो', 'रहा', 'था', 'वह', 'बहुत', 'वास्तविक', 'लगता', 'था', 'लेकिन', 'उनके', 'पति', 'को', 'कुछ', 'भी', 'नजर', 'नहीं', 'आता', 'था', '।', 'END'] ['END', '।', 'था', 'आता', 'नहीं', 'नजर', 'भी', 'कुछ', 'को', 'पति', 'उनके', 'लेकिन', 'था', 'लगता', 'वास्तविक', 'बहुत', 'वह', 'था', 'रहा', 'हो', 'भी', 'जो', 'साथ', 'उनके', 'और', 'थीं', 'रही', 'गुजर', 'से', 'स्थिति', 'जिस', 'मीरा', 'दरअसल', 'START']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_conversation[51], tokenized_conversation[51][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9937204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17ffde8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['START', 'छांड़ि', 'दई', 'कुल', 'की', 'कानि', 'कहा', 'करै', 'कोई', '।', 'END'], ['START', '।', 'END'], ['START', 'आज', 'भी', 'कई', 'इसाई', 'संप्रदायों', 'में', 'नन', 'बनने', 'की', 'दीक्षा', 'पाने', 'के', 'लिए', 'लड़कियां', 'पहले', 'जीसस', 'के', 'साथ', 'विवाह', 'करती', 'हैं', '।', 'END'], ['START', 'मीरा', 'के', 'प्रभु', 'गिरधर', 'नागर', 'हरखहरख', 'जस', 'पायो', '।', 'END'], ['START', 'उसने', 'राणा', 'से', 'कहा', 'कि', 'मीरा', 'का', 'किसी', 'के', 'साथ', 'गुप्त', 'प्रेम', 'है', 'और', 'उसने', 'मीरा', 'को', 'मंदिर', 'में', 'अपने', 'प्रेमी', 'से', 'बात', 'करते', 'देखा', 'है', '।', 'END'], ['START', 'उनके', 'पदों', 'में', 'उच्च', 'आध्यात्मिक', 'अनुभव', 'हैं', '।', 'END'], ['START', 'इस', 'शादी', 'के', 'लिए', 'पहले', 'तो', 'मीराबाई', 'ने', 'मना', 'कर', 'दिया', 'लेकिन', 'जोर', 'देने', 'पर', 'वह', 'फूटफूट', 'कर', 'रोने', 'लगीं', '।', 'END'], ['START', 'संतन', 'ढिग', 'बैठि', 'बैठि', 'लोक', 'लाज', 'खोई', '।', 'END'], ['START', 'बचपन', 'से', 'ही', 'वह', 'कृष्णभक्ति', 'में', 'रम', 'गई', 'थीं', '।', 'END'], ['START', 'मीराबाई', 'के', 'बचपन', 'में', 'हुई', 'एक', 'घटना', 'की', 'वजह', 'से', 'उनका', 'कृष्णप्रेम', 'अपनी', 'चरम', 'अवस्था', 'तक', 'पहुंचा', '।', 'END'], ['START', 'उन्होंने', 'कृष्ण', 'को', 'याद', 'किया', 'और', 'जहर', 'पीकर', 'वहां', 'से', 'चल', 'दीं', '।', 'END'], ['START', 'लेकिन', 'यह', 'सब', 'आप', 'अनजाने', 'में', 'और', 'बिना', 'प्रेमभाव', 'के', 'कर', 'रहे', 'हैं', '।', 'END'], ['START', '’', 'इस', 'जबाब', 'से', 'जीव', 'गोसाईं', 'बहुत', 'शर्मिंदा', 'हुए', '।', 'END'], ['START', 'शादी', 'के', 'बाद', 'विदाई', 'के', 'समय', 'वे', 'कृष्ण', 'की', 'वही', 'मूर्ति', 'अपने', 'साथ', 'ले', 'गईं', 'जिसे', 'उनकी', 'माता', 'ने', 'उनका', 'दूल्हा', 'बताया', 'था', '।', 'END'], ['START', 'मीरा', 'जीव', 'गोसांई', 'के', 'दर्शन', 'करना', 'चाहती', 'थीं', 'लेकिन', 'उन्होंने', 'मीरा', 'से', 'मिलने', 'से', 'मना', 'कर', 'दिया', '।', 'END'], ['START', 'आप', 'नहीं', 'जानते', 'आप', 'कहां', 'पहुंचेंगे', '।', 'END'], ['START', 'दरअसल', 'मीरा', 'जिस', 'स्थिति', 'से', 'गुजर', 'रही', 'थीं', 'और', 'उनके', 'साथ', 'जो', 'भी', 'हो', 'रहा', 'था', 'वह', 'बहुत', 'वास्तविक', 'लगता', 'था', 'लेकिन', 'उनके', 'पति', 'को', 'कुछ', 'भी', 'नजर', 'नहीं', 'आता', 'था', '।', 'END'], ['START', 'मीरा', 'की', 'भक्ति', 'उनका', 'आम', 'लोगों', 'के', 'साथ', 'घुलनामिलना', 'और', 'नारीमर्यादा', 'के', 'प्रति', 'उनकी', 'लापरवाही', 'का', 'उसने', 'कड़ा', 'विरोध', 'किया', '।', 'END'], ['START', '”', 'जीव', 'गोसांई', 'वृंदावन', 'में', 'वैष्णवसंप्रदाय', 'के', 'मुखिया', 'थे', '।', 'END'], ['START', 'कृष्ण', 'को', 'लेकर', 'मीरा', 'इतनी', 'दीवानी', 'थीं', 'कि', 'महज', 'आठ', 'साल', 'की', 'उम्र', 'में', 'मन', 'ही', 'मन', 'उन्होंने', 'कृष्ण', 'से', 'विवाह', 'कर', 'लिया', '।', 'END']]\n"
     ]
    }
   ],
   "source": [
    "print(random.sample(tokenized_conversation, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63773c9",
   "metadata": {},
   "source": [
    "In this code, we are working with a dataset of tokenized sentences and generating variations of sentences by extracting the last i words (ranging from 3 to 19).Then generating randomly sample 65 sentences from the dataset and extract the last i words from each of these selected sentences. Finally, we print a random sample of 10 of these extracted sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2b6d469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['कुछ', 'माना', '।', 'END'], ['START', 'लोग', 'उनके', 'मरने', 'का', 'इंतजार', 'कर', 'रहे', 'थे', 'लेकिन', 'वह', 'स्वस्थ्य', 'और', 'प्रसन्न', 'बनी', 'रहीं', '।', 'END'], ['से', 'जीव', 'गोसाईं', 'बहुत', 'शर्मिंदा', 'हुए', '।', 'END'], ['का', 'नया', 'राजा', 'बना', 'बहुत', 'कठोर', 'था', '।', 'END'], ['START', 'इस', 'तरह', 'की', 'कई', 'घटनाएं', 'हुईं', '।', 'END'], ['START', 'मीरा', 'के', 'प्रभु', 'गिरधर', 'नागर', 'हरखहरख', 'जस', 'पायो', '।', 'END'], ['START', 'अगर', 'यहां', 'कोई', 'पुरुष', 'है', 'तो', 'केवल', 'गिरिधर', 'गोपाल', '।', 'END'], ['एक', 'सच्चाई', 'थी', 'कि', 'कृष्ण', 'उनके', 'साथ', 'उठतेबैठते', 'थे', 'घूमते', 'थे', '।', 'END'], ['भी', 'राणा', 'के', 'संबंधी', 'मीरा', 'को', 'कई', 'तरीकों', 'से', 'सताने', 'लगे', '।', 'END'], ['ने', 'कृष्ण', 'की', 'मूर्ति', 'की', 'ओर', 'इशारा', 'कर', 'के', 'कह', 'दिया', 'कि', 'यही', 'तुम्हारे', 'दूल्हा', 'हैं', '।', 'END']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "last_n_words = []\n",
    "for i in range(3, 20):\n",
    "    tokenized_sentences_400 = random.sample(list(tokenized_conversation), 65)\n",
    "    for s in tokenized_sentences_400:\n",
    "        last_n_words.append(s[::-1][:i][::-1])\n",
    "\n",
    "print(random.sample(last_n_words, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49ad2b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(last_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84f4248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eos = [[word_to_index[w] for w in sent[:-1]] for sent in last_n_words\n",
    "                         if all([w in word_to_index for w in sent])]\n",
    "y_train_eos = [[word_to_index[w] for w in sent[1:]] for sent in last_n_words\n",
    "                         if all([w in word_to_index for w in sent])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7532004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105, 1105)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_eos), len(y_train_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f8fcb122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[660, 24], [43, 24], [396, 24], [308, 24], [81, 24], [688, 24], [665, 24], [694, 24], [546, 24], [267, 24]] [[24, 25], [24, 25], [24, 25], [24, 25], [24, 25], [24, 25], [24, 25], [24, 25], [24, 25], [24, 25]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_eos[0:10], y_train_eos[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3308d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 682, 683, 219, 684, 625, 685, 686, 687, 688, 24], [0, 17, 5, 18, 457, 267, 138, 455, 458, 300, 13, 248, 459, 24], [315, 316, 317, 122, 45, 318, 13, 319, 318, 320, 321, 322, 323, 4, 324, 325, 24], [202, 81, 78, 203, 204, 205, 78, 206, 207, 81, 138, 39, 208, 4, 136, 127, 24], [487, 484, 488, 489, 13, 50, 490, 66, 138, 491, 2, 492, 85, 493, 70, 81, 24], [470, 471, 113, 469, 57, 472, 473, 474, 4, 475, 6, 95, 159, 87, 407, 471, 24], [0, 345, 48, 438, 153, 225, 24], [0, 535, 536, 537, 306, 4, 538, 2, 539, 151, 24], [0, 677, 677, 6, 678, 679, 680, 4, 63, 681, 24], [0, 71, 72, 61, 73, 74, 24]] [[682, 683, 219, 684, 625, 685, 686, 687, 688, 24, 25], [17, 5, 18, 457, 267, 138, 455, 458, 300, 13, 248, 459, 24, 25], [316, 317, 122, 45, 318, 13, 319, 318, 320, 321, 322, 323, 4, 324, 325, 24, 25], [81, 78, 203, 204, 205, 78, 206, 207, 81, 138, 39, 208, 4, 136, 127, 24, 25], [484, 488, 489, 13, 50, 490, 66, 138, 491, 2, 492, 85, 493, 70, 81, 24, 25], [471, 113, 469, 57, 472, 473, 474, 4, 475, 6, 95, 159, 87, 407, 471, 24, 25], [345, 48, 438, 153, 225, 24, 25], [535, 536, 537, 306, 4, 538, 2, 539, 151, 24, 25], [677, 677, 6, 678, 679, 680, 4, 63, 681, 24, 25], [71, 72, 61, 73, 74, 24, 25]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_eos[1000:1010], y_train_eos[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ba3e531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12468, 12468)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91c17f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.extend(X_train_eos)\n",
    "y_train.extend(y_train_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "216784ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13573, 13573)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6aa16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(r\"C:\\Users\\dkdha\\Downloads\\X_train_mirabai.pkl\", 'wb') as file:\n",
    "#     pickle.dump(X_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a60ce636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'C:\\Users\\dkdha\\Downloads\\y_train_mirabai.pkl', 'wb') as file:\n",
    "#     pickle.dump(y_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74e6feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'C:\\Users\\dkdha\\Downloads\\tokenized_sentences_mirabai.pkl', 'wb') as file:\n",
    "#     pickle.dump(tokenized_conversation, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9d8ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'C:\\Users\\dkdha\\Downloads\\word_to_index_mirabai.pkl', 'wb') as file:\n",
    "#     pickle.dump(word_to_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c2471c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'C:\\Users\\dkdha\\Downloads\\index_to_word_mirabai.pkl', 'wb') as file:\n",
    "#     pickle.dump(index_to_word, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24e38c8c-e3b3-458f-9870-7cb8fdea05b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13573"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a9477c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Determine the length of the longest sequence\n",
    "max_seq_length = max(len(sequence) for sequence in X_train)\n",
    "\n",
    "# Pad all sequences to the length of the longest one\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, padding='post')\n",
    "y_train_padded = pad_sequences(y_train, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "# Now you can safely convert to NumPy arrays\n",
    "X_train2 = np.array(X_train_padded)\n",
    "y_train2 = np.array(y_train_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b71ca05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13573, 19), (13573, 19))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "09dd21b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([121, 122,   5,   6, 123,  84, 124,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([122,   5,   6, 123,  84, 124, 125,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([354,  45, 355,   2, 111,  50, 356, 349, 346,  87, 357,  20, 341,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([ 45, 355,   2, 111,  50, 356, 349, 346,  87, 357,  20, 341,  20,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([  4, 232, 233, 234, 235,  37,  11,  39, 236, 237,   2, 141, 138,\n",
      "       238,   0,   0,   0,   0,   0], dtype=int32), array([232, 233, 234, 235,  37,  11,  39, 236, 237,   2, 141, 138, 238,\n",
      "       239,   0,   0,   0,   0,   0], dtype=int32)), (array([162, 300,  72, 301, 159, 302, 113,  22, 121,   2,  99, 303,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([300,  72, 301, 159, 302, 113,  22, 121,   2,  99, 303, 304,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([229,  37, 115,  99,   4, 230,  71,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([ 37, 115,  99,   4, 230,  71,   2,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([440,  92, 105, 219, 138, 159,  87, 441,  55, 442,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([ 92, 105, 219, 138, 159,  87, 441,  55, 442, 336,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([320, 321, 322, 323,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([321, 322, 323,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([259, 411, 412,  37, 115,  55, 212,  18,  22,  72,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([411, 412,  37, 115,  55, 212,  18,  22,  72, 413,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32)), (array([15, 16, 17,  5, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0], dtype=int32), array([16, 17,  5, 18, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0], dtype=int32)), (array([ 66, 138, 491,   2, 492,  85, 493,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32), array([138, 491,   2, 492,  85, 493,  70,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0], dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "print(random.sample(list(zip(X_train2, y_train2)), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3edc57b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30a87dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only need t perform this step once. \n",
    "# pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "60bcaee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8aa88d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ac94f",
   "metadata": {},
   "source": [
    "In this code, we are loading a pre-trained FastText word embedding model using Gensim and extracting word vectors from it.The `embeddings_index` dictionary can be used to access word vectors for specific words during further processing. The pre-trained FastText model can be downloaded from https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c5749676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1876653 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Path to the downloaded FastText model file\n",
    "fasttext_model_path = '/Users/cherilyogi/Desktop/Class_Folder/INFO_6106/Homework_7/cc.hi.300.vec'\n",
    "\n",
    "# Initialize the FastText model\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(fasttext_model_path)\n",
    "\n",
    "# Initialize a dictionary to store word vectors\n",
    "embeddings_index = {}\n",
    "\n",
    "# Iterate through the words in the FastText model\n",
    "for word in fasttext_model.index_to_key:\n",
    "    embeddings_index[word] = fasttext_model[word]\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96b57da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
    "for word, i in most_common_words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < vocabulary_size:\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba469a",
   "metadata": {},
   "source": [
    "The resulting `embedding_matrix` contains the word vectors for the words in our vocabulary, derived from the pre-trained FastText model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f7516840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 300)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b804a994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('आया', 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eecd7e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0054    , -0.0315    ,  0.0458    ,  0.0484    , -0.0217    ,\n",
       "       -0.0206    ,  0.0424    , -0.0518    ,  0.0192    ,  0.0805    ,\n",
       "        0.0324    , -0.0703    ,  0.0658    ,  0.0236    , -0.0199    ,\n",
       "        0.0194    ,  0.1912    ,  0.0926    , -0.0763    ,  0.35589999,\n",
       "        0.0656    ,  0.0254    , -0.0495    , -0.0385    , -0.0037    ,\n",
       "        0.0213    , -0.0267    , -0.0684    , -0.0354    , -0.0437    ,\n",
       "        0.0291    , -0.0729    ,  0.0095    , -0.0357    ,  0.1052    ,\n",
       "        0.0072    ,  0.0199    ,  0.0347    , -0.0363    , -0.0319    ,\n",
       "        0.058     ,  0.1169    , -0.0268    , -0.0024    , -0.0261    ,\n",
       "        0.0444    , -0.0463    , -0.0523    ,  0.0015    , -0.01      ,\n",
       "        0.0092    , -0.0313    , -0.0107    ,  0.0215    ,  0.0306    ,\n",
       "        0.0062    , -0.0069    , -0.0714    , -0.0163    , -0.1188    ,\n",
       "       -0.0581    ,  0.0518    ,  0.0312    ,  0.0219    ,  0.0309    ,\n",
       "       -0.0169    , -0.0748    ,  0.0075    , -0.0416    , -0.0487    ,\n",
       "        0.0733    , -0.006     ,  0.0829    , -0.0108    , -0.035     ,\n",
       "        0.0614    ,  0.0063    , -0.0039    , -0.0604    ,  0.0488    ,\n",
       "       -0.0187    ,  0.0141    , -0.0686    ,  0.0872    , -0.0328    ,\n",
       "        0.0506    , -0.0257    , -0.12899999,  0.1062    , -0.34290001,\n",
       "        0.0289    ,  0.0323    , -0.0422    ,  0.0039    ,  0.0599    ,\n",
       "       -0.0217    ,  0.0582    ,  0.0693    ,  0.0012    , -0.0108    ,\n",
       "        0.0201    , -0.1083    , -0.0244    ,  0.0525    ,  0.0086    ,\n",
       "        0.0528    ,  0.0056    , -0.0582    , -0.0465    , -0.0459    ,\n",
       "       -0.0885    , -0.0363    , -0.0327    , -0.02      , -0.0428    ,\n",
       "        0.0106    , -0.0234    , -0.0326    ,  0.16060001,  0.0262    ,\n",
       "       -0.0075    , -0.0457    ,  0.0803    , -0.0393    ,  0.0682    ,\n",
       "        0.0974    ,  0.022     ,  0.0052    ,  0.0686    , -0.0186    ,\n",
       "        0.051     ,  0.0731    , -0.0242    ,  0.0129    ,  0.1198    ,\n",
       "       -0.0424    ,  0.0201    , -0.0688    ,  0.0503    ,  0.01      ,\n",
       "        0.0557    ,  0.0015    , -0.0143    , -0.0216    , -0.028     ,\n",
       "       -0.0505    ,  0.0542    , -0.0014    ,  0.0212    ,  0.0196    ,\n",
       "        0.0014    ,  0.005     , -0.0674    ,  0.0049    ,  0.0752    ,\n",
       "        0.0316    ,  0.0291    ,  0.0417    , -0.0453    ,  0.0608    ,\n",
       "       -0.0183    , -0.1131    ,  0.0132    , -0.141     , -0.0356    ,\n",
       "       -0.1548    , -0.0309    , -0.0817    ,  0.0027    , -0.0207    ,\n",
       "        0.0732    ,  0.0727    , -0.1944    ,  0.0534    , -0.089     ,\n",
       "        0.0477    ,  0.0751    ,  0.1052    ,  0.0379    ,  0.031     ,\n",
       "       -0.0308    ,  0.1004    ,  0.0106    , -0.0583    ,  0.0413    ,\n",
       "        0.0349    ,  0.0223    , -0.0199    , -0.0156    ,  0.0292    ,\n",
       "       -0.0424    , -0.0604    , -0.0631    ,  0.2147    ,  0.0121    ,\n",
       "       -0.0233    , -0.0671    ,  0.0313    ,  0.1216    ,  0.0024    ,\n",
       "       -0.1213    ,  0.1495    ,  0.0208    ,  0.0104    , -0.0914    ,\n",
       "       -0.0293    ,  0.0048    , -0.0557    ,  0.0696    ,  0.0395    ,\n",
       "       -0.0014    , -0.0753    , -0.0129    , -0.0405    ,  0.054     ,\n",
       "        0.0504    ,  0.0552    ,  0.0892    ,  0.0091    ,  0.0945    ,\n",
       "       -0.0729    , -0.0287    , -0.0378    ,  0.0441    ,  0.0478    ,\n",
       "       -0.0142    , -0.0158    ,  0.0092    , -0.0491    ,  0.018     ,\n",
       "       -0.0105    , -0.0247    ,  0.039     , -0.0585    , -0.0524    ,\n",
       "       -0.0265    , -0.0235    , -0.0325    ,  0.035     , -0.0166    ,\n",
       "       -0.0582    ,  0.0222    ,  0.0553    , -0.0644    , -0.0247    ,\n",
       "        0.0366    , -0.0167    , -0.0659    ,  0.0142    , -0.0812    ,\n",
       "        0.0673    ,  0.0311    ,  0.0023    ,  0.0029    ,  0.0247    ,\n",
       "       -0.0858    , -0.064     ,  0.0264    ,  0.2491    ,  0.0009    ,\n",
       "       -0.0683    ,  0.0129    , -0.0071    , -0.0167    ,  0.0139    ,\n",
       "        0.0321    ,  0.0232    , -0.0643    ,  0.1113    ,  0.1137    ,\n",
       "        0.0708    , -0.0092    , -0.15350001, -0.0317    ,  0.0674    ,\n",
       "        0.0454    , -0.0203    , -0.0704    , -0.0382    ,  0.0415    ,\n",
       "       -0.0122    ,  0.0089    ,  0.0113    , -0.0304    ,  0.0306    ,\n",
       "        0.0469    ,  0.0856    , -0.0289    ,  0.0405    ,  0.0073    ,\n",
       "        0.0317    ,  0.0088    , -0.0102    , -0.0175    ,  0.0216    ,\n",
       "        0.0263    ,  0.0205    ,  0.0437    ,  0.061     , -0.1006    ])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67d3b0",
   "metadata": {},
   "source": [
    "The `find_closest_embeddings` function takes an embedding vector as input and returns a sorted list of words from the vocabulary, ordered by their similarity to the input embedding. The similarity is calculated using the Euclidean distance between the embeddings. This function is used to find words in the vocabulary that are semantically similar to a given word or word vector based on their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ebb1c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_index.keys(), key=lambda word: spatial.distance.euclidean(embeddings_index[word], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b6c5f2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['आता', 'सामने', 'उसने', 'MYAX', 'निकला']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_embeddings(embeddings_index[\"आया\"])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2735bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['की', 'जीव', 'जीवों', 'विषाभ', 'जलगति', 'ऊतिकी', 'की\\u200c', 'पदाथ', 'एककोशीय', 'इसकी']\n"
     ]
    }
   ],
   "source": [
    "print(find_closest_embeddings(\n",
    "    embeddings_index[\"की\"] - embeddings_index[\"दिन\"] + embeddings_index[\"जीव\"]\n",
    ")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e841500",
   "metadata": {},
   "source": [
    "In this code, we are using the t-Distributed Stochastic Neighbor Embedding (t-SNE) technique for dimensionality reduction to gain insights into the relationships between data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4328a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5bec7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =  list(embeddings_index.keys())[:500]\n",
    "vectors = [embeddings_index[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "abec4e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 300)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "986cd5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([529, 308,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5455ff",
   "metadata": {},
   "source": [
    "Here we are creating and training a Sequential model in TensorFlow/Keras using an Embedding layer, a SimpleRNN layer, and a Dense layer.\n",
    "1. The three important parameters here are:\n",
    "    `vocab_size`: The size of the vocabulary, which is 1030 in this case.\n",
    "    `embedding_dim`: The dimension of the word embeddings, set to 300.\n",
    "    `max_length`: The maximum sequence length, which is 19.\n",
    "2. The model consists of three layers :\n",
    "    An Embedding layer with an input vocabulary size of `vocab_size`, an embedding dimension of `embedding_dim`, and an input sequence length of `max_length`. This layer is responsible for converting input sequences into dense word embeddings.\n",
    "    A SimpleRNN layer with 500 units and `return_sequences=True`. This layer processes the sequences and returns sequences for each time step. The output of this layer will be passed to the next layer.\n",
    "    A Dense layer with a vocabulary size of `vocab_size` and `softmax activation`. This layer is used for predicting the next word in the sequence.\n",
    "3. The model is complied using the Adam optimizer and the loss function is specified as `sparse_categorical_crossentropy`. Additionally we are also tracking accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "720227d9-7e48-4060-8275-3bb58c142431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "107/107 [==============================] - 6s 54ms/step - loss: 2.8128 - accuracy: 0.5952\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 6s 52ms/step - loss: 2.2278 - accuracy: 0.6281\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 6s 54ms/step - loss: 1.2387 - accuracy: 0.7707\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.4803 - accuracy: 0.9163\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.2546 - accuracy: 0.9515\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 6s 53ms/step - loss: 0.1809 - accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 6s 56ms/step - loss: 0.1484 - accuracy: 0.9636\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.1317 - accuracy: 0.9646\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 6s 56ms/step - loss: 0.1213 - accuracy: 0.9651\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 6s 57ms/step - loss: 0.1149 - accuracy: 0.9656\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 6s 53ms/step - loss: 0.1112 - accuracy: 0.9655\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.1077 - accuracy: 0.9659\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 6s 52ms/step - loss: 0.1056 - accuracy: 0.9657\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 6s 56ms/step - loss: 0.1045 - accuracy: 0.9656\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 6s 53ms/step - loss: 0.1034 - accuracy: 0.9654\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 6s 53ms/step - loss: 0.1019 - accuracy: 0.9657\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 6s 54ms/step - loss: 0.1013 - accuracy: 0.9655\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 6s 53ms/step - loss: 0.1009 - accuracy: 0.9655\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.1009 - accuracy: 0.9655\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 6s 56ms/step - loss: 0.1010 - accuracy: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x35d378450>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "vocab_size = 1030  \n",
    "embedding_dim = 300  \n",
    "max_length = 19  \n",
    "\n",
    "# Define the RNN model architecture\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    SimpleRNN(units=500, return_sequences=True),  \n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train2, y_train2, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536983a0",
   "metadata": {},
   "source": [
    "The function `generate_sentence_tf` uses the above trained TensorFlow/Keras model to generate sentences. It samples words from the model's predicted probability distribution for the next word, iteratively creating a sentence.The function takes several inputs, such as :\n",
    "1. `model`: The trained language model (RNN) created using TensorFlow/Keras.\n",
    "2. `sentence_start_token`: The start token for sentences.\n",
    "3. `sentence_end_token`: The end token for sentences.\n",
    "4. `unknown_token`: A token for unknown or out-of-vocabulary words.\n",
    "5. `word_to_index`: A dictionary mapping words to their corresponding token indices.\n",
    "6. `index_to_word`: A dictionary mapping token indices to words.\n",
    "7. `senten_max_length`: The maximum length for generated sentences.\n",
    "\n",
    "The main part of the code generates a specified number of sentences (`num_sentences`) by repeatedly calling the `generate_sentence_tf` function and printing the generated sentences if their lengths meet the minimum requirement (`senten_min_length`). These sentences are generated using the above trained model, which has been pretrained to generate text based on the patterns it learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a51385fb-d063-460f-9d7d-5c7250e18047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "उनके वह बाद वह दधि उनके सींचि यहां वह प्रेम जब । । । लगाया । । बन\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "यहां वह लोगों देखा क्योंकि प्रेम यही बाद तो नहीं यहां ससुराल यहां फिर । खोवायो\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "सींचि यहां सींचि जाएं । वह लिया क्योंकि । भोजपुरी लगी नहिं वह यह कृष्ण वह । ।\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "पंजाबी वह लिया वह कोई बाद वह । । । नागर जल राजी मीरा रोई था । ललिता\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "चले । कि देखा छोई वह । नहीं रहा मीरा वह था वह वह । वह न ।\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "वही प्रयोग । था या वही वह उत्सवों । जब । जी प्रेम या वह था किया फारसी\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "मीरा कोई कि बाद भक्ति । बैठि प्रेम कृश्णभक्ति वह पंजाबी यहां । । । वह जल था\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "इस देखि यह प्रयोग आप । वह प्रेम\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "सारी यहां यह । वह आया पद\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_sentence_tf(model, sentence_start_token, sentence_end_token, unknown_token, word_to_index, index_to_word, senten_max_length):\n",
    "    new_sentence = [word_to_index[sentence_start_token]]\n",
    "    start_token_index = word_to_index[sentence_start_token]\n",
    "    \n",
    "    while not new_sentence[-1] == word_to_index[sentence_end_token] and len(new_sentence) < senten_max_length:\n",
    "        padded_sentence = pad_sequences([new_sentence], maxlen=19, padding='post')\n",
    "        next_word_probs = model.predict(padded_sentence)[0]\n",
    "        \n",
    "        # Set the probability of the start token to 0 for this and all subsequent predictions\n",
    "        next_word_probs[:, start_token_index] = 0\n",
    "\n",
    "        # Renormalize probabilities to sum to 1 after modifying the 'start' token probability\n",
    "        next_word_probs /= np.sum(next_word_probs, axis=1, keepdims=True)\n",
    "\n",
    "        # Sample a word from the probability distribution\n",
    "        sampled_word = np.random.choice(range(len(next_word_probs[-1])), p=next_word_probs[-1])\n",
    "        \n",
    "        # Avoid sampling unknown or start token by setting their probabilities to 0 and renormalizing\n",
    "        while sampled_word in [word_to_index[unknown_token], start_token_index]:\n",
    "            next_word_probs[-1][sampled_word] = 0\n",
    "            next_word_probs[-1] /= np.sum(next_word_probs[-1])\n",
    "            sampled_word = np.random.choice(range(len(next_word_probs[-1])), p=next_word_probs[-1])\n",
    "        \n",
    "        new_sentence.append(sampled_word)\n",
    "    \n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]  # Exclude the start token\n",
    "    return sentence_str\n",
    "\n",
    "\n",
    "num_sentences = 10\n",
    "senten_min_length = 7\n",
    "senten_max_length = 20\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent = generate_sentence_tf(model, sentence_start_token, sentence_end_token, unknown_token, word_to_index, index_to_word, senten_max_length)\n",
    "    if len(sent) >= senten_min_length:\n",
    "        print(\" \".join(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8504a",
   "metadata": {},
   "source": [
    "Result :  Despite achieving a high training accuracy, the model's predictions exhibit certain shortcomings. \n",
    "1. Random Words: The model appears to insert random or incorrect words in some cases. These words disrupt the meaning of the sentence and result in nonsensical or inaccurate outputs. This suggests that the model's understanding of context and coherence is not perfect.\n",
    "2. Repetition of Words: Another notable issue is the repetition of specific words in generated text. This repetition can make the text less coherent and may not reflect natural language usage.\n",
    "3. Contextual Understanding: The model seems to struggle with a deep understanding of context. It sometimes fails to maintain context and coherence throughout the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1860615",
   "metadata": {},
   "source": [
    "# Alternative Approach\n",
    "\n",
    "We followed an article online - https://igtechteam.com/2023/06/27/nlp-project/#next-word-prediction from where the below code was implemented for our dataset. The reason we were trying different things is because, the results we are getting is still not very accurate despite the high accuracy results by the model numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f327c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f6793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/Users/cherilyogi/Desktop/Class_Folder/INFO_6106/Homework_7/mirabai.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a08bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "text = content.strip()\n",
    "text = text.replace(\"\\n\",\" \")\n",
    "text = re.sub(\"–|’|‘|।\",\" \",text)\n",
    "text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530b1b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8318"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea2917",
   "metadata": {},
   "source": [
    "Using the Keras `Tokenizer` to preprocess the text data. We are fitting the tokenizer on the preprocessed text data, which essentially builds the vocabulary based on the words in your text. This tokenizer is then saved to a file named `token.pkl`, which will allow us to use the same tokenizer for prediction later. Then we convert the preprocessed tex into a sequences of integers. The resulting `sequence_data` is a list of integer sequences representing the words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1b668b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 1, 124, 3, 12, 4, 84, 228, 229, 68, 8, 230, 5, 125, 231]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    " \n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    " \n",
    "sequence_data = tokenizer.texts_to_sequences([text])[0]\n",
    "sequence_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178b0519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1763"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715ecd1",
   "metadata": {},
   "source": [
    "Here we are creating sequences of words for training, we are also printing the first 10 sequences from sequences to see what they look like. This code effectively prepares our data for training the model where each sequence contains four words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6cff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n",
      "The Length of sequences are:  1760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 33,   1, 124,   3],\n",
       "       [  1, 124,   3,  12],\n",
       "       [124,   3,  12,   4],\n",
       "       [  3,  12,   4,  84],\n",
       "       [ 12,   4,  84, 228],\n",
       "       [  4,  84, 228, 229],\n",
       "       [ 84, 228, 229,  68],\n",
       "       [228, 229,  68,   8],\n",
       "       [229,  68,   8, 230],\n",
       "       [ 68,   8, 230,   5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "sequences = []\n",
    " \n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "     \n",
    "        \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e87e3c",
   "metadata": {},
   "source": [
    "Preparing the input data X and the target data y for training purpose and then converting them both into NumPy arrays for easier handling. Xcontains sequences of three words each, and contains the corresponding target words.\n",
    "We are using `to_categorical` to one-hot encode the y values, because each word in the vocabulary is a potential class, and one-hot encoding is used to represent the target word as a binary vector with a 1 in the position corresponding to the index of the word in the vocabulary.\n",
    "Finally, X contains sequences of three words each, and y is the one-hot encoded target word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49952ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[ 33   1 124]\n",
      " [  1 124   3]\n",
      " [124   3  12]\n",
      " [  3  12   4]\n",
      " [ 12   4  84]\n",
      " [  4  84 228]\n",
      " [ 84 228 229]\n",
      " [228 229  68]\n",
      " [229  68   8]\n",
      " [ 68   8 230]]\n",
      "Response:  [  3  12   4  84 228 229  68   8 230   5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    " \n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "     \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb560b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fadcfd",
   "metadata": {},
   "source": [
    "This plot will show the architecture of the model, including the layers and their connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974e59c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    " \n",
    "\n",
    "plot_model(model, to_file='plot.png', show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60824c1",
   "metadata": {},
   "source": [
    "The code below is setting up a `ModelCheckpoint` callback and then compiling and training the model. The ModelCheckpoint callback is used to save the model's weights during training, which can be helpful for later model evaluation or resuming training from a specific point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8291451c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 6.2789\n",
      "Epoch 1: loss improved from inf to 6.28155, saving model to next_words.h5\n",
      "28/28 [==============================] - 3s 63ms/step - loss: 6.2815\n",
      "Epoch 2/70\n",
      " 2/28 [=>............................] - ETA: 1s - loss: 5.8666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cherilyogi/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - ETA: 0s - loss: 5.9075\n",
      "Epoch 2: loss improved from 6.28155 to 5.90749, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 65ms/step - loss: 5.9075\n",
      "Epoch 3/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.8053\n",
      "Epoch 3: loss improved from 5.90749 to 5.80534, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 5.8053\n",
      "Epoch 4/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.7174\n",
      "Epoch 4: loss improved from 5.80534 to 5.71742, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 5.7174\n",
      "Epoch 5/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.6380\n",
      "Epoch 5: loss improved from 5.71742 to 5.63804, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 5.6380\n",
      "Epoch 6/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.5621\n",
      "Epoch 6: loss improved from 5.63804 to 5.56209, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 5.5621\n",
      "Epoch 7/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.4939\n",
      "Epoch 7: loss improved from 5.56209 to 5.49388, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 5.4939\n",
      "Epoch 8/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.4382\n",
      "Epoch 8: loss improved from 5.49388 to 5.43824, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 5.4382\n",
      "Epoch 9/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.3989\n",
      "Epoch 9: loss improved from 5.43824 to 5.39888, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 5.3989\n",
      "Epoch 10/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.3615\n",
      "Epoch 10: loss improved from 5.39888 to 5.36148, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 5.3615\n",
      "Epoch 11/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.3014\n",
      "Epoch 11: loss improved from 5.36148 to 5.30140, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 5.3014\n",
      "Epoch 12/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.2268\n",
      "Epoch 12: loss improved from 5.30140 to 5.22684, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 5.2268\n",
      "Epoch 13/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.1265\n",
      "Epoch 13: loss improved from 5.22684 to 5.12649, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 5.1265\n",
      "Epoch 14/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.0122\n",
      "Epoch 14: loss improved from 5.12649 to 5.01220, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 5.0122\n",
      "Epoch 15/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.8915\n",
      "Epoch 15: loss improved from 5.01220 to 4.89149, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 4.8915\n",
      "Epoch 16/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.7889\n",
      "Epoch 16: loss improved from 4.89149 to 4.78886, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 4.7889\n",
      "Epoch 17/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.6299\n",
      "Epoch 17: loss improved from 4.78886 to 4.62993, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 4.6299\n",
      "Epoch 18/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.5430\n",
      "Epoch 18: loss improved from 4.62993 to 4.54302, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 4.5430\n",
      "Epoch 19/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.4562\n",
      "Epoch 19: loss improved from 4.54302 to 4.45617, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 4.4562\n",
      "Epoch 20/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.3447\n",
      "Epoch 20: loss improved from 4.45617 to 4.34468, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 4.3447\n",
      "Epoch 21/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.2733\n",
      "Epoch 21: loss improved from 4.34468 to 4.27331, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 4.2733\n",
      "Epoch 22/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.1753\n",
      "Epoch 22: loss improved from 4.27331 to 4.17533, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 4.1753\n",
      "Epoch 23/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 4.0312\n",
      "Epoch 23: loss improved from 4.17533 to 4.03124, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 4.0312\n",
      "Epoch 24/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 3.8844\n",
      "Epoch 24: loss improved from 4.03124 to 3.88436, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 3.8844\n",
      "Epoch 25/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 3.6756\n",
      "Epoch 25: loss improved from 3.88436 to 3.67558, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 3.6756\n",
      "Epoch 26/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 3.4438\n",
      "Epoch 26: loss improved from 3.67558 to 3.44382, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 3.4438\n",
      "Epoch 27/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 3.2810\n",
      "Epoch 27: loss improved from 3.44382 to 3.28104, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 3.2810\n",
      "Epoch 28/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 3.0507\n",
      "Epoch 28: loss improved from 3.28104 to 3.05075, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 3.0507\n",
      "Epoch 29/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.8463\n",
      "Epoch 29: loss improved from 3.05075 to 2.84632, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 2.8463\n",
      "Epoch 30/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.6588\n",
      "Epoch 30: loss improved from 2.84632 to 2.65878, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 2.6588\n",
      "Epoch 31/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.4143\n",
      "Epoch 31: loss improved from 2.65878 to 2.41427, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 2.4143\n",
      "Epoch 32/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.1669\n",
      "Epoch 32: loss improved from 2.41427 to 2.16689, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 2.1669\n",
      "Epoch 33/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0506\n",
      "Epoch 33: loss improved from 2.16689 to 2.05064, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 2.0506\n",
      "Epoch 34/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8092\n",
      "Epoch 34: loss improved from 2.05064 to 1.80920, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 1.8092\n",
      "Epoch 35/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5906\n",
      "Epoch 35: loss improved from 1.80920 to 1.59059, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 1.5906\n",
      "Epoch 36/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4257\n",
      "Epoch 36: loss improved from 1.59059 to 1.42568, saving model to next_words.h5\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 1.4257\n",
      "Epoch 37/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3778\n",
      "Epoch 37: loss improved from 1.42568 to 1.37780, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 1.3778\n",
      "Epoch 38/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2401\n",
      "Epoch 38: loss improved from 1.37780 to 1.24011, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 1.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1107\n",
      "Epoch 39: loss improved from 1.24011 to 1.11067, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 1.1107\n",
      "Epoch 40/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0459\n",
      "Epoch 40: loss improved from 1.11067 to 1.04589, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 1.0459\n",
      "Epoch 41/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8867\n",
      "Epoch 41: loss improved from 1.04589 to 0.88672, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.8867\n",
      "Epoch 42/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7363\n",
      "Epoch 42: loss improved from 0.88672 to 0.73627, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.7363\n",
      "Epoch 43/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6511\n",
      "Epoch 43: loss improved from 0.73627 to 0.65106, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.6511\n",
      "Epoch 44/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6468\n",
      "Epoch 44: loss improved from 0.65106 to 0.64680, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 0.6468\n",
      "Epoch 45/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5805\n",
      "Epoch 45: loss improved from 0.64680 to 0.58046, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 0.5805\n",
      "Epoch 46/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4469\n",
      "Epoch 46: loss improved from 0.58046 to 0.44686, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.4469\n",
      "Epoch 47/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3636\n",
      "Epoch 47: loss improved from 0.44686 to 0.36361, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 0.3636\n",
      "Epoch 48/70\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3284\n",
      "Epoch 48: loss improved from 0.36361 to 0.33273, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 0.3327\n",
      "Epoch 49/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3218\n",
      "Epoch 49: loss improved from 0.33273 to 0.32179, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 0.3218\n",
      "Epoch 50/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2270\n",
      "Epoch 50: loss improved from 0.32179 to 0.22700, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 0.2270\n",
      "Epoch 51/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2061\n",
      "Epoch 51: loss improved from 0.22700 to 0.20612, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.2061\n",
      "Epoch 52/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2177\n",
      "Epoch 52: loss did not improve from 0.20612\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 0.2177\n",
      "Epoch 53/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2176\n",
      "Epoch 53: loss did not improve from 0.20612\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2176\n",
      "Epoch 54/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2158\n",
      "Epoch 54: loss did not improve from 0.20612\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 0.2158\n",
      "Epoch 55/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 55: loss improved from 0.20612 to 0.20086, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 0.2009\n",
      "Epoch 56/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1931\n",
      "Epoch 56: loss improved from 0.20086 to 0.19307, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 0.1931\n",
      "Epoch 57/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 57: loss improved from 0.19307 to 0.17745, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 0.1774\n",
      "Epoch 58/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 58: loss improved from 0.17745 to 0.17629, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 0.1763\n",
      "Epoch 59/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1544\n",
      "Epoch 59: loss improved from 0.17629 to 0.15438, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 0.1544\n",
      "Epoch 60/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 60: loss did not improve from 0.15438\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 0.1628\n",
      "Epoch 61/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1615\n",
      "Epoch 61: loss did not improve from 0.15438\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 0.1615\n",
      "Epoch 62/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 62: loss did not improve from 0.15438\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.1604\n",
      "Epoch 63/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1436\n",
      "Epoch 63: loss improved from 0.15438 to 0.14361, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 0.1436\n",
      "Epoch 64/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1590\n",
      "Epoch 64: loss did not improve from 0.14361\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 0.1590\n",
      "Epoch 65/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1697\n",
      "Epoch 65: loss did not improve from 0.14361\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 0.1697\n",
      "Epoch 66/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1555\n",
      "Epoch 66: loss did not improve from 0.14361\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 0.1555\n",
      "Epoch 67/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1486\n",
      "Epoch 67: loss did not improve from 0.14361\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 0.1486\n",
      "Epoch 68/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1392\n",
      "Epoch 68: loss improved from 0.14361 to 0.13920, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.1392\n",
      "Epoch 69/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 69: loss did not improve from 0.13920\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.1494\n",
      "Epoch 70/70\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1224\n",
      "Epoch 70: loss improved from 0.13920 to 0.12239, saving model to next_words.h5\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29bfbf3d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    " \n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa428094",
   "metadata": {},
   "source": [
    "The function `Predict_Next_Words`  uses a trained model to predict the next word in a sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f9f413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    " \n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    " \n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "    \n",
    " \n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    sequence = np.array(sequence)\n",
    "    preds = np.argmax(model.predict(sequence))\n",
    "    predicted_word = \"\"\n",
    "\n",
    "    for key, value in tokenizer.word_index.items():\n",
    "        if value == preds:\n",
    "            predicted_word = key\n",
    "            break\n",
    "\n",
    "    print(predicted_word)\n",
    "    return predicted_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bace261",
   "metadata": {},
   "source": [
    "We have implemented a loop that allows a user to input a line of text, and we use the last three words of that text as input to our `Predict_Next_Words` function to predict the next word. If the user enters \"0,\" the loop stops, and the execution completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de508eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line or enter 0 to stop execution: राणा कुंभा अपनी बहन के साथ आधी रात को मंदिर गया\n",
      "['को', 'मंदिर', 'गया']\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "वह\n",
      "Enter your line or enter 0 to stop execution: बातें कर रही हो, उसे मेरे सामने लाओ।’ मीरा\n",
      "['सामने', 'लाओ।’', 'मीरा']\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "कि\n",
      "Enter your line or enter 0 to stop execution: 0\n",
      "Execution completed.....\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter your line or enter 0 to stop execution: \")\n",
    "\n",
    "    if text == \"0\":\n",
    "        print(\"Execution completed.....\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            text = text.split(\" \")\n",
    "            text = text[-3:]\n",
    "            print(text)\n",
    "\n",
    "            Predict_Next_Words(model, tokenizer, text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred: \",e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec45ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
